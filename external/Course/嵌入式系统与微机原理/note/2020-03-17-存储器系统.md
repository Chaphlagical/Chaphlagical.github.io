---
title: 存储器系统
tags: 微机原理与嵌入式系统
article_header:
  type: cover
  image:
    src: /assets/images/embed.jpg
---

<!--more-->

[课程地址1](https://www.eeo.cn/live.php?lessonKey=a8fe0aeef4fc86cd)

[课程地址2](https://www.eeo.cn/live.php?lessonKey=915fa9c5b9693201)

## 一、概述

### (一) 存储器类型及特点

#### 1、半导体存储器

##### (1) 原理

半导体存储器是一种以半导体电路作为存储媒体的存储器

* 内存储器就是由成为存储器芯片的半导体集成电路组成

##### (2) 分类

**按其功能分类**

* 随机存取存储器RAM
* 只读存储器ROM

**按地位和作用分**

<img src="/assets/images/存储器系统.assets/image-20200305144425236.png" alt="image-20200305144425236" style="zoom:67%;" />

**按结构和工艺分**

* TTL（Transistor-Transistor Logic）
* COMS（Complementary metal-oxide-semiconductor）

**按存储信息的可保存性分**

* 易失性存储器
* 非易失性存储器

**按存储器在计算机中的功能分**

* 高速缓冲存储器（Cache）
* 主存储器
* 辅助存储器（外存储器）

##### (3) 优点

* 体积小
* 存储速度快
* 存储密度高
* 与逻辑电路接口容易

##### (4) 缺点

* 和磁芯存储器不同，半导体存储器如RAM，属于易失性存储器，在电源中断时数据消失
* 可擦除、可编程ROM，编程次数有限

#### 2、磁介质存储器

##### (1) 原理

利用磁性介质的磁极化来存储信息

##### (2) 分类

* 早期主要用磁泡、磁鼓和磁芯作为存储器
* 现在主要采用磁表面存储器；磁盘（硬盘、软盘）和磁带

##### (3) 特点

* 早期为主存。现在为外设，需接口电路支持
* 非易失性存储器，容量大，存取速度越来越快，体积不断减小。主要的外设，应用广泛

##### (4) 磁芯存储器结构和工作方式

磁芯在导线上流过一定电流情形下会被磁化或者改变磁化方向，实现通过实验和材料的工艺控制得到这个能够让磁芯磁化的电流最小阈值。根据磁化时电流的方向磁芯可产生两个相反方向的磁化，这就可作为0和1的状态来记录数据。每个磁芯都有XY互相垂直的两个方向的导线穿过，另外还有一条斜穿的读出线，这些线组成阵列，XY分别做两个不同方向的寻址

##### (5) 磁盘结构和工作方式

* 磁盘，是在一片或多片金属、薄膜或玻璃上覆盖磁性材料，由磁头随机存取表面被磁化的不同信息
* 以硬磁盘为代表的存储器，由硬磁盘、磁头、磁盘旋转运动机构，以及控制器组成，驱动盘片高速运动，由磁头沿径向运动进行存取信息的读写
* 作为计算机的海量外存，主要存储文件、图像和视频等
* 硬磁盘存储器已经是微型计算机系统最主要的标准外设之一，经过不断地技术进步，其容量越来越大，存取速度越来越高，而体积却不断减小

##### (6) 磁带结构和工作方式

* 磁带是一种柔软地带状磁性记录介质，由带基和磁表面层两部分组成，带基多为薄膜聚酯材料，磁表面层所用材料多为$\gamma-\mathrm{Fe_2O_3}$和$\mathrm{CrO_2}$等
* 由磁带传送机构、赐福控制电路、读写磁头、读写电路和有关逻辑控制电路等组成。驱动磁带相对磁头运动，用磁头进行电磁转换，在磁带上顺序地记录或读出数据
* 磁带控制器是中央处理器在磁带机上读写数据用的控制电路装置。存储数据地磁带可脱机保存和互换读出

#### 3、光存储器

##### (1) 原理

* 光盘上刻有凹点和空白，光照射后辐射强度不同，接收电路再转化为0、1地数字信号

##### (2) 分类

* 只读型光盘
* 可记录型光盘

##### (3) 光驱结构和工作方式

* 光驱组成：激光头组件（激光发射器、半分光棱镜、物镜、透镜以及光电二极管）、驱动机械部分、电路及电路板（电源电路、前置信号处理电路、聚焦/循迹/径向/主轴伺服电路、光电转换及控制电路、DSP数字信号处理电路等）、IDE解码器及输出接口、控制面板及外壳等
* 工作方式：驱动光盘高速旋转，激光二极管产生对应波长地激光光束，照射光盘表面，经由激光头组件中地光电二极管捕捉反射回来地信号从而识别实际地数据

##### (4) 特点

* 作为计算机外设：内置、外置。不同类型地光盘需要不用类型设备地支持
* 非易失性存储器，容量大，成本低，应用广泛

### (二) 微机系统的存储体系架构

* 简单地二级结构
	* 内存+外存
* 完整的四级结构
	* 寄存器+Cache+主存+辅存（联机、脱机外存）

<img src="/assets/images/存储器系统.assets/image-20200305151232929.png" alt="image-20200305151232929" style="zoom:50%;" />

<img src="/assets/images/存储器系统.assets/image-20200305151248536.png" alt="image-20200305151248536" style="zoom:67%;" />

#### 1、寄存器

##### (1) 组成

采用触发器，构成中央处理器CPU中地一部分

##### (2) 功能

暂存指令、数据和地址

##### (3) 特点

CPU处理的数据先提取到寄存器。有限存储容量，高速

#### 2、高速缓冲存储器Cache

##### (1) 组成

存在于CPU与内存之间，由静态存储芯片SRAM组成

##### (2) 功能

CPU向内存读取数据时，首先查询Cache存储体缓存区是否有对应数据，如果有则直接读取，没有再从内存中读取

##### (3) 特点

* 成本高，容量比较小。但速度比内存高得多，近于CPU的速度
* 系统动态管理缓存中的数据，如果有数据访问频率降低到一定值，就从Cache存储体中移除，而将内存中访问更加频繁的数据替换进去

#### 3、主存储器

##### (1) 组成

* 主存储器，简称内存，是计算机运行过程中的存储主力，主要由DRAM和ROM组成
* 在一些特殊类型或者小容量应用场合，如，在嵌入式系统中，也采用SRAM作为主存

##### (2) 功能

程序的运行都是在内存中进行。存储指令（编译好的代码段），运行中的各个静态，动态，临时变量，外部文件的指针等等

##### (3) 特点

成本较高，容量比较大，速度高，但比Cache低得多

#### 4、辅存

##### (1) 联机外存储器

* 组成：主要为磁介质的机械硬盘、固态硬盘SSD
* 功能：存储需要永久存储的文件
* 特点：
	* 磁介质机械硬盘空间大，价格便宜
	* 固态硬盘在接口的规范和定义、功能及使用方法上与普通机械硬盘完全相同，在产品外形和尺寸上也完全一致

##### (2) 脱机外存储器

移动硬盘、光盘、U盘、FLash等便携式存储器，便于携带

### (三) 辅助存储器的主要接口标准

常将联机、脱机存储器称为辅助存储器。辅助存储器接口，主要包括硬盘接口标准、Flash存储卡的接口标准等。通用的接口标准为不同类型辅助存储器产品提供接入的互换性，便于产品升级和维护

<img src="/assets/images/存储器系统.assets/image-20200305152815295.png" alt="image-20200305152815295" style="zoom:67%;" />

#### 1、IDE接口

* IDE又称为ATA，用40/80针排线连接PC机和硬盘，16位双向总线并行传送，盘体与控制器集成一起以减少接口电缆长度，提高传输可靠性
* 后发展为Ultra DMA，最快的Ultra DMA133接口的时钟达到133MHz
* 由于采用并行接口传输数据，也称为PATA硬盘

#### 2、SCSI接口

* 用于计算机及其周边设备之间（硬盘、软驱、光驱、打印机、扫描仪等）系统级接口的独立处理器标准
* 配专门SCSI控制卡，最多连15个硬盘，也可驱动其他SCSI接口外设
* SCSI多用于中高端的服务器和工作站。主流的Ultra 320SCSI的速度为320MB/s

#### 3、SATA接口

* SATA使用了差动信号系统，能有效滤除噪声
* 4针串行点对点传输数据，一次传一位，但总线8位，每时钟周期能传送1字节，并用数据包传送，速率达150MB/s
* 接口结构简单，能减小功耗，支持热插拔，还能对传输指令进行检查，并自动纠错，传输可靠性高
* SATA2和SATA3是最新硬盘接口，传输速度分别达到300MB/s和600MB/s

#### 4、SAS接口

* 串行连接SCSI接口
* 新一代SCSI技术，它和SATA接口那样采用串行技术来获得更高的传输速度，并通过缩短连线来改善内部空间等
* SAS的接口技术可以向下兼容SATA，而SATA系统不兼容SAS

#### 5、SD接口

* SD卡的数据传送和物理规范由MMC（Multi Media Card）发展而来，大小和MMC卡相似，长宽和MMC卡一样，比MMC卡厚0.7mm
* SD卡集成了闪存记忆卡控制器、MLC（Multilevel Cell）和NAND闪存，通过9针的接口界面与专门的驱动器相连接
* SD卡系统是一个新的大容量存储系统，提供了一个便宜的、结实的卡片式的存储媒介
* SD卡的低耗电和广供电电压，可以满足移动电话、电池应用。使用非常有效的数据压缩比如MPEG，SD卡可以提供足够的容量来存储多媒体数据
* SD卡衍生类型Micro SD（T-Flash，简称TF）卡，具有更小的尺寸，在大部分场合替代了常规的SD卡，成为脱机外存储器的主流。

<img src="/assets/images/存储器系统.assets/image-20200305154716470.png" alt="image-20200305154716470" style="zoom:67%;" />

#### 6、eMMC接口

##### (1) 嵌入式存储器接口

* 嵌入式MMC，基于MMC协议的内嵌式存储器标准规格。主要针对使用成本较低的数据存储和传播媒体产品，手机或平板电脑等产品
* eMMC=控制器+NAND Flash+MMC标准封装接口
* eMMC封装为MCP芯片。为BGA封装
* eMMC支持MMC、SPI模式

##### (2) 特点

* 接口速度高达每秒400MBytes
* 不需处理其它复杂的NAND Flash兼容性和管理问题，简化了存储器的设计
* eMMC加快了新产品更新速度，减少研发成本，缩短新产品研发周期
* eMMC为半双工方式。将有被全双工的UFS取代的趋势

#### 7、UFS

* UFS，即“通用闪存存储”，同样是一种内嵌式存储器的标准规格，由JEDEC（Joint Electron Device Engineering Council）发布。同样是整合有主控芯片的闪存，不过其使用的是PC平台上常见的SCSI结构模型并支持对应的SCSI指令集
* UFS是UFSHCI标准JESD223的扩展
* UFSHCI标准定义了UFS驱动程序和UFS主机控制器之间的接口。除寄存器接口外，它还定义了系统内存中的数据结构，用于交换数据，控制和状态信息
* 技术特点
	* 串行传输，全双工，同一通道允许读写传输，读写能够同时进行，单通道带宽达1.5GB/s以上，传输效率有效提高
	* 抗EMI和串扰差分信号可以使用较低的电压，并且由于提高了抗噪声性能，获得更好的信噪比（SNR）
	* 差分信号集成到UFS卡，降低接收器电路复杂性
	* CLK线上的电阻，通过阻尼减少信号失真和EMI
	* 电源电容，去耦以及储能35

## 二、半导体存储芯片的基本结构和性能指标

* 电子计算机主板上主要采用半导体存储器，称为内存。内存用来存放当前正在执行的数据和程序，有易失性和非易失性两种
	* PC上内存是RAM
	* 嵌入式系统上则RAM和ROM都有
* RAM属于易失性存储器
	* 仅用于暂时存放程序和数据，关闭电源或断电，数据会丢失。
* ROM属于非易失性存储器
	* 用于存放程序和静态数据，即使断电，数据也不会丢失。
* 存储器的性能指标
	* 存储容量、存取时间、存储周期、存储器带宽，可靠性、功耗、价格、电源种类等

### (一) 随机存取存储器

* 随机存取存储器
	* 在使用过程中既可利用程序随时写入信息，又可随时读出信息，分为双极型和MOS型两种。前者读写速度高，但功耗大，集成度低，故在微型机主存中几乎都用后者。
* RAM分为两类：
	* 静态RAM（SRAM，Static RAM），其存储电路以双稳态触发器为基础，状态稳定，只要不掉电，信息不会丢失。优点是不需刷新，缺点是集成度低。适用于不需要大存储容量的微型计算机（例如，单板机和单片机）中。
	* 动态RAM（DRAM，Dynamic RAM），其存储单元以电容为基础，电路简单，集成度高。但也存在问题，即电容中电荷由于漏电会逐渐丢失，因此DRAM需定时刷新电路。它适用于大存储容量的计算机

#### 1、静态RAM（SRAM）

##### (1) 特点

* 用双稳态触发器（锁存器）存储信息。
* 速度快（双极型<5ns，MOS型几十～几百ns ），不需刷新，外围电路比较简单，但集成度低（存储容量小，约1Mbit/片），功耗大。
* SRAM被广泛地用作高速缓冲存储器Cache。
* 对容量为$M\times N$的SRAM芯片，其地址线数=$\lg2M$；数据线数=$N$。反之，若SRAM芯片的地址线数为$K$，则可以推断其单元数为$2^K$个。如，地址线分别为13、10根，则单元数为$2^{13}×8,2^{10}×4$ 

##### (2) 存储单元

<img src="/assets/images/存储器系统.assets/image-20200305155648090.png" alt="image-20200305155648090" style="zoom:67%;" />

* $V_1～V_4$管组成双稳态锁存器，用于记忆1位二值代码。
* 若$V_1$截止，则A点为高电平，它使$V_2$导通，于是B点为低电平，这又保证了$V_1$的截止。为“1”状态。
* 同样，$V_1$导通而$V_2$截止，则A点为低电平，B点为高电平，这是另一个稳定状态，“0”状态。
* 仅仅能保持这两个状态的一种还是不够的，还要对状态进行控制，于是就加上了控制管$V_5$、$V_6$ 

##### (3) 工作原理

**保持状态**

<img src="/assets/images/存储器系统.assets/image-20200305155840968.png" alt="image-20200305155840968" style="zoom:67%;" />

**读出状态**

选择线通过译码控制为高电平

<img src="/assets/images/存储器系统.assets/image-20200305155907768.png" alt="image-20200305155907768" style="zoom:67%;" />

**写入状态**

选择线通过译码控制为高电平

<img src="/assets/images/存储器系统.assets/image-20200305155940157.png" alt="image-20200305155940157" style="zoom:67%;" />

##### (4) 静态RAM芯片结构

* 静态RAM芯片内部由多个基本存储电路单元组成，容量为单元数与数据线位数之乘积。
* 为了选中某一个单元，往往利用矩阵式排列的地址译码电路。
	* 行选择信号+ 列选择信号
* 例如，1K单元的内存需10根地址线，其中5根用于行译码，另5根用于列译码。
* 译码后在芯片内部排列成32条行选择线和32条列选择线，这样可选中1024个单元中的任何一个，而每一个单元的基本存储电路的个数与数据线位数相同
* 常用的典型SRAM芯片有6116、6264、62256、628128等

**6116芯片**

<img src="/assets/images/存储器系统.assets/image-20200305160302944.png" alt="image-20200305160302944" style="zoom:67%;" />

* 6116芯片的容量为$2K×8$位。
* 2048个存储单元需11根地址线
	* 7根用于行地址译码输入，4根用于列译码地址输入
	* 每条列线控制8位，形成了128×128个存储阵列，即16384个存储位
* 6116的控制线有三条，片选CS#、输出允许OE#和读写控制WE#
* 工作过程：
	* 读出
		* 地址输入线$A_{10}～A_0$送来的地址信号经地址译码器送到行、列地址译码器
		* 译码后选中一个存储单元（8个存储位）
		* 由CS#、OE#、WE#构成读出逻辑(CS#=0，OE#=0，WE#=1）
		* 打开右面的8个三态门，被选中单元的8位数据经I/O电路和三态门送到D7～D0输出
	* 写入
		* 地址选中某一存储单元的方法和读出时相同不过这时CS#=0，OE#=1，WE#=0
		* 不过这时CS#=0，OE#=1，WE#=0
		* 打开左边的三态门，从D~7~～D~0~端输入的数据经三态门和输入数据控制电路送到I/O电路，从而写到存储单元的8个存储位中

#### 2、动态RAM（DRAM）

##### (1) 特点

* DRAM是靠MOS电路中栅极电容存储信息，电容上的电荷会逐渐泄漏
* 需要定时充电以维持存储内容不丢失（称为动态刷新），动态RAM需要设置刷新电路，相应外围电路就较为复杂。刷新定时间隔一般为几微秒～几毫秒
* 集成度高（存储容量大，可达1Gbit/片以上），功耗低，但速度慢，约为SRAM的一半，需要刷新
* DRAM在微机中应用广泛，如微机中的内存条（主存）、显卡上的显示存储器几乎都是用DRAM制造的

##### (2) 存储原理

<img src="/assets/images/存储器系统.assets/image-20200305160647224.png" alt="image-20200305160647224" style="zoom:67%;" />

* 存储单元由1个MOS管和1个小电容构成。
	* 电容C充满电荷便保存了信息1
	* 电容C无电荷为0
* 数据输入输出端连数据总线的某一位D~i~（位线）。
* 低位地址（如A~0~~ A~7~）译码产生行选信号X，高位地址（如A~15~~A~8~）译码产生列选信号Y。X、Y都为高电平时该单元被选中
* 刷新操作：
	* 电容C上保存的电荷会逐渐泄漏。故DRAM使用过程中需要及时向保存1的那些存储单元补充电荷，也就是对电容C进行预充电，这一过程称为DRAM的刷新（refresh）。
	* 刷新逐行进行，当某一行选择信号X为“1”时，选中了该行，电容上信息送到刷新放大器上，刷新放大器又对这些电容立即进行重写。刷新时，列选择信号Y为“0”，因此电容上信息不会被送到数据总线上。
	* 温度升高会加快电容放电，因此两次刷新的间隔不能太短，规定为1~100ms。在70°C时的典型刷新间隔为2ms，绝大多数刷新电路按此标准设计

* 写操作时，X=1，Y=1，Q和T管均导通，要写入的值（0或1）从Di加到C上。
* 读操作时，Q和T同样导通，存储在C上电荷通过Q、刷新放大器和T输出到D~i~

##### (3) DRAM芯片举例

* 常见小容量DRAM芯片有：
	* 64K×1位－4164/2164
	* 256K×1位－41256
	* 1M×l位－21010
	* 256K×4位－21014
	* 4M×1位－21040... ...等
* 大容量DRAM芯片有：
	* 16M×16位
	* 64M×4位
	* 32M×8位
	* 256M×4位
	* 512M×4位（DDR结构）...等
* DRAM芯片举例：Intel 2164A  
	* 单管存储电路设计，容量：64K×1位
	* 数据线有二根：数据输入$\mathrm{D_{IN}}$和输出$\mathrm{D_{OUT}}$；
	* 8根地址输入脚A7~A0，分时接收8位行、列地址；
	* 行和列地址选通信号RAS#和CAS#输入端；
	* 读写命令WE# , 0-写，1-读

##### (4) 举例：Intel 216A

![image-20200305161411662](/assets/images/存储器系统.assets/image-20200305161411662.png)

* Intel 2164A的地址线与寻址
	* 容量为64K×1位，即片内有65536个存储单元，每个单元只有1位数据，用8片2164A才能构成64K字节的存储器。若想在2164A芯片内寻址64K个单元，则需要用16条地址线。但为减少地址线引脚数目，地址线又分为行地址线和列地址线，进行分时工作，这样DRAM对外部只需引出8条地址线。
	* 芯片内部有地址锁存器，利用多路开关，由行地址选通信号RAS(Row Address Strobe），把先送来的8位地址送至行地址锁存器加以锁存。由随后出现的列地址选通信号CAS(Column Address Strobe）把后送来的8位地址送至列地址锁存器加以锁存
* 64K×1存储主体，设计成4个128×128矩阵。
* 4个128路刷新放大器，接收由行地址选通的4×128个存储单元信息，经放大后再写回原存储单元进行刷新
* 16位地址分为行地址A~7~~ A~0~和列地址A~15~~A~8~，以分时复用方式，分两次送入芯片。行地址在先，列地址随后，各由一个8位地址锁存器保存。
* 两次送来的8位地址信息的最高位（A~7~和A~15~），形成RA7和CA7去控制4选1的I/O门电路，从4个矩阵中选择1个进行读/写。
* 行/列地址译码器对行/列地址的低7位进行译码，从某个128×128个单元中选择1个进行读/写。
* 行地址到达，选通信号RAS#变低；列地址到达，选通信号CAS#变低。经行/列时钟缓冲器协调后，有序控制行/列地址的选通以及数据读/写或刷新。
* 要写入的1位数据从$\mathrm{D_{IN}}$脚输入，由数据输入缓冲器暂存；准备从$\mathrm{D_{OUT}}$脚读出的1位数据，也先由输出缓冲器暂存。
* 写允许WE#以及RAS#、CAS#信号, 通过写允许时钟缓冲器控制后, 决定打开哪个数据缓冲器

##### (5) DRAM存储条

* 内存条

	* PC配置的内存已高达16GB、32GB，服务器更高达256GB，要求更高的DRAM集成度
	* 容量为1G位以及更高集成度的存储器芯片已大量使用。通常，把这些芯片放在内存条上形成更大存储容量，用户只需把内存条插到系统板上提供的存储条插座上即可使用。
	* 内存条标准化，实现通用和互换，便于维护和升级

* 内存条的主要技术指标

	* 容量：用户最关心的指标，每种内存条都有多种容量规格
	* 时钟频率：内存芯片的基本工作频率，即表5.2中列出的时钟频率
	* 数据速率：芯片上每根引脚可传输数据的速率
	* 数据宽度：可同时传输数据的位数，现大多为64位
	* 奇偶校验：在每1字节外增加了1位，用作出错检测
	* ECC功能：出错检查和修正功能
	* ......

* 存储条示例

	<img src="/assets/images/存储器系统.assets/image-20200305161709682.png" alt="image-20200305161709682" style="zoom:67%;" />

	* 图中是采用HYM59256A存储芯片，构成256K×9位存储容量的存储条。
	* 其中，2片256K×4位的存储芯片通过位扩展形成256K字节的存储单元，1片256K×1位的存储芯片作为奇偶校验
	* 引脚
		* A8～A0为地址输入线。
		* DQ7～DQ0为双向数据线，PD为奇偶校验数据输入，PCAS#为奇偶校验的地址选通信号，PQ为奇偶校验数据输出。
		* WE#为读写控制信号，RAS#、CAS#为行、列地址选通信号。
		* V~DD~为电源（+5V），V~SS~为地线。
		* 30个引脚定义是存储条的通用标准之一

### (二) 只读存储器

#### 1、ROM

* 只读存储器（ROM）掉电后信息不会丢失（非易失性或不会挥发性），弥补了RAM的不足，因此成为计算机中的一个重要部件。
* ROM包括掩模ROM、PROM、EPROM、EEPROM等多种类型。
* 掩模ROM和PROM已淘汰，广泛使用的是EEPROM 和Flash
* 注意：
	* ROM早已不是“只读”，仍称为ROM只是一种习惯
	* 只读，是相对于CPU的读写控制电平及其控制逻辑而言
	* EEPROM、Flash都是可在线编程读写的，只不过需要专门的写、擦除电平和时序

#### 2、掩膜ROM

<img src="/assets/images/存储器系统.assets/image-20200305164708204.png" alt="image-20200305164708204" style="zoom:67%;" />

* Mask ROM（掩膜ROM）的存储数据由专门设计的掩模板决定，为固化数据，用户不能修改。
* ROM电路结构包括存储矩阵、地址译码器和输出缓冲器三个组成部分。
	* 存储矩阵由许多存储单元排列而成。存储单元可以用二极管构成，也可以用双极型三极管或MOS管构成。每个单元能存放一位二值代码（0或1）。每一个或一组存储单元有一个对应的地址代码。
	* 地址译码器的作用是将输入的地址代码译成相应的控制信号，利用这个控制信号从存储矩阵中将指定的单元选出，并把其中的数据送到输出缓冲器。
	* 输出缓冲器的作用有两个，一是能提高存储器的带负载能力，二是实现对输出状态的三态控制，以使与系统的总线连接与隔离

**掩膜ROM芯片示例**

<img src="/assets/images/存储器系统.assets/image-20200305164756707.png" alt="image-20200305164756707" style="zoom: 67%;" />

* 例如，4位数据输出，4×4位的MOS管，单译码结构。
* 地址线A~1~、A~0~，译码后可译出4种状态W~3~~ W~0~。输出4条选择线，分别选中4个单元，每个单元4位输出。
* 存储矩阵由MOS门组成，当W~3~~ W~0~每根线上给出高电平信号时，都会在4根线d~3~~ d~0~上输出一个4位二值代码。
* 将每个输出代码称为一个“字”，并将W3~ W0称为字线，将d3~d0称为位线(或数据线），而A1、A0称为地址线。
* 输出端的缓冲器用来提高带负载能力，并将输出的高、低电平变换为标准的逻辑电平。
* 同时，通过给定EN#信号实现对输出的三态控制，将数据反相输出
* 若地址线A~1~A~0~=00，则选中0号单元，即字线0为高电平，若有MOS管与其相连(如位线d2和d0），其相应的MOS管导通，位线输出为0，而位线1和3没有MOS管与字线相连，则输出为1

#### 3、PROM

<img src="/assets/images/存储器系统.assets/image-20200305165024053.png" alt="image-20200305165024053" style="zoom:67%;" />

* 可编程ROM，即PROM是一种简单的可编程逻辑器件PLD（Programmable Logical Device）。
* PROM的总体结构与掩模ROM一样，同样由存储矩阵、地址译码器和输出电路组成。
* 在出厂时已经在存储矩阵的所有交叉点上全部制作了存储元件，即相当于在所有存储单元中都存入了“1”。
* 用户可以根据需要将其中的某些单元写入数据“0”（部分的PROM在出厂时数据全为“0”，则用户可以将其中的部分单元写入“1”），以实现对其“编程”的目的

##### (1) PROM采用经典的“双极性熔丝结构”

<img src="/assets/images/存储器系统.assets/image-20200305165128138.png" alt="image-20200305165128138" style="zoom:50%;" />

* 由一只三极管和串在发射极的快速熔断丝组成。
* 三极管be结相当于接在字线与位线之间的二极管。熔丝用很细的低熔点合金丝或多晶硅导线制成。
* 如果改写某些单元，则可以给这些单元通以足够大电流，维持一定时间后，需存入0的那些存储单元上的熔丝烧断

##### (2) 编程过程

* 地址译码器选择要编程的地址，找出要写“0” 的单元地址。
* 将V~CC~和选中的字线提高到编程所要求的高电平。
* 在编程单元的位线上加入编程脉冲（幅度约20V，持续时间约十几微秒）。
* 写入放大器A~W~的输出为低电平、低内阻状态，有较大的脉冲电流流过熔丝，将其熔断。
* 正常工作时读出放大器AR输出的高电平不足以使D~Z~导通，A~W~不工作

#### 4、EPROM

##### (1)简介

* 可擦除可编程ROM
	* 采用叠栅注入MOS管SIMOS (Stacked-gate Injection MOS)做存储单元
* 是一个N沟道增强型的MOS管，有两个重叠的栅极—控制栅G~c~和浮置栅G~f~
	* 控制栅G~c~用于控制读出和写入
	* 浮置栅G~f~用于长期保存注入电荷
* 初始状态
	* 浮栅上未注入电荷以前，在控制栅上加入正常的髙电平能够使漏-源之间产生导电沟道，MOS管导通，存储信息“0”
* 重复擦写编程的EPROM
	* 利用编程器写入后，信息可长久保持，因此可作为只读存储器
	* 需要变更时，可利用擦除器将其擦除，各单元内容读出值为FFH
	* 再根据需要利用EPROM编程器编程，因此这种芯片可反复使用

##### (2) 编程原理

* 漏-源间加较高电压（约+20~+25V），发生雪崩击穿
* 同时在控制栅上加以高压脉冲（幅度约+25V，宽度约50ms）
* 在栅极电场作用下，一些高能量电子穿越Si02层到达浮置栅，被浮置栅俘获而形成注入电荷
* 浮置栅上注入了电荷的SIMOS管相当于写入了“1”，未注入电荷的相当于存入了“0”

##### (3) 擦除原理

* 存储器芯片开有玻璃窗口。
* 用特定波长紫外线照射该窗口数分钟，所有存储单元浮栅上的电荷会形成光电流泄放掉，使浮栅恢复初态。
* 擦净的芯片可重新编程。
* 编程过程总是从头到尾，对1块芯片的全部单元进行重写，因此不能修改芯片中的部分内容（哪怕1个字节）。
* 通过编程器写入新的数据后，需要将窗口用不透光胶带遮蔽，避免紫外线照射而使电荷泄放，以防数据丢失

##### (4) EPROM芯片示例

<img src="/assets/images/存储器系统.assets/image-20200305171714470.png" alt="image-20200305171714470" style="zoom: 67%;" />

* EPROM芯片有多种型号，如2716(2K×8 位）、2732(4K×8 位）、2764(8K×8 位）、27128(16K×8 位）、27256(32K×8 位）等
* 典型EPROM芯片2764A
	* 28脚DIP封装
	* 13条地址线A~12~~A~0~
	* 8条数据线D~7~~D~0~
	* 2个电压输入端V~CC~和V~PP~
	* 片选端CE#(功能同CS#）输出允许OE#编程控制端PGM#
* 读方式（数据）
	* V~CC~和V~PP~都接至+5 V，PGM#接至高电平
	* 当从2764A的某个单元读数据时，先通过地址引脚接收来自CPU的地址信号，然后使控制信号和CE#、OE#都有效
	* 经过一个时间间隔，指定单元的内容即可读到数据总线上
* 读方式（读Intel标识符）
	* A~9~引脚接至11.5～12.5 V
	* 分两次顺序读出两个字节，先让A~1~～A~8~全为低电平，而使A~0~从低变高
	* A~0~=0，读出制造商编码(陶瓷封装为89H，塑封为88H）
	* A~0~=1，读出器件编码(2764A为08H，27C64为07H）
* 备用方式
	* CE#为高电平，2764A就工作在备用方式，输出端为高阻状态
	* 芯片功耗将下降，从电源所取电流由100 mA下降到40 mA
* 编程方式
	* V~PP~接+12.5V，V~CC~接+5V
	* 从数据线输入数据
	* CE#端保持低电平，OE#为高电平
	* 每写一个地址单元，都必须在PGM#引脚端给一个低电平有效，宽度为45 ms的脉冲
* 编程禁止
	* 在编程过程中，只要使该片CE#为高电平，编程立即禁止
* 编程校验方式
	* 完成一个字节编程后，电源接法不变
	* PGM#为高电平，CE#、OE#均为低电平
	* 则同一单元数据在数据线上输出，这样就可与输入数据相比较，校验编程结果是否正确
* 快速编程方式
	* 传统编程按字节方式，宽度为45 ms的编程脉冲，速度慢。且容量越大，速度越慢
	* 新的编程方法提高速度达6倍以上
	* 思路：V~pp~上加编程电压，用1ms编程脉冲依次写完所有数据，再从头开始校验；若有错误，重写此单元

##### (5) EPROM存在的问题

* EPROM虽可多次重新编程使用，但是整个芯片只要写错一位，就必须从电路板上取下擦掉重写，擦除时间很长，因而使用不便。
* 在实际应用中，往往只要改写几个字节的内容，因此多数情况下需要以字节为单位进行擦写

#### 5、EEPROM

##### (1) 电可擦除可编程ROM、E^2^PROM基本特性

* 可以在电路板上直接编程写入（在系统编程）
* 允许以字节为单位擦除和重写，而EPROM需要将整个芯片所有的信息擦除后才能重写
* 使用单一的+5V电源，不需要专门的编程电源
* 在写入过程中自动进行擦写，一个字节的擦写时间远远小于EPROM所需的时间，约需10ms左右（但还是远远大于RAM）
* 无需专用电路，只要按一定的时序操作即可进行在线擦除和编程

##### (2) EEPROM工作原理

* 采用了一种称为浮栅隧道氧化层MOS管（Floating gate Tunnel Oxide，简称Flotox管）。Flotox管与SIMOS管相似，属于N沟道增强型的MOS管，有两个栅极—控制栅G~C~和浮置栅G~f~。
* 在E^2^PROM中，使浮动栅带上电荷与消去电荷的方法与EPROM不同
* 在E^2^PROM中，在浮动栅上方增加了一个控制栅，而浮动栅与漏极之间有一层极薄的氧化硅，称为隧道区（隧道二极管），在控制栅与源极之间的电压（实际是在电场）VG的作用下，电荷通过隧道流向浮空栅，实现写入
* 若VG的极性相反，则使电荷从浮动栅流向源极，即起擦除作用。编程与擦除所用的电流是极小的，可用普通的电源供给

##### (4) E~2~PROM结构示意图

<img src="/assets/images/存储器系统.assets/image-20200305172603701.png" alt="image-20200305172603701" style="zoom:67%;" />

为了提高擦、写的可靠性，并保护隧道区超薄氧化层，在E^2^PROM的存储单元中除Flotox管外还附加了一个选通管T~2~。右图中的T~1~为Flotox管（也称为存储管），T~2~为普通的N沟道增强型MOS管（也称为选通管）

<img src="/assets/images/存储器系统.assets/image-20200305172750911.png" alt="image-20200305172750911" style="zoom:50%;" />

##### (3) E~2~PROM 工作过程

* 读出
	* 字线加高电平使选通管T~2~导通
	* 若T~1~管浮置栅上没充负电荷，则T~1~管导通，在位线上读出“0”（低电平）
	* 若T~1~管浮置栅上充有负电荷，则T~1~截止，在位线上读出“1”
* 写入
	* 使写入为“0”的存储单元的T~1~管浮置栅放电
	* 控制栅G~C~为0电平
	* 同时在字线和位线上加+20V左右、宽度约10ms的脉冲电压
	* 浮置栅存储电荷通过隧道区放电，使T~1~管开启电压降为0V左右，成为低开启电压管
* 擦除
	* 控制栅、字线施加+20V左右、宽度约10ms脉冲电压，漏区接0电平
	* 浮置栅存储的负电荷，使Flotox管的开启电压提高到+7V以上
	* 读出时控制栅上电压只有+3V，故T~1~管不导通。一个字节擦除后，所有的存储单元均为1状态

##### (4) E^2^PROM典型芯片

* E^2^PROM的主要产品有：
	* 早期的高压编程芯片，如：2816、2817...
	* 低压编程芯片，如：2816A、2817A、2864A...
	* “大容量”28010(1M位，128KB)、28040(4M位)等
* E^2^PROM的主要技术指标：
	* 读取时间120~250ns
	* 字节擦写时间10ms左右写入时间与字节擦写时间相当，约10ms左右
	* 写入时间与字节擦写时间相当，约10ms左右

**举例：2816芯片**

<img src="/assets/images/存储器系统.assets/image-20200305173254478.png" alt="image-20200305173254478" style="zoom:50%;" />

* 基本特点
	* 2 K×8 位的E^2^PROM
	* 24脚DIP封装
	* 2816为双向数据线，以适应读写工作模式
	* 2816的读取时间为250ns，可满足多数微处理器对读取速度的要求
	* 最突出的特点是可以字节为单位进行擦除和重写
	* 擦或写用CE#和OE#信号加以控制，一个字节的擦写时间为10ms
	* 2816可整片进行擦除，整片擦除时间也是10ms
	* 无论字节擦除还是整片擦除均在机内进行

* 2816有六种工作方式，每种工作方式下各个控制信号所需电平如表所示

<img src="/assets/images/存储器系统.assets/image-20200305182435661.png" alt="image-20200305182435661" style="zoom: 50%;" />

* 2816读方式
	* 允许CPU读取2816的数据
	* 发出地址信号以及相关的控制信号
	* CE#、OE#信号有效延时读取，有效数据出现在总线上
* 2816写方式
	* 以字节为单位的擦除和写入是同一种操作，即都为写
	* 字节擦除和写入
		* CE#为低电平
		* OE#为高电平
		* 数据线为字节数据
		* V~PP~端输入编程脉冲，宽度最小为9ms，最大为70ms，电压为+21V。
		* 字节擦除是固定写“1”,数据输入是TTL高电平
* 2816片擦除方式
	* 两种擦除方式：片擦除、字节擦除
	* CE#为高电平
	* OE#引脚电压达+9～+15V
	* V~PP~接+21V编程脉冲
	* 数据输入引脚置为TTL高电平
	* 约经10ms，整片内容全部被擦除，即2KB的内容全为FFH
* 2816备用方式
	* 进入备用状态，输出呈高阻态
	* CE#端加TTL高电平
	* OE#控制无效
	* 备用状态下，其功耗可降到55％81

#### 6、Flash

##### (1) 简介

* 快闪存储器，常称为闪存，也称快擦写存储器，简称Flash Memory
* 闪存是一个笼统的称呼，准确地是指具有快速擦写和非易失等特性的存储器件
* 与普通存储芯片不同，闪存内部通常还带有多个寄存器和内部控制逻辑，可以编程选择闪存的工作方式和操作内容
* 由于闪存的存储密度（容量）大、非易失、存取速度快等特点，成为各个主要半导体厂商争先恐后的研发重点，新技术、新材料和新产品不断涌现
* 除了半导体以外，采用新型材料作为存储介质的全新一代闪存也在不断涌现、发展和完善之中

##### (2) 工作原理

目前常见的半导体闪存工作原理类似于E^2^PROM，采用MOS工艺。

* 若浮空栅上保存有电荷，则在源、漏极之间形成导电沟道，达到一种稳定状态，可以定义该基本存储单元电路保存信息“0”
* 若浮空栅上没有电荷，则在源、漏之间无法形成导电沟道，为另一稳定状态，可定义保存信息“1”。

<img src="/assets/images/存储器系统.assets/image-20200305183806021.png" alt="image-20200305183806021" style="zoom:67%;" />

<img src="/assets/images/存储器系统.assets/image-20200305183818759.png" alt="image-20200305183818759" style="zoom: 67%;" />

* Flash与E^2^PROM的区别

	* Flash没有选通管T，因此集成度高，容量大，但稳定性和擦写次数都不如E^2^PROM
	* E^2^PROM可按位擦除，Flash只能按块（或按页或行）擦除

	<img src="/assets/images/存储器系统.assets/image-20200305183951580.png" alt="image-20200305183951580" style="zoom:50%;" />

##### (3) 分类

* 闪存有多种类型，基于MOS工艺的闪存从结构上就有：AND、NOR、NAND、DiNOR等类型，其中NAND和NOR是目前的主流类型

* 快闪存储器Flash分为NAND flash和NOR flash二种

* NAND flash的擦和写均是基于隧道效应，电流穿过浮置栅极与硅基层之间的绝缘层，对浮置栅极进行充电（写数据）或放电（擦除数据）。

	* NANDFLASH的中的N是NOT，含义是FloatingGate中有电荷时，读出‘0’，无电荷时读出‘1’，是一种‘非’的逻辑；AND的含义是同一个BitLine下的各个基本存储单元是串联的，是一种‘与’的逻辑

		<img src="/assets/images/存储器系统.assets/image-20200305184227877.png" alt="image-20200305184227877" style="zoom:67%;" />

* NOR flash擦除数据是基于隧道效应（电流从浮置栅极到硅基层），但在写入数据时则是采用热电子注入方式（电流从浮置栅极到源极）

	* FLASH的中的N是NOT，含义是FloatingGate中有电荷时，读出‘0’，无电荷时读出‘1’，是一种‘非’的逻辑；OR的含义是同一个BitLine下的各个基本存储单元是并联的，是一种‘或’的逻辑

		<img src="/assets/images/存储器系统.assets/image-20200305184249097.png" alt="image-20200305184249097" style="zoom: 67%;" />

**NOR型闪存**

* NOR型闪存读写和存储格式与内存相近，其基本存储单元是bit，有独立的地址线和数据线，可按位随机读取
* NOR型闪存的特点之一是芯片内执行（XiP, eXecutein Place），应用程序可以像访问内存一样使用闪存
* NOR型闪存读操作的传输效率很高，在1～4MB的小容量时具有很高的成本效益。适合存储程序及相关数据
* 闪存的写入操作只能在空（存储“0”）或已擦除的单元内进行。虽然可以按位读取，但其擦除只能按“块”进行，所以写入和擦除速度较慢，影响了它的性能。NOR型闪存另一个的缺点是容量小，成本较高
* 手机中存放电话簿、短信和通话记录的是NOR型闪存

**NAND型闪存**

* NAND型闪存的优点是存储密度和存储容量大。2017年2月，WD旗下的Sandisk推出了iNAND7350，单芯片封装的容量高达256GB。
* NAND型闪存也需要先擦除再写入，擦除和写入是以块(Block)或者页(Page)为单位进行的，一个块包含了若干页，每一页的有效容量是512字节的倍数。
	* 有效容量指数据存储可用容量，此外还有m×16字节的空闲字节，用(n×512+m×16)Byte表示。2Gb以下多是每页(512+16)字节，32页组成一个块（16KB）；2Gb以上页容量扩大到（2048+64）字节，64页组成一个块（128KB）。空闲（spare）字节可用于ECC和磨损均衡（wear leveling）

### (三) 存储芯片的性能指标

#### 1、存储容量

* 在一个存储器中容纳的存储单元总数通常称为该存储器的存储容量
* 存储容量可以用位数、字数或字节数来表示
* 以位数表示的存储器芯片容量计算
* 存储器芯片容量＝单元数×数据线位数
* 例如，设地址线位数为n，数据线位数为m，则：
	* 编址单元总数为：2^n^
	* 存储器芯片容量为：2^n^×m

* 存储器芯片是以存储1位二进制数（bit）为最小单位。
* 存放一个机器字的存储单元，通常称为字存储单元，相应的单元地址叫字地址。而存放一个字节的单元，称为字节存储单元，相应的地址称为字节地址。
* 如果计算机中可编址的最小单位是字存储单元，则该计算机称为按字编址的计算机。如果计算机中可编址的最小单位是字节，则该计算机称为按字节编址的计算机。
* 一个机器字可以包含数个字节，所以一个存储单元也可以包含数个能够单独编址的字节地址。
* 虽然微型计算机的字长已经达到16位、32位，甚至64位，但其内存仍以一个字节为一个单元

* 计算机存储单位换算表：

	<img src="/assets/images/存储器系统.assets/image-20200305184637007.png" alt="image-20200305184637007" style="zoom: 50%;" />

#### 2、存取时间和存取周期

##### (1) 存取时间（访问时间）T~a~

* 存取时间称存储器访问时间，是指从启动一次存储器操作到完成该操作所经历的时间。如，从一次读操作命令发出到该操作完成，将数据读入数据缓冲寄存器为止所经历的时间
* 超高速存储器的存取时间小于20ns、中速100～200ns之间、低速300ns以上

##### (2) 影响T~a~的因素

* 不同存储器芯片，存取速度不同；只读存储器还是随机存储器；芯片的位容量，表示存储功能的指标；功耗，CMOS器件功耗低，速度慢；HMOS存储器件在速度、功耗和容量方面进行了折中；价格，存储器的价格，包括附加电路的价格

##### (3) 存取周期T~M~

* 存取周期是指连续启动两次独立的存储器操作（如连续两次读操作）所需间隔的最小时间。通常，存取周期略大于存取时间

##### 3、其他指标

* 数据传送速率（频宽）B~M~	
	* 数据传送速率，指单位时间内能够传送的信息量
	* 若系统的总线宽度为W，则BM=W/TM（b/s）。
	* 例如，若W=32位，TM=100ns，则
		* BM=32位/100×10-9s=320M位/s=40MB/s
		* 若TM=40ns，则BM=100MB/s
* 体积与功耗
	* 便携式微机，其便携性能和续航时间尤为重要，因而对体积、功耗非常敏感。
* 可靠性
	* 采用平均故障间隔时间MTBF衡量，即两次故障之间的平均时间间隔。
	* MTBF=1/λ
	* λ为故障率，表示单位时间内故障次数

## 三、内存条性能的改进

**使用内存条的原因：**

* 扩展性：早期，计算机将内存芯片直接固化在线路板上。由于无法拆卸更换，要进行内存的扩展非常麻烦。这对于计算机的发展造成了阻碍。随着软件规模的扩大，以及新的硬件平台对扩展性提出了更高的要求，迫切需要提高运行速度和扩大内存容量
* 互换性：不同的系统采用同样的内存，降低系统成本
* 灵活性：针对不同的系统规模，要求内存以更加灵活的方式配置
* 可维护性：通过标准化，使得内存通用，提高维护效率，降低维护成本

### (一) 内存条的组成

**内存颗粒**、**SPD芯片**、**PCB电路板**、**引脚（俗称金手指）**以及**阻容元件**组成

#### 1、内存颗粒

* 内存芯片称为内存颗粒
* 芯片封装：TSOP(Thin Small Outline Package）和BGA(Ball-Gird-Array）
* 根据内存条容量，集成数量不等的内存颗粒

#### 2、SPD芯片

* SPD（Serial Presence Detect）是一片E2PROM，记录内存条出厂时预先存入的速度、工作频率、容量、工作电压、行/列地址带宽、传输延迟、SPD版本等基本参数
* 开机时BIOS自动读取SPD记录信息，对主存进行设置，使内存运行在规定的工作频率，工作在最佳状态

#### 3、元件/芯片常用封装

* BGA(Ball Grid Array)，在封装底部，引脚都呈球状排列成类似于格子的图案。BGA封装使每平方英寸的存储量有了很大提升。且BGA封装方式有更加快速有效的散热途径

* 采用BGA封装的内存产品在相同容量下，体积只有TSOP封装的三分之一

	![image-20200310093054781](/assets/images/存储器系统.assets/image-20200310093054781.png)

#### 4、PCB (print circuit board，印刷电路板)

* 内存条的PCB采用4层或6层电路板。采用多层电路板一来可减小电路板体积；二来可分层屏蔽电路，减少电磁辐射，电源和地用单独的层有利于信号完整性

#### 5、金手指

* 金手指就是内存条电路板上的引脚，用于与计算机总线连接，也是内存条在主板上进行固定的装置，并连接总线上的有关信号线。
* 按照引脚布局，常用的内存条有：SIMM（single in-line memory module）、DIMM（Dual In-line Memory Module）、SODIMM（Small Outline Dual In-line Memory Module）等

#### 6、阻容元件

* 用于提高信号完整性，如防止信号反弹、滤除高频干扰等

### (二) 内存条的演变

* 最初的内存是直接以DIP封装芯片的形式安装在主板的DRAM插座上
* 最早的30脚SIPP（Single In-line Pin Package）接口，针脚的定义与30脚SIMM一样。SIPP很快就被SIMM取代，两侧金手指传输相同的信号
* 早期的内存频率与CPU外频不同步，采用异步DRAM。可细分为FPM DRAM（Fast Page Mode DRAM）、EDO DRAM（Extended Data Out DRAM），常见接口为30脚SIMM与72脚SIMM，工作电压都是5V

![image-20200310093851569](/assets/images/存储器系统.assets/image-20200310093851569.png)

#### 1、FPM DRAM&EDO DRAM

* 传统DRAM的访问，需要经过“**发送行址—发送列址—读写数据**”3个阶段，一次访问时间是每个阶段所需时间之和
* FPM（Fast Page Mode，快速页面模式）**对地址连续（列址相同）的多个单元进行读写访问**。除访问第一个数据之外，后续访问只需要经历“发送行地址—读写数据”2个阶段，从而缩短了访问时间
* EDO（Extended Data Out，扩展数据输出）是对传统DRAM存取技术的改进。它取消了主板与内存两个存储周期之间的时间间隔，每隔2个时钟脉冲周期传输一次数据，大大地缩短了存取时间。**在输入下一个行地址时，仍然允许数据输出进行**，扩展了数据输出的时间，“EDO”因此得名

#### 2、SDR SDRAM（Single Data Rate SDRAM）

* SDRAM（SynchronousDRAM，同步动态随机存取内存）
* 传统DRAM采用“异步”的方式进行存取，存储器的吞吐速率受限从而导致系统性能难以提高。
* SDRAM采用**同步方式**进行存取。**送往SDRAM的地址、数据和控制信号都在一个时钟信号的上升沿被采样和锁存，SDRAM输出的数据也在另一个时钟上升沿锁存到芯片内部的输出寄存器**。
* SDRAM收到地址和控制信号之后，在内部进行操作。在此期间，处理器和总线主控器可以处理其它任务（例如，启动其它存储体的读操作），无需做无谓等待，从而提高了系统性能。
* 输入地址、控制信号到数据输出所需的时钟个数可以通过对芯片内“方式寄存器”的编程来确定

* SDRAM芯片支持“突发总线模式（Burst）”进行读写操作。当对一组相邻的存储单元进行访问时，第一个地址给出后，后续地址自动生成，无需再发，可以进行连续读写，大大提高了速度
	* SDRAM增加了时钟信号和内存命令的概念。内存命令的类型取决于时钟上升沿上的CE#、RAS#、CAS# 和WE#信号状态
	* SDRAM工作电压为3.5V，采用168线带两个缺口的DIMM插槽。早期时钟频率为66M，后来多为133M，可进行64位的读写。产品规格用时钟频率表示，如pc100或pc133表示其时钟频率为100M或133M
	* SDRAM的存在时间相当长，Intel奔腾2、奔腾3与奔腾4，以及Slot 1、Socket 370与Socket 478的赛扬处理器，AMD的K6与K7处理器都可使用SDRAM内存条

#### 3、RDRAM（Rambus DRAM）

* Intel与Rambus合作并推出了Rambus DRAM内存条以代替SDR SDRAM，简称为RDRAM
* 与SDRAM不同，采用了新的**高速简单内存架构，减少数据复杂性**，提高整个系统性能
	* RDRAM内部引入了RISC，**依靠高时钟频率**来简化每个时钟周期的数据量
* RDRAM采用RIMM（Rambus In-line Memory Module）插槽，184脚，总线位宽16位，插两条组建双通道时就是32位，工作电压2.5V，频率有600、700、800、1066MHz等
	* RIMM与DIMM的外型尺寸差不多，金手指同样也是双面的
* RDRAM内存条通常都是用在Socket 423的奔腾4平台上，搭配Intel 850芯片组使用。由于RDRAM的制造成本高，使得RDRAM的价格居高不下。同时由于奔腾4平台的成本相对较高，最终导致RDRAM被DDR SDRAM替代

#### 4、DDR SDRAM

* DDR（DoubleDataRate）SDRAM（双倍速率同步内存），原来的SDRAM被称为SDRSDRAM
* SDR仅在时钟脉冲的上沿进行一次写或读操作，DDR内部有两个乒乓交替工作的存储体，还有2bit的预取缓冲，**可在时钟上沿和下沿都进行一次对等的写或读操作**，至少在理论上DDR的数据传输能力比同频率的SDR提高了一倍
* DDR内存条的工作电压是2.5V，共有184线，金手指只有一个“缺口”
	* DDR工作频率有100/133/166/200/266MHz等。所谓双倍速率就是传输速率是工作频率的两倍，因此型号上所标识的是工作频率×2，即标称为DDR200、266、333、400和533，容量128/256/512MB等，主要用于P4级别的64位PC机
	* DDR内存条最初只有单通道，后来出现了支持双通芯片组，让内存的带宽直接翻倍，两根DDR-400内存条组成双通道，可以满足FBS800MHz的奔腾4处理器
		* 能用DDR内存条的CPU很多，除Intel与AMD外，还有NVIDIA、VIA、ALI、ATI等厂家

#### 5、DDR2 SDRAM

* DDR2内存采用了**4bit预读取**（类似于快餐店里的备餐）技术，数据通过四条线路串行传输到I/O缓存区，使工作频率为100MHz的内存可实现400MHz的数据传输频率，因此称为DDR2-400，其带宽为（100MHz×4）×（64b/8b）=3200MB/s=3.2GB/s 
* 数据预取以及多路串行传送，实际数据传送速率相同时的功耗更低；或同样的功耗下拥有更快的传送速率
	* DDR2有240个金手指，DDR是184个，两者的防呆缺口位置不同
	* DDR2采用CAS、OCD、ODT等技术提高信号完整性
	* DDR2的标准电压下降至1.8V，相较上代产品更为节能
	* DDR2的频率从400MHz到1200MHz，主流的是DDR2-800
	* 容量从256MB至最大4GB，4GB的DDR2内存条应用很少
	* DDR2在2004年6月与Intel的915/925主板同步推出，伴随了大半个LGA 775时代26

#### 6、DDR3 SDRAM

* 在DDR2基础进一步改进为**8位预取**，如100MHz的DDR3-800，带宽可达到:                                       （100MHz×8）×（64b/8b）＝6.4GB/s
* 通过预取可以增加传送速度，很自然地启发我们，能否再提高预取比特数，例如从8n提高到16n，从而进一步提高数据传送速率？
* 回答是否定的。因为这需要将I/O控制器的频率再次翻倍，并且增加数据线数量，在I/O芯片频率已经很高时，技术难度和成本都会大幅增加。
	* DDR3的工作电压1.5V，240线，容量512MB和1/2/4/8GB，单条16GB的DDR3内存比较少。
	* DDR3还采用CWD、Reset、ZQ、STR、RASR等新技术，让内存在休眠时也能够随着温度变化去控制对内存颗粒的充电频率，以确保系统数据的完整性。
	* DDR3内存条随着Intel在2007年发布3系列芯片组一同到来。
	* 支持DDR3内存的平台有Intel后期的LGA 775主板P35、P45、x38、x48等，LGA 1366平台，LGA 115x系列全都支持。还有LGA 2011的x79，AMD方面AM3、AM3＋、FM1、FM2、FM3接口的产品均支持DDR3

#### 7、DDR4 SDRAM

* DDR4是目前的主流，相比DDR2和DDR3有以下几项关键技术
	* Bank Group架构。使用2个或4个可选择的采用8n预取的**Bank Group分组**，每个Bank Group可以独立读写数据，如果是2个独立的Bank Group，相当于将内存预取值提高到了16n，如果是4个独立的Bank Group，则等效的预取值提高到了32n。
	* 点到点传输。每个通道只连接一根内存条，消除了共享传输带来的性能瓶颈。
	* 3D堆叠。在散热允许情况下，采用3D堆叠封装技术，使得单根内存条的容量从目前8GB提高到64GB。其他技术变化
	* DDR4功耗明显降低，电压达到1.2V，传输速度从2133 MT/s起，最高可达4266 MT/s
* DDR4增加了DBI（Data Bus Inversion）、CRC（Cyclic Redundancy Check）、CA parity等功能，增强了信号的完整性、改善数据传输及储存的可靠性

#### 8、DDR5 SDRAM

* 主导内存标准制定的JEDEC（Joint Electron Device Engineering Council）规范组织，虽然之前宣布2018年正式发布DDR5标准，但实际上并没有，最终规范要到2020年才能完成。
* DDR5主要特性是芯片容量，而不仅仅是更高的性能和更低的功耗。
	* 内存带宽在DDR4基础上翻倍，从8位翻倍到16位。
	* 频率最低4800MHz，最高6400MHz。
	* 电压则从1.2V降至1.1V，功耗减少30%。
	* 每个模块使用两个独立的32/40位通道，支持ECC（Error Correcting Code）。
* 此外，DDR5将具有改进的命令总线效率，更好的刷新方案以及增加的存储体，以获得额外的性能，提高总线效率。

## 四、存储系统的层次架构

### (一) 存储器系统的分层管理、

#### 1、完整的四级结构

* 寄存器＋Cache＋主存＋辅存（联机、脱机外存）

#### 2、存储系统的基本特点

* 存储系统是指计算机中由存放程序和数据的各种存储设备、控制部件及管理信息调度的设备（硬件）和算法（软件）所组成的系统。
* 存储系统的性能在计算机中具有非常重要的地位，存储管理与组织的好坏影响到整机效率。主要因为冯·诺伊曼体系结构是建筑在“存储程序”概念基础上，访存操作约占中央处理器70%左右的时间。

#### 3、存在的问题

* 存储器的存取速度在不断提高，但相比较而言，主存增速与CPU增速不同步。
* 指令执行期间多次访问存储器。频繁的存储器访问，导致占用大量的CPU运行时间。
* 主存储器（内存）存放当前正在执行的应用程序及数据，但难以同时满足存取速度快、存储容量大和成本低的要求。
* 在早期计算机系统中，程序员会直接对主存储器的物理地址进行操作，这种编程方式的缺陷是，当程序出现寻址错误时，可能会导致整个系统崩溃，一个进程出现寻址错误时也可能会导致另一个进程崩溃

### (二)虚拟存储器与地址映射

#### 1、虚拟存储器思想的诞生

* 问题：应用程序太大以至于内存容纳不下该程序、
	* 早期DOS操作系统的时候，程序规模不大，虽然内存容量小（以K为单位），但还是可以容纳当时的程序。但随着图形界面的兴起还有用户需求的不断增大，应用程序的规模也随之膨胀起来，终于一个难题出现在程序员的面前，那就是应用程序太大以至于内存容纳不下该程序。
* 简单的解决办法：
	* 通常解决的办法是把程序分割成许多称为覆盖块（overlay）的片段。覆盖块0首先运行，结束时它将调用另一个块1......→程序员要对代码进行分割
* 更好的解决办法：虚拟存储器(virtual memory)，简称虚存

#### 2、虚拟存储器基本思想

* 程序，数据，堆栈的总的大小可以超过物理存储器的大小，操作系统把当前使用的部分保留在内存，而把其他未被使用的部分保存在磁盘上。
* 例如一个16MB的程序和一个内存只有4MB的机器，操作系统通过选择，可以决定各个时刻将哪4MB的内容保留在内存中，并在需要时在内存和磁盘间交换程序片段，这样就可以把这个16M的程序运行在一个只具有4M内存机器上了。而这个16M的程序在运行前不必由程序员进行分割

<img src="/assets/images/存储器系统.assets/image-20200310131447780.png" alt="image-20200310131447780" style="zoom:67%;" />

#### 3、Cache与虚存的异同

* 相同点
	* 两者都有利于提高存储系统的性能。
	* 均基于程序局部性原理。一个程序运行时，只会用到程序和数据的一小部分，仅把这部分放到比较快速的存储器（内存）中，其他大部分放在速度低、价格低、容量大的存储器中
* 不同点
	* 在虚拟存储器中未命中的性能损失要远大于Cache系统中未命中的损失。因为主存和Cache的速度相差5~10倍，而外存和主存的速度相差上千倍
	* Cache主要解决主存与CPU的速度差异问题，而虚存主要解决内存容量问题。
	* CPU与Cache和主存之间均有直接访问通路，Cache不命中时可直接访问主存。而虚存所依赖的辅存与CPU之间不存在直接的数据通路，当主存不命中时只能通过调页解决，CPU最终还是要访问主存。
	* Cache的管理完全由硬件完成，对系统程序员和应用程序员均透明。而虚存管理由软件（操作系统）和硬件共同完成，虚存对实现存储管理的程序员是不透明的（段式和段页式管理对应用程序员”半透明“）。

#### 4、虚拟地址和物理地址

##### (1) 概念

* 任何计算机上都存在一个程序能够产生的地址集合，称之为地址范围。这个范围的大小由CPU的位数决定，例如一个32位的CPU，它的地址范围是0~0xFFFFFFFF (4G)。我们把这个地址范围称为虚拟地址空间，该空间中的某一个地址我们称之为虚拟地址。
* 与虚拟地址空间和虚拟地址相对应的则是物理地址空间和物理地址，例如，对于一台内存为256MB的32bit x86计算机而言，它的虚拟地址空间范围是0\~0xFFFFFFFF(4GB)，而物理地址空间范围是0x000000000\~0x0FFFFFFF（256MB）。
* 在没有使用虚拟存储器的机器上，虚拟地址被直接送到内存地址总线上，使具有相同地址的物理存储器被读写。

##### (2) 虚拟地址与物理地址之间需要映射

* 在使用了虚拟存储器的情况下，虚拟地址不是被直接送到内存地址总线上，而是送到内存管理单元MMU。MMU由一个或一组芯片组成，其功能是把虚拟地址映射为物理地址。
* MMU是一种负责处理CPU内存访问请求的计算机硬件。它的功能包括虚拟地址到物理地址的转换、内存保护、CPU高速缓存控制等。

<img src="/assets/images/存储器系统.assets/image-20200310131859347.png" alt="image-20200310131859347" style="zoom:50%;" />

##### (3) 虚拟存储器地址映射方式

* 虚拟存储器利用大容量的外存来扩充内存，产生一个比实际内存空间大得多的、逻辑的虚拟内存空间，简称虚存。
	* 例如，Windows操作系统下，虚拟内存在硬盘上就是为一个很大的隐藏文件文件，文件名是PageFile.Sys。虚拟内存有时候也被称为是“页面文件”就是从这个文件的文件名中来的。
* 一般情况下，程序代码是保存在虚存。但是当代码需要运行的时候就必须将其装入内存，要将虚存地址以一定的规则转换成物理地址。
* 虚存的地址变换，分三种：段式，页式，段页式。

#### 5、段式虚拟存储器

* 段式存储管理是一种把主存按段分配的存储管理方式，主存与辅存间信息传送单位是**不定长**的段
	* 段：按照程序的自然分界划分的长度可以动态改变的区域。通常可把子程序、操作数和常数等不同类型的数据划分到不同的段中，并且每个程序可以有多个相同类型的段

<img src="/assets/images/存储器系统.assets/image-20200310132342433.png" alt="image-20200310132342433" style="zoom:50%;" />

* **地址变换**

	* 多用户虚地址是由用户号U，段号S，和段内偏移地址D组成。
	* 虚地址和物理地址之间通过段表（存放于主存储器）来映射，CPU中会有一个段表基址寄存器，段表记录段号、段长、起始地址，从基址寄存器能够直接读出段表的起始地址。通过用户号U查找到对应的基址寄存器，基址寄存器的起始地址加上虚地址的段号，就能找到段表地址A~s~。
	* 如果所访问的段在内存中，则从段表中给出的起始地址，加上虚地址的偏移量，则得到物理地址（主存实地址）。

	<img src="/assets/images/存储器系统.assets/image-20200310132450491.png" alt="image-20200310132450491" style="zoom:67%;" />

* 段式存储管理的优点

	* 段的分界与程序的自然分界相对应，使得段易于编译、管理、修改和保护，也便于多道程序共享。

* 段式存储管理的缺点

	* 容易在段间留下许多空余的存储空间碎片。段式存储管理还存在交换性能较低的问题。因为辅存的访问速度比主存慢得多，而每一次交换，都需要把一大段连续的内存数据写到硬盘上，导致了当内存交换一个较大的段时，会让机器显得卡顿

#### 6、页式虚拟存储器

* 页式存储管理是一种把主存按页分配的存储管理方式，主存与辅存间信息传送单位是**定长**的页

<img src="/assets/images/存储器系统.assets/image-20200310132704289.png" alt="image-20200310132704289" style="zoom:67%;" />

* **地址映射过程**

	* 将一个进程的地址空间划分成若干个大小相等的区域（页）。
	* 对应地主存空间划分成与页同样大小的若干个物理块。
	* 在为进程分配主存时，将进程中若干个页分别装入多个不相邻的块中。

* **页式虚拟存储器的地址转换**

	* 用户虚地址，由用户号U，虚页号P，和页内偏移地址D组成。
	* 页表用来记录页号和主存页号。CPU中的基址寄存器存放页表的基地址。和段表一样，用户号U会通过基址寄存器找到页表起始地址，起始地址与虚页号相加，再与偏移地址拼接就得到物理实地址。
	* 页的大小一样，故它在虚地址中某一页的偏移量和主存中某一页的偏移量相同。

	<img src="/assets/images/存储器系统.assets/image-20200310132826833.png" alt="image-20200310132826833" style="zoom:67%;" />

* 页式虚拟存储器的特点

	* 对比段式虚拟存储，管理的粒度更细，所以造成内存页碎片浪费也会小很多。
	* 但页不是程序独立模块对应的逻辑实体，处理、保护和共享都不如段方便。
	* 页要比段小得多，如Linux操作系统采用页式存储管理，页的默认设置为4KB，所以页在进行交换时，相比段交换卡顿有所缓解。
	* 加载程序的时候，无需一次性把程序加载到内存，而是在程序运行中需要用到的对应虚拟内存页里面的指令和数据时，再加载到内存中，由操作系统完成。
	* 当CPU要读取特定的页，但却发现页的内容没有加载时，就会触发一个来自CPU的缺页错误（Page Fault）。操作系统会捕获这个错误，然后找到对应的页并加载到内存中。通过这种方式，使得可以运行那些远大于实际物理内存的程序，但相对的执行效率也会有所下降。

#### 7、段页式虚拟存储器

* 段页式虚拟存储器，**先将用户程序按程序的逻辑关系分为若干个段，并为每一个段赋予一个段名，再将每一个段划分成若干页，以页为单位离散分配**。

* 段页式虚拟存储器充分利用段式和页式两种虚拟存储器在管理主存和辅存空间的优点，提高了主存利用率。

	<img src="/assets/images/存储器系统.assets/image-20200310133013886.png" alt="image-20200310133013886" style="zoom:67%;" />

* 地址转换

	* 虚地址，由用户号U，段号S，虚页号P，页内偏移D组成。
	* 段表，记录页表长度和页表地址。
	* 先通过U在段表基址寄存器中找到段表基地址，然后和段号S相加，得到页表起始地址和页表长度，通过页表找到主存实页号再与偏移量拼接，得到物理地址。
	* 如果要访问的地址不在内存中，就会需要调入一页或一段到主存中。

	<img src="/assets/images/存储器系统.assets/image-20200310140127413.png" alt="image-20200310140127413" style="zoom:67%;" />

## 五、高速缓冲存储器Cache

### (一) 高速缓冲存储器Cache的原理

#### 1、采用高速缓冲存储器Cache的原因

* 在CPU的所有操作中，存储器的存取访问是最频繁的操作。
	* CPU的运行速度比大容量DRAM存储器的存取速度高得多。高端CPU时钟频率已超5GHz，指令执行时间远小于1ns。
	* 内存访问速度虽达ns级，如SDRAM为6~10ns，但与CPU有明显差距。
* 存储器的访问速度低是制约计算机系统性能的关键因素。

#### 2、CPU与DRAM的发展现状

CPU和主存储器的速度总是有差距，CPU的发展一直是提高速度为核心目标；主存的发展则一直以提高容量为核心目标。

<img src="/assets/images/存储器系统.assets/image-20200310140747608.png" alt="image-20200310140747608" style="zoom:50%;" />

#### 3、程序访问的局部性原理

* 程序在一定时间段内通常只访问较小的地址空间

	<img src="/assets/images/存储器系统.assets/image-20200310140827251.png" alt="image-20200310140827251" style="zoom:50%;" />

* 两种局部性：时间局部性和空间局部性

	* 时间局部性：最近访问的信息很可能再次被访问
	* 空间局部性：最近访问信息的邻近信息可能被访问

#### 4、在主存和CPU之间设置Cache

* 思想：根据程序访问的时空局部性，把经常访问的代码和数据保存到高速缓冲存储器（Cache)中，把不常访问的代码和数据保存到大容量的相对低速DRAM中，尽量减少CPU访问DRAM的概率，在保证系统性能的前提下，降低存储器系统的实现代价。
* 实现：Cache设置在CPU与主存储器之间，通常采用存取速度快并且无需刷新的SRAM来实现。
	* 根据时间局部性：将最近被访问的信息项装入到Cache中；
	* 根据空间局部性：将最近被访问的信息项的邻近信息也装入到Cache中。
* 在主存和CPU之间设置了Cache之后，如果当前正在执行的程序和数据存放在Cache中，则当程序运行时不必再从主存储器读取指令和数据，而只需访问Cache即可。

#### 5、Cache的基本运行原理

* 当CPU访问主存时，给出的地址同时送往Cache。首先检查Cache，如果要访问的数据已经在Cache中，则CPU就能很快完成访问，这种情况称为Cache“命中”（Cache hit）。
	$$
	命中率=\frac{命中次数}{访问次数（即总线周期数）}\times 100 \%
	$$

* 否则，CPU就必须从主存中提取数据，称为Cache“未命中”（Cache miss）。

* 如果组织的好，那么程序所用的大部分的数据都可在Cache中找到。Cache的“命中率”（hit rate）和Cache的容量大小、控制算法和组织方式等有关，当然还和所运行的程序有关。

* Cache的“命中率”通常应在90%以上。某些组织较好的Cache系统，命中率可达95%（例如早期IBM 360可达99%）。

#### 6、Cache的组织方式

* Cache的基本单元称为行或区块（Line，Cache line），其中包括：
	* 数据字段：保存从主存单元复制过来的数据，单位是（区）块。每个区块的大小为4~128字节，典型的Cache line通常的大小为**32**或**64**字节。
	* 标志字段：保存数据字段在主存中的地址信息，又称为地址标记寄存器，记为Tag。
	* 有效位字段：标识区块和Tag是否有效。
* 在Cache系统中，主存是以区块为单位映象到Cache中。以CPU读取一个字节的数据为例，如果所需字节不在Cache中，在CPU从内存中读取数据的同时，Cache控制器将把该字节所在的整个区块从主存复制到Cache。

#### 7、Cache的管理

* 主存和Cache都会采用分Cache Line（也称字块）的方式进行管理，Cache中保存的就是对应的主存字块的一个副本。每一个Cache字块都会有一个标记位，用于表示当前字块里存放的是哪一个内存字块的副本。通过这个标记位，CPU就可以判断出希望访问的内存字块是否已经存在于Cache中。
* 当Cache已经用满，但主存还需将新的字块调入Cache时，就会执行一次Cache字块的替换。这种替换应遵守一定的规则，最好使得被替换的字块是下一个时间段内估计最少使用的。这种规则称为**替换策略或替换算法**，由替换部件实现。
* 当程序对Cache字块执行写入时，如何保证Cache字块和内存字块的一致性。通常的有两种写入方式：一个是**先写Cache字块，待Cache字块被替换出去时再一次性写入内存字块**；再一个是**在写Cache字块的同时也写入内存字块**。

#### 8、Cache管理的基本问题

* Cache中存放近期需要重复运行的指令数据，形成主存储器内容的副本。CPU首先从副本中读取数据，只有Cache中没有所需的数据时或Cache中已满时，才直接访问内存。从而提高CPU对存储器的访问速度。
* Cache和主存储器一起构成一级存储器。高速缓冲存储器和主存储器之间信息的调度和传送由硬件自动进行。
* 高速缓冲存储器Cache，需要解决两个问题：一是主存地址与缓存地址的映像及转换；二是按一定原则对Cache的内容进行替换。
	* 依靠专门的硬件实现，Cache对CPU和程序员而言是透明的

### (二) 高速缓冲存储器Cache的基本结构

#### 1、计算机的Cache系统基本组成

三个组成部分：

* Cache模块（SRAM）
* 主存（DRAM）
* Cache控制器

<img src="/assets/images/存储器系统.assets/image-20200310153543372.png" alt="image-20200310153543372" style="zoom:50%;" />

#### 2、Cache的基本结构

* Cache由Cache Tag、Tag存储体和Cache控制器三部分组成。
	* **Cache Tag**主要用来记录Cache存储体中数据的位置，判断Cache内数据是否命中。
	* **Cache存储体**主要用来存储片外数据，方便处理器直接调用。
	* **Cache控制器**由主存地址寄存器、Cache地址寄存器，主存-Cache地址变换部件及替换控制部件等四部件组成。Cache控制器控制整个Cache的具体工作，决定了Cache的工作效率。

<img src="/assets/images/存储器系统.assets/image-20200310153707998.png" alt="image-20200310153707998" style="zoom: 67%;" />

#### 3、Cache控制器的主要部件

* **主存地址寄存器**，存放主存的页号、块号、字号或者块内偏移地址等信息，具体包括哪些信息决定于所采用的地址映射方式。
* **Cache地址寄存器**，存放所要映射的Cache的页号、块号、字号或者块内偏移地址等信息，具体包括哪些信息决定于所采用的地址映射方式。
* **地址变换部件**，建立目录表以实现主存地址到缓存地址的转换。
* **替换控制部件**，在缓存已满时按一定策略进行数据块替换，并修改地址变换部件。
* 注意：地址寄存器中存放的信息不是直接地址，要得到地址信息必须通过地址变换部件按地址映射方式进行变换。

#### 4、Cache控制器的控制行为

* Cache控制器控制主存和Cache间的数据传输
	* CPU发出数据读（写）请求后，Cache控制器先将这个请求转向Cache存储器。
	* 若数据在Cache中，就对Cache进行读（写）操作，称为一次**命中**。
	* 若不在Cache中，CPU就对主存操作，称为一次**脱靶**，这时CPU必须在其总线周期中插入等待周期Tw。
* Cache控制的特点
	* Cache对于CPU和用户程序都是透明的，即CPU和程序不知道它的存在
	* 主存-Cache地址变换部件，以判断CPU要寻访的数据是否在Cache中。
	* 主要包含一个相联存储器，能在Cache控制器管理下，按照一定的地址映射关系，动态地在其中构建起一个表格，将Cache中的一个存储块与主存中的若干个存储块对应起来。

#### 5、影响命中率的因素

影响命中率的因素：Cache容量、存储单元组数目和组大小、地址映射方案、联想比较策略、数据替换算法、写操作处理方法、程序本身特性等。

* 命中率计算

	* 命中率的计算方法

	$$
	h=N_c/(N_c+N_m)
	$$

	* $N_c$和$N_m$是对Cache和主存的存取次数，只有$N_c$足够大，才有$h→1$

	* $(1-h)$为丢失率（MissRate），访问信息不在Cache中的比率
	* 没有命中的数据，CPU只好从内存获取，并把该数据所在的数据块调入Cache，使以后对整块数据的读写都从Cache中进行，不必再调用内存。

### (三) 地址映射与转换

* 地址映射（或称映像）：主存单元的数据在被复制到Cache中的同时，该主存单元的地址，在经过某种函数关系处理后也被写进Tag，这一过程被称为Cache的地址映像。
* 地址变换：CPU读写数据时，把访问主存地址变换为访问Cache的地址，这一过程被叫做Cache的地址变换。再根据地址变换结果对Cache进行检查。
* Cache与主存都分成块(Cacheline)，每块由多个字节组成，大小相等。在一个时间段内，Cache的某块中放着主存某块的全部信息，即Cache的某一块是主存某块的副本(或叫映像)。
* 按照主存和Cache之间的映像关系，Cache的组织方式分为以下几种：
	* 全相联映像（Fully associative mapping ）：完全随意的对应。
	* 直接映像（Direct mapping）；一对多的硬性对应。
	* 多路组相联映像（Multi-way set associative mapping）:多对多有限随意对应

#### 1、全相联映射方式

<img src="/assets/images/存储器系统.assets/image-20200310154455649.png" alt="image-20200310154455649" style="zoom: 67%;" />

* 全相联映射方式（Fully Associative ）：主存中任意一个块都可以映射到Cache中任意一个块。设Cache共有$2^C$块，主存共有$2^M$块，当主存的某一块j需调进Cache中时，它可以存入Cache的块0、块1、...、块i、...或块$2^C-1$的任意一块上。

##### (1) 地址变换

<img src="/assets/images/存储器系统.assets/image-20200310154623610.png" alt="image-20200310154623610" style="zoom: 67%;" />

* 主存地址到Cache地址的转换是通过查找块表完成
* CPU的访主存地址：M为主存的块号，W为块内的字号
* CPU访Cache的地址：C为Cache的块号，W为块内的字号
* 当一个主存块调入Cache中时，会在一个存储主存块号M~j~和Cache块号C~i~映射关系的块表中进行登记。 CPU访问内存时，
	* 根据主存地址中的主存块号M~j~在块表中查找Cache块号C~i~
	* 若找到，则本次访Cache命中，于是将对应的Cache块号C~i~取出
	* 并与块内字号W一起形成一个访Cache的地址
	* 最后根据该地址完成对Cache单元的访问

##### (2) 特点

* 大多数程序运行时需要访问位于主存不同位置的数据，在全相联映像方式中，主存中的区块可以映像到Cache的任意位置，因此Cache的利用率高。
* 在这种方式中，Cache中区块的位置与在内存的位置没有任何关系。每个区块在主存中的地址需要在Tag中保存。CPU访问主存时，Cache控制器对访问主存的地址与Tag中的地址逐一进行比较，匹配成功才算命中。
* 为保证比较的时效性，若Cache中共有N个区块，则需要有N个比较电路同时并行比较。此外，若主存有2^m^个区块，则有m位区块地址，Tag较长，不仅造成Cache的实际利用率较低，并且比较电路的实现代价太高。
* 优点：Cache存储空间利用率高，不易产生冲突，命中率比较高。
* 缺点：比较和替换策略都需要硬件实现，电路复杂，只适用于小容量Cache。访问相关存储器时，每次都要与全部内容比较，速度低，成本高。因而应用少。

#### 2、直接相联映射

<img src="/assets/images/存储器系统.assets/image-20200310155145543.png" alt="image-20200310155145543" style="zoom:67%;" />

* 直接相联映射(Direct-Mapped)方式是将主存空间按照Cache的大小划分为若干页，也称为区，页内分块。主存储器中一块只能映射到Cache的一个特定的块中。
	* 主存的某块j只能映射到满足如下特定关系的Cache块i中：$i＝j\mod2^C$。
	* 例如，主存的第0、2^C^、2^C＋1^、...块只能映射到Cache的第0块，主存的第1、2^C^+1、2^C＋1^+1、...块只能映射到Cache的第1块，......，主存的第2^C^-1、2^C＋1^-1、...2^M^-1块只能映射到Cache的第2^C^-1块。

##### (1) 地址变换

<img src="/assets/images/存储器系统.assets/image-20200310155351275.png" alt="image-20200310155351275" style="zoom:67%;" />

* CPU的访主存地址为如下形式：T为标志号，C为Cache的块号，W为块内的字号。在这里，原主存的块号M实际上被分成了两个字段：T和C，其中C用于指出主存的块可以映射的Cache的块（即对2^C^求余后的余数部分），而对于余数相同的不同的主存块来讲，整除2^C^后的商（即T）部分则不相同。在直接相联映射方式下，标志号T是随Cache的每个块一起存储的。
* CPU送来一个访存地址时
	* 根据该主存地址的C字段找到Cache的相应块
	* 然后将该块标志字段中存放的标志与主存地址的T标志进行比较
	* 若相符，说明主存的块目前已调入该Cache块中，则命中
	* 根据主存地址的W字段合成Cache地址
	* 访问该Cache块的相应单元。若不相符，未命中，使用主存地址直接访主存。

##### (2) 特点

* 直接映象是一种最简单的地址映像方式，其思想是：按照Cache的大小，将主存也分为同样尺寸的若干“页”。主存中位于不同页但是偏移量相同的数据在调往Cache时，只能存放在Cache中具有同样偏移量的位置，Tag只需记录区块在主存的页号。（访问连续地址空间的数据会怎样？）
* 但是，当程序访问不同页但具有相同偏移量的数据时，将不可避免地产生冲突。此时，即使Cache中有其它空闲块，也因为固定的地址映像关系而无法应用。
* 优点：地址映射方式简单，数据访问时，只需检查页号是否相等即可，因而可以得到比较快的访问速度，硬件设备简单。
* 缺点：替换操作频繁。主存每个块在Cache中只有一个对应位置，若另一个块也要调入该位置，将会发生冲突，即使Cache的其它块位置空闲，也不能接受它，导致命中率低。

#### 3、组相联映射（最常见的方式）

* 组相联映射(Set-Associative)方式：Cache划分成大小相等的组，将总块数为2C的Cache分成$2^u$组，每组$2^v$块。主存容量是Cache容量的整数倍，将总块数为$2^M$的主存划分为$2^s$页，每页$2^u$块，即主存每页的大小与Cache的组数相等。
* 主存的块与Cache的组之间采用直接相联映射，而与组内的各块则采用全相联映射。也就是说，主存的某块只能映射到Cache的特定组中的任意一块。主存的某块j与Cache的组k之间满足关系：$k＝j \mod 2^u$
* 例：8-entry cache采用2-Way Set-Associative方式，将8个Cache分成了2组，每组有4个Cache Line

<img src="/assets/images/存储器系统.assets/image-20200310220818427.png" alt="image-20200310220818427" style="zoom:67%;" />

##### (1) 地址变换

* 主存划分为2^s^页，每页2^u^块，Cache分成2^u^组，每组包含2^v^块
	* s为主存的页号，u为页内的块号，w是块内地址
	* u为Cache的组号，v为组内的块号，w是块内地址
* Cache的块号C＝u+v，而主存的块号M＝s+u。
* 主存块被调入Cache时，同时将其地址的前s位写入块表的s字段。
* CPU访问存储器时
	* 根据主存地址中的u字段，找到块表对应的组
	* 然后将该组的所有项的前s位，与主存的s字段比较
	* 若相符，则表明主存块在Cache中，则将该项的v字段取出
	* 再取出主存地址w字段
	* u+v+w形成Cache地址

<img src="/assets/images/存储器系统.assets/image-20200310221005426.png" alt="image-20200310221005426" style="zoom:67%;" />

##### (2) 特点

* 又称为成组相联映像方式，是以上两种方式的一种折衷方案。主存和Cache之间，既不是硬性的多对一对应，也不是完全的随意对应，而是采用了一种有限度的随意对应
* 该方案将Cache进行分组（路），例如分成2组或4组。每组采用直接映像方式，以减少比较电路的成本；组与组之间为全相连映像方式，以避免区块位置的冲突。用多组Cache并行提供高速缓存功能
* CPU访问内存时，Cache控制器经过两次比较，判断是否命中。这种方式集中了以上两种方式的优点，因此得到了广泛应用
* 优点：块冲突概率比较低，块利用率大幅度提高，块失效率明显降低
* 缺点：实现难度和造价要比直接映射方式高

### (四) Cache更新与替换策略

#### 1、读取结构

* 贯穿读出（Look Through）
	* 该方式将Cache隔在CPU与主存之间
	* CPU对主存的所有数据请求都首先送到Cache，由Cache在其中查找
	* 如果命中，则切断CPU对主存的请求，并将数据送出
	* 不命中，则将数据请求传给主存
	* 优点：降低了CPU对主存的请求次数
	* 缺点：延迟了CPU对主存的访问时间
* 旁路读出（Look Aside）
	* CPU同时向Cache和主存发出数据请求
	* 由于Cache速度更快，如果命中，则Cache在将数据回送给CPU的同时，还来得及中断CPU对主存的请求
	* 不命中，则Cache不做任何动作，由CPU直接访问主存
	* 优点：没有时间延迟
	* 缺点：每次CPU都存在主存访问，从而占用一部分总线时间

#### 2、写入更新策略

* 当CPU对Cache数据做了修改后，应修改主存相应位置内容
* 写通方式（Write Through）
	* 从CPU发出的写信号送到Cache的同时，也写入主存，保证主存的数据能同步更新
	* 优点：操作简单，较好地保持了Cache与主存内容的一致性，可靠性高
	* 缺点：由于主存的慢速，降低了写速度并占用了总线时间，没有发挥Cache高速访问优势
* 写回方式（Write Back）
	* 更新数据只写到Cache，而主存中的数据不变
	* 在Cache中设置“修改标志位”，Cache中有被修改的数据时，该标志位置“1”
	* 每次Cache有数据更新时，判断该标志位。只有该标志位为1，即Cache中的数据被再次更改而需要换出时，才将原更新的数据写入主存相应的单元中，然后再接受再次更新的数据
	* 优点：克服了写通方式写速度低的问题，有利于提高CPU执行效率
	* 缺点：有Cache与主存数据不一致的隐患，控制也较复杂。

#### 3、替换策略

Cache一个块对应主存多个块，块大小相同。主存数据块装入Cache时，如果相应位置被其他块占用，则必须替换掉旧块，以新块填充。替换策略如下：

* 随机（Random）替换策略
* 最不经常使用（Least Frequently Used，LFU）替换策略
* 先进先出（FIFO）替换策略
* 近期最少使用（Least Recently Used，LRU）替换策略

##### (1) 随机（Random）替换策略

* 随机确定需要替换的Cache块，不管Cache块过去、现在及将来的使用情况，而随机地选择某块进行替换
* 优点：方法最简单，易硬件实现，速度快
* 缺点：被换出的数据可能马上就需要再次使用，增加了映射装入次数，降低命中率和效率

##### (2) 最不经常使用（Least Frequently Used，LFU）替换策略

* 将一段时间内被访问次数最少的块替换出去。
* 每块设置一计数器，从0开始计数，每访问一次，被访块的计数器就增1。
* 需要替换时，将计数值最小的块换出，同时将所有块的计数器清零。
* 优点：方法较简单，较易硬件实现。
* 缺点：统计的是各块两次替换间的访问次数，不能严格反映近期被访问情况。新调入的块很容易被替换出去。

##### (3) 先进先出（FIFO）替换策略

* 根据进入Cache的先后次序来替换，先调入的Cache块被首先替换掉。
* 优点：不需要随时记录各个块的使用情况，容易实现，且系统开销小。
* 缺点：一些需要经常使用的程序块可能会被调入的新块替换掉。

##### (4) 近期最少使用（Least Recently Used，LRU）替换策略

* 将CPU近期最少使用的块作为被替换的块。
* 需要随时记录Cache中各块的使用情况，以便确定哪个块是近期最少使用的块。
* 为每个块设置一个“未访问次数计数器”。
* 每次Cache命中时，命中块的计数器清0，其它各块的计数器加1。
* 每当有新块调入时，将计数值最大的块替换出去。
* 优点：确保新加入的块保留，还可把频繁调用后不再需要的数据淘汰掉，提高Cache利用率和命中率。硬件实现并不困难。

### (五) 影响Cache性能的因素

#### 1、Cache脱靶的原因

* 分块太小
	* 程序开始执行时，主存块逐步复制进Cache，因此容易脱靶，需经过一段时间后Cache才装满。首次执行产生脱靶的次数，与分块大小有关，块越大，不命中次数就越小
* 容量太小
	* 不能将所需指令和数据都调入Cache，因此频繁的替换，导致CPU访问慢速主存次数增多
* 替换进Cache的主存块过大或过多
	* 替换进Cache的主存块数目太多，会把下次要访问的指令或数据替换出去
	* 数据块太大，替换所传数据量越大
	* Cache所含块数减少，少数块刚装入就被覆盖掉

#### 2、提高Cache性能的几种方法

* **增大Cache容量**来降低不命中率
	* Cache太小致命中率太低，过大改善不明显。一般选Cache与内存容量比4：1000，命中率90％以上。每块取4～8字节（或字）较好。
* 通过**结构设计**减少不命中次数
	* 指令、数据分开存储，存取比例不一样，可将两类Cache分开，并采用二级、三级Cache结构。
* 通过**预取技术**提高命中率
	* 预测将要访问的指令和数据，提前将下条要执行指令取入Cache，提高CPU取指令的速度。

## 六、存储器系统设计

### (一) 主存储器系统设计技术

* CPU总线的负载能力
	* CPU通过总线直接驱动负载的能力有限，应根据需要连接的存储器芯片参数，考虑在总线上增加缓冲器或驱动器，增大CPU的负载能力。
* CPU时序与存储器存取速度间的配合
	* CPU要对存储器频繁读/写，选芯片时要考虑其存取速度能否与CPU读/写时序匹配。
* 存储器的地址分配和片选
	* 需要为存储器分配地址范围。由于每块芯片存储容量有限，一个存储器系统可能是由多块芯片组成，要重点考虑容量的扩充方案和片选信号的形成。
* 控制信号的连接
	* CPU提供的存储器控制信号，如CS#、OE#、WE#等，应与存储器的相关引脚正确连接，才能实现读/写等控制功能。

### (二) 存储器系统扩展方式

#### 1、位扩展

<img src="/assets/images/存储器系统.assets/image-20200310223259606.png" alt="image-20200310223259606" style="zoom: 80%;" />

举例：1M×1位的芯片扩展为1M×8位的RAM并与CPU总线连接

* 每个芯片数据线分别连接数据总线D~7~~D~0~的不同位，以形成8位数据
* 各芯片的地址线A~19~~A~0~与CPU地址总线对应地址线并联
* 读写控制线R/W#与CPU读写控制线分别并联连接，CPU的片选控制线CS#与各芯片的CS#并联

#### 2、字扩展

<img src="/assets/images/存储器系统.assets/image-20200310223455820.png" alt="image-20200310223455820" style="zoom: 80%;" />

举例：存储器芯片为256K×8位，采用4片进行字扩展为1M×8位的RAM，并与CPU总线连接

* 每个芯片的各位数据线分别与数据总线D~7~~D~0~位并联；
* 各芯片低位地址线A~17~~A~0~与CPU地址总线对应地址线并联；
* 高位地址线A~19~、A~18~通过2线-4线译码器分别产生不同的译码输出信号控制每个存储器芯片的片选端CS#；
* 各芯片的读写控制线R/W#与CPU读写控制线分别并联连接。

#### 3、复合扩展

* 在位长和字数均不足时，采用复合扩展方式。
* 举例：如将256K×1位的芯片扩展为1M×8位的存储器系统。
	* 先进行位扩展，用8片256K×1位芯片进行位扩展，构成256K×8位的存储器；再将位扩展后的存储器作为整体进行字扩展，用4个256K×8位的存储器，从而构成1M×8位的存储器系统

### (三) 嵌入式存储器系统设计

* 嵌入式系统存储结构特点
	* 嵌入式微处理器内置小容量NOR Flash闪存和小容量的SRAM。
* 嵌入式系统的存储器扩展
	* 通过不同的总线接口，连接大容量的NAND Flash、DRAM、SD、eMMC、TF等存储器。
	* 嵌入式微处理器内置的存储器容量有限，在内置存储器存储容量不足时，可外部扩展SRAM或者DRAM

#### 1、NOR Flash闪存的存储器扩展设计

<img src="/assets/images/存储器系统.assets/image-20200310224339106.png" alt="image-20200310224339106" style="zoom:67%;" />

* HY29LV160 NOR Flash芯片
	* 地址线20根，共1M=220个存储单元
	* 每个存储单元16位
	* 容量2MB=16Mbits
	* 地址线A[19:0] →ARM A[20:1]
	* 数据线DQ[15:0]
	* 控制线OE#、WE#、CE#
	* BYTE# = 1表示工作在字模式
	* RY/BY#指示编程或擦除的状态

* ARM微处理器对NOR Flash的访问不需要其他任何软件的设置，系统在上电复位后，从NOR Flash的0X0地址开始执行第1条指令，即开始执行NOR Flash存储器的启动代码

#### 2、NAND Flash闪存的存储器接口设计

* NAND Flash与嵌入式微处理器的连接，通过NAND Flash控制器实现
	* ARM微处理器集成的NAND Flash控制器的内部结构方框图，如图1所示
	* NAND Flash K9F2808U0A与ARM嵌入式微处理器的接口电路，如图2所示
* NAND Flash 是以存储外设方式存在，故ARM微处理器对NAND Flash的访问，是通过NAND Flash控制器接口进行

![image-20200310224858264](/assets/images/存储器系统.assets/image-20200310224858264.png)

##### 3、SDRAM的存储器扩展设计

* SDRAM作为同步动态存储器，是利用同一个时钟信号同步控制DRAM的地址、数据和控制信号。从而保持SDRAM的时钟频率与系统前端时钟频率，保证CPU对存储器的访问速度与处理速度一致。

* 嵌入式系统采用SDRAM或者SRAM作为系统的主存储器器，用于保存程序运行过程中的实时数据或者存储从外存装入的程序或数据。

* 在SDRAM与ARM微处理器进行电路连接时，要根据实际，对扩展主存容量、芯片粒数、单元数、芯片位宽与Bank之间的关系进行配置。

* 表为ARM微处理器SDRAM控制器Bank地址配置

	<img src="/assets/images/存储器系统.assets/image-20200310225019610.png" alt="image-20200310225019610" style="zoom:67%;" />

* HY57V561620T SDRAM的引脚定义

![image-20200310225109482](/assets/images/存储器系统.assets/image-20200310225109482.png)

* 图为ARM微处理器与HY57V561620T SDRAM的连接示意图
* HY57V561620T的存储器组织为4M×16位×4Banks，从而构成32MB的总存储容量

<img src="/assets/images/存储器系统.assets/image-20200310225138517.png" alt="image-20200310225138517" style="zoom:67%;" />