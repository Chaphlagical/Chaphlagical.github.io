[{"content":"1. 马尔可夫过程 1.1. 马尔可夫性质Markov Property 马尔可夫性质的特点：\n 当一个随机过程在给定现在状态及所有过去状态情况下，其未来状态的条件概率分布仅依赖于当前状态 在给定现在状态时，随机过程与过去状态（历史）是条件独立的  当一个状态$s_t$当且仅当满足：\n$$\nP[S_{t+1}|S_t]=P[S_{t+1}|S_1,\\cdots,S_t]\n$$\n时，称状态$s_t$具有马尔可夫性质\n 状态包含了关于历史的所有信息 一旦知道当前状态，过去的历史信息可以被完全抛弃 当前状态足以用来预计未来 能够用于简化问题的表达和求解，但提高了对信息全局性和充分性的要求  1.2. 状态转移矩阵Transition Matrix 对于一个马尔可夫状态$s$以及其继任状态$s'$，状态转移概率定义为：\n$$\n\\mathcal P_{ss'}=P[S_{t+1}=s'|S_t=s]\n$$\n状态转移矩阵$\\mathcal P$定义了所有状态$s$到所有继任状态$s'$的转移概率：\n$$\n\\mathcal P=\\begin{bmatrix}\n\\mathcal P_{11}\u0026amp;\\cdots\u0026amp;\\mathcal P_{1n}\\\\\n\\vdots\\\\\n\\mathcal P_{n1}\u0026amp;\\cdots\u0026amp;\\mathcal P_{nn}\n\\end{bmatrix}\n$$\n其中，矩阵的每一行之和为1，即:\n$$\n\\sum_{j=1}^n\\mathcal P_{ij}=1\n$$\n1.3. 马尔可夫过程Markov Process 马尔可夫过程是一个无记忆的随机过程，即随机状态序列$s_1,s_2,\\cdots$，且每个状态$s_i$均具有马尔可夫性质\n马尔可夫过程（马尔可夫链）可定义为一个元组$\u0026lt;\\mathcal S,\\mathcal P\u0026gt;$\n $\\mathcal S$为有限的状态集合 $\\mathcal P$为状态转移矩阵，即$\\mathcal P_{ss'}=P[S_{t+1}=s'|S_t=s]$  示例\n学生上课马尔可夫链\n状态集合可表示为：$\\mathcal S={Class1,Class 2,Class3,Pass,Pub,Facebook,Sleep}$\n状态转移矩阵可表示为：\n$$\n\\mathcal P=\n\\begin{bmatrix}\n\u0026amp;0.5\u0026amp;\u0026amp;\u0026amp;\u0026amp;0.5\u0026amp;\\\\\n\u0026amp;\u0026amp;0.8\u0026amp;\u0026amp;\u0026amp;\u0026amp;0.2\\\\\n\u0026amp;\u0026amp;\u0026amp;0.6\u0026amp;0.4\u0026amp;\u0026amp;\\\\\n0.2\u0026amp;0.4\u0026amp;0.4\u0026amp;\u0026amp;\u0026amp;\u0026amp;1.0\\\\\n0.1\u0026amp;\u0026amp;\u0026amp;\u0026amp;\u0026amp;0.9\u0026amp;\\\\\n\u0026amp;\u0026amp;\u0026amp;\u0026amp;\u0026amp;\u0026amp;1\n\\end{bmatrix}\n$$\n2. 马尔可夫奖励过程 2.1. 马尔可夫奖励过程Markov Reward Process(MRP) 马尔可夫奖励过程是一个带有价值的马尔可夫链，可以定义为一个元组$\u0026lt;\\mathcal S,\\mathcal P,\\mathcal R,\\gamma\u0026gt;$\n $\\mathcal S$为有限的状态集合 $\\mathcal P$为状态转移矩阵，即$\\mathcal P_{ss'}=P[S_{t+1}=s'|S_t=s]$ $\\mathrm R$为奖励函数，$\\mathrm R_s=E[R_{t+1}|S_t=s]$ $\\gamma$为折扣因子，$\\gamma\\in[0,1]$  示例\n2.2. 收获Return 从$t$时刻起的总折扣奖励为$G_t$，定义为：\n$$\nG_t=R_{t+1}+\\gamma R_{t+2}+\\cdots=\\sum_{k=0}^\\infty \\gamma^kR_{t+k+1}\n$$\n 折扣因子$\\gamma\\in [0,1]$为未来奖励在当前时刻的价值比例 获得的奖励$R$在$k+1$次时间步后的值为$\\gamma^kR$ 即时奖励会高于延迟奖励  $\\gamma$靠近0表示更倾向于当前的评估 $\\gamma$靠近1表示更侧重远期的效益    大部分马尔可夫奖励过程和马尔可夫决策过程具有折扣因子，原因如下：\n 更方便地在数学上进行奖励折扣 在循环的马尔可夫过程中避免无穷的收获 可能无法完全表达出未来情况的不确定性 如果奖励是经济上的，则即时奖励可能比延迟奖励更有用 动物/人类的行为表现出更倾向于即时奖励 有时候也可能使用非折扣的马尔可夫奖励过程，即$\\gamma =1$，比如当所有的序列都终止  示例：\n假设学生MRP中，$\\mathcal S=Class1$，且$\\gamma=0.5$，则有\n2.3. 价值函数Value Function 价值函数$v(s)$表示状态$s$的长期价值，定义为从状态$s$出发的收获期望：\n$$\nv(s)=E[G_t|S_t=s]\n$$\n示例\n当折扣因子$\\gamma=0.9$时\n2.4. 贝尔曼方程Bellman Equation 价值函数可以分解为两个部分：\n 即时奖励$R_{t+1}$ 继任状态的延时奖励$\\gamma v(S_{t+1})$  $$\n\\begin{align}\nv(s)\u0026amp;=E[G_t|S_t=s]\\\\\n\u0026amp;=E[R_{t+1}+\\gamma R_{t+2}+\\gamma^2R_{t+3}+\\cdots|S_t=s]\\\\\n\u0026amp;=E[R_{t+1}+\\gamma(R_{t+2}+\\gamma^R_{t+3}+\\cdots)|S_t=s]\\\\\n\u0026amp;=E[R_{t+1}+\\gamma G_{t+1})|S_t=s]\\\\\n\u0026amp;=E[R_{t+1}+\\gamma v(S_{t+1})|S_t=s]\n\\end{align}\n$$\n由状态转移关系：\n可以得到：\n$$\nv(s)=R_s+\\gamma\\sum_{s'\\in \\mathcal S}\\mathcal P_{ss'}v(s')\n$$\n对所有状态，可以将贝尔曼方程表示为矩阵形式：\n$$\n\\pmb v=\\pmb {\\mathcal R}+\\gamma\\pmb{\\mathcal P}\\pmb v\n$$\n其中$\\pmb v$表示所有状态的价值函数组成的列向量：\n$$\n\\begin{bmatrix}v(1)\\\\\\vdots\\\\v(n)\\end{bmatrix}=\n\\begin{bmatrix}R_1\\\\\\vdots\\\\R_2\\end{bmatrix}+\\gamma\n\\begin{bmatrix}\n\\mathcal P_{11}\u0026amp;\\cdots\u0026amp;\\mathcal P_{1n}\\\\\n\\vdots\\\\\n\\mathcal P_{n1}\u0026amp;\\cdots\u0026amp;\\mathcal P_{nn}\n\\end{bmatrix}\n\\begin{bmatrix}\nv(1)\\\\\n\\vdots\\\\\nv(n)\n\\end{bmatrix}\n$$\n贝尔曼方程的求解：\n  贝尔曼方程为一个线性方程组\n  通过直接法求解：\n$$\n\\pmb v = (\\pmb I-\\gamma\\pmb{\\mathcal P})^{-1}\\pmb{\\mathcal R}\n$$\n  对$n$个状态的计算复杂度为$O(n^3)$\n  只有对小规模的MRPs能够使用直接法求解\n  对大型MRPs有许多迭代求解的方法：\n 动态规划 蒙特卡洛方法 时序差分方法    示例\n3. 马尔可夫决策过程 3.1. 马尔可夫决策过程基本框架  特点  MDPs立足于Agent与环境的直接交互 只考虑离散时间，假设Agent与环境的交互过程可分解为一系列阶段，每个阶段均由“感知-决策-行动”构成 已知环境模型   MDPs问题归结为最优策略的求解问题：  将Agents的行动归结为策略的执行 将Agents的决策问题归结为求解最优策略 以“效用最大化”作为“最优”的基本标准   经典规划 vs. MDPs  行动效果确定 vs. 不确定 经典规划实际上假定环境是完全不可观察 经典规划是以达到目标状态为“成功”标准，没有其他区别；而 MDPs 以效用最大化为“成功”标准   一个经典规划问题可以描述为一个特殊的NOMDP问题，每个目标状态$s$上，定义一个“驻留行动”使得$\\mathcal P_{ss'}^a=1$  3.2. 马尔可夫决策过程Markov Decision Process(MDP) 马尔可夫决策过程是指具有决策的马尔可夫奖励过程，定义为一个元组$\u0026lt;\\mathcal S,\\mathcal A,\\mathcal P,\\mathcal R,\\gamma\u0026gt;$\n $\\mathcal S$为状态的有限集合 $\\mathcal A$为行动的有限集合 $\\mathcal P$为状态转移矩阵，$\\mathcal P_{ss'}^a=P[S_{t+1}=s'|S_t=s,A_t=a]$ $\\mathcal R$为奖励函数，$R_s^a=E[R_{t+1}|S_t=s,A_t=a]$ $\\gamma$为折扣因子，$\\gamma\\in[0,1]$  MDPs研究的主题是，给定一个MDP模型，如何求解最优策略，即期望回报最大的策略\n示例\n3.3. 策略Policy 策略$\\pi$定义为对给定状态$s$的行为概率分布：\n$$\n\\pi(a|s)=P[A_t=a|S_t=s]\n$$\n 一个策略充分定义了一个Agent的行为 MDP的策略依赖于当前状态，而非历史状态，即时不变的：$A_t\\sim \\pi(\\cdot|S_t),\\forall t\u0026gt;0$  对给定MDP：$\\mathcal M=\u0026lt;\\mathcal S,\\mathcal A,\\mathcal P,\\mathcal R,\\gamma\u0026gt;$，以及一个策略$\\pi$，则：\n  状态序列$S_1,S_2,\\cdots$是一个马尔可夫过程$\u0026lt;\\mathcal S,\\mathcal P^\\pi\u0026gt;$，且\n$$\n\\mathcal P_{s,s'}^\\pi=\\sum_{a\\in\\mathcal A}\\pi(a|s)\\mathcal P_{ss'}^a\n$$\n  状态与奖励序列$S_1,R_2,S_2,\\cdots$是一个马尔可夫奖励过程$\u0026lt;\\mathcal S,\\mathcal P^\\pi,\\mathcal R^\\pi,\\gamma\u0026gt;$\n$$\n\\begin{align}\n\\mathcal P_{s,s'}^\\pi\u0026amp;=\\sum_{a\\in\\mathcal A}\\pi(a|s)\\mathcal P_{ss'}^a\\\\\nR_s^\\pi\u0026amp;=\\sum_{a\\in\\mathcal A}\\pi(a|s)R_s^a\n\\end{align}\n$$\n  3.4. 价值函数Value Function MDP的状态-价值函数$v_\\pi(s)$为策略$\\pi$下从状态$s$出发的收获期望：\n$$\nv_\\pi(s)=E_\\pi[G_t|S_t=s]\n$$\n示例\nMDP的行动-价值函数$q_\\pi(s,a)$为在策略$\\pi$下，采用行动$a$时，从状态$s$出发的收获期望：\n$$\nq_\\pi(s,a)=E_\\pi[G_t|S_t=s,A_t=a]\n$$\n3.5. 贝尔曼方程Bellman Equation 价值函数可以分解为两个部分：\n 即时奖励 继任状态的延时奖励  状态-价值函数：\n$$\nv_\\pi(s)=E_\\pi[R_{t+1}+\\gamma v_\\pi(S_{t+1})|S_t=s]\n$$\n$$\nv_\\pi(s)=\\sum_{a\\in\\mathcal A}\\pi(a|s)q_\\pi(s,a)\n$$\n行动-价值函数：\n$$\nq_\\pi(s,a)=E_\\pi[R_{t+1}+\\gamma q_\\pi(S_{t+1},A_{t+1})|S_t=s,A_t=a]\n$$\n$$\nq_\\pi(s,a)=R_s^a+\\gamma\\sum_{s'\\in \\mathcal S}\\mathcal P_{ss'}^av_\\pi(s')\n$$\n联立有：\n$$\nv_\\pi(s)=\\sum_{a\\in\\mathcal A}\\pi(a|s)\\Big(R_s^a+\\gamma\\sum_{s'\\in \\mathcal S}\\mathcal P_{ss'}^av_\\pi(s')\\Big)\n$$\n$$\nq_\\pi(s,a)=R_s^a+\\gamma\\sum_{s'\\in \\mathcal S}\\mathcal P_{ss'}^a\\sum_{a'\\in\\mathcal A}\\pi(a'|s')q_\\pi(s',a')\n$$\n同样地，贝尔曼方程可以表示为矩阵形式：\n$$\n\\pmb v_\\pi=\\pmb{\\mathcal R}^\\pi+\\gamma\\mathcal{\\pmb P}^\\pi\\pmb v_\\pi\n$$\n其直接解为：\n$$\n\\pmb v_\\pi = (\\pmb I-\\gamma\\pmb{\\mathcal P}^\\pi)^{-1}\\pmb{\\mathcal R}^\\pi\n$$\n**示例**\n3.6. 最优价值函数Optimal Value Function 最优状态-价值函数$v_\\ast(s)$是指对于所有策略的最大价值函数：\n$$\nv_\\ast(s)=\\max_\\pi v_\\pi(s)\n$$\n最优行动-价值函数$q_\\ast(s,a)$是指对于所有策略的最大行动-价值函数：\n$$\nq_\\ast(s,a)=\\max_\\pi q_\\pi(s,a)\n$$\n 最优值函数表示MDP的最佳性能 求解MDP即求解MDP的最佳价值函数  示例\n3.7. 最优策略Optimal Policy 定义策略上的一个偏序关系：\n$$\n\\pi\\geq \\pi'\\ \\mathrm{if}\\ v_\\pi(s)\\geq v_{\\pi'}(s),\\ \\forall s\n$$\n对于任意的马尔科夫决策过程：\n 存在最优策略$\\pi_\\ast$，使得其由于其他所有策略，即$\\forall \\pi,\\pi_\\ast\\geq \\pi$ 所有最优策略会得到相应的最优价值函数$v_{\\pi_\\ast}=v_\\ast(s)$ 所有最优策略会得到相应的最优行动-价值函数$q_{\\pi_\\ast}(s,a)=q_\\ast(s,a)$  最优策略可以通过最大化$q_\\ast(s,a)$来寻找：\n$$\n\\pi_\\ast(a|s)=\n\\begin{cases}\n1\u0026amp;\\mathrm{if}\\ a=\\arg\\max\\limits_{a\\in\\mathcal A}q_\\ast(s,a)\\\\\n0\u0026amp;\\mathrm{otherwise}\n\\end{cases}\n$$\n 对任意的MDP，总有确定的最优策略 如果已知$q_\\ast(s,a)$，即可立即得到最优策略  示例\n3.8. 贝尔曼最优性方程Bellman Optimality Equation $$\nv_\\ast(s)=\\max_a q_\\ast(s,a)\n$$\n$$\nq_\\ast(s,a)=R_s^a+\\gamma\\sum_{s'\\in\\mathcal S}\\mathcal P_{ss'}^av_\\ast(s')\n$$\n$$\nv_\\ast(s)=\\max_a R_s^a+\\gamma\\sum_{s'\\in\\mathcal S}\\mathcal P_{ss'}^av_\\ast(s')\n$$\n$$\nq_\\ast(s,a)=R_s^a+\\gamma\\sum_{s'\\in\\mathcal S}\\mathcal P_{ss'}^a\\max_{a'}q_\\ast(s',a')\n$$\n示例\n贝尔曼最优性方程的求解：\n 贝尔曼最优性方程非线性 通常情况下无闭式解 许多迭代求解方法：  值迭代 策略迭代 Q-Learning Sarsa算法    值迭代算法\n借助于辅助$Q_t^a(s)$，在$s$执行$a$，然后执行$t-1$步的最优策略所产生的预期回报：\n  对所有状态$s$，初始化状态$v_0(s)=0$\n  给定一组$v_k(s)$的值，对所有的状态进行下列迭代更新：\n$$\nv_{k+1}(s)=\\max_a \\bigg(R_s^a+\\gamma\\sum_{s'\\in\\mathcal S}\\mathcal P_{ss'}^av_k(s')\\bigg)\n$$\n  不断重复步骤2直至收敛：\n$$\n|v_t(s)-v_{t-1}(s)|\u0026lt;\\epsilon,\\forall s\\in\\mathcal S\n$$\n   每一步值迭代的计算复杂度为$O(|A||S|^2)$ 根据不动点理论，算法将最终收敛到最优值，所需的迭代次数为$poly(|S|,|A|,1/(1-\\gamma))$ 本质上是一种动态规划方法  策略迭代算法\n  先给定初始策略$\\pi$，求解线性方程，计算出$\\pi$相应的价值函数$v_\\pi(s)$：\n$$\nv^a_\\pi(s)=R_s^{\\pi(s)}+\\gamma\\sum_{s'\\in \\mathcal S}\\mathcal P_{ss'}^av^a_\\pi(s')\n$$\n  基于计算出的价值函数$v_\\pi^a(s)$，按下式进行更新策略：\n$$\n\\pi(s)=\\arg\\max_a \\begin{Bmatrix}R_s^a+\\gamma\\sum_{s'\\in \\mathcal S}\\mathcal P_{ss'}^av^a_\\pi(s')\\end{Bmatrix}\n$$\n  重复步骤1、2直至收敛\n   策略迭代算法最终收敛到最优值  收敛到最优值所需的迭代不大于$|A|^{|S|}$（确定性策略的总数目）    3. 部分可观察马尔可夫决策过程 3.1. 部分可观察马尔可夫决策过程Partially Observable Markov Decision Process(POMDP) MDPs 刻画了行动的不确定性：事先不知道，事后知道；观察是确定的，知道行动的效果\n一般情况下，行动和观察都是不确定的——扩展到POMDP\n在 POMDP 问题中，“环境”被看成一个“黑箱”，一个状态是黑箱某个时期的内部情况，观察是这个黑箱的“输出”\n部分可观察马尔可夫决策过程是一个具有隐藏状态的MDP，可以用元组$\u0026lt;\\mathcal S,\\mathcal A,\\mathcal O,\\mathcal P,\\mathcal R,\\mathcal Z,\\gamma\u0026gt;$描述\n $\\mathcal S$为状态的有限集合 $\\mathcal A$为行动的有限集合 $\\mathcal O$为观察的有限集合 $\\mathcal P$为状态转移矩阵，$\\mathcal P_{ss'}^a=P[S_{t+1}=s'|S_t=s,A_t=a]$ $\\mathcal R$为奖励函数，$R_s^a=E[R_{t+1}|S_t=s,A_t=a]$ $\\mathcal Z$为观察函数，$\\mathcal Z_{s\u0026rsquo;o}^a=P[O_{t+1}=o|S_{t+1}=s',A_t=a]$ $\\gamma$为折扣因子$\\gamma\\in[0,1]$  3.2. 信念状态Belief States 定义历史$H_t$为关于行动、观察以及奖励的序列：\n$$\nH_t=A_0,O_1,R_1,\\cdots,A_{t-1},O_t,R_t\n$$\n定义信念状态集合$\\mathcal B(h)$是在历史$h$的条件下，状态的分布：\n$$\n\\mathcal B(h)=(P[S_t=s^1|H_t=h],\\cdots,P[S_t=s^n|H_t=h])\n$$\n假设$\\mathcal S={s_1,s_2,\\cdots,s_n}$，则$\\forall i:0\\leq b(s_i)\\leq 1$，有$\\sum_{i=1}^nb(s_i)=1$，$b=(b(s_1),\\cdots,b(s_n))$，则$b(s_i)$表示环境处于$s_i$状态的概率\n当$|\\mathcal S|$有穷的，$\\pi(\\mathcal S)$是无穷的\n给定一个POMDP模型，一个$b\\in\\mathcal B$，一个$a\\in\\mathcal A$和一个$o\\in\\mathcal O$，可以计算（估计）在$b$下执行$a$得到$o$时，环境处于状态$s'\\in\\mathcal S$的概率：\n$$\n\\begin{align}\nb'(s')\u0026amp;=P_r(s'|o,a,b)=\\frac{P_r(o|s',a,b)P_r(s'|a,b)}{P_r(o|a,b)}\\\\\n\u0026amp;=\\frac{P_r(o|s',a)\\sum_sP_r(s'|a,b,s)P_r(s|a,b)}{P_r(o|a,b)}\\\\\n\u0026amp;=\\frac{\\mathcal Z_{s\u0026rsquo;o}^a\\sum_s\\mathcal P_{ss'}^ab(s)}{P_r(o|a,b)}\n\\end{align}\n$$\n$b'$为$o,a,b$的函数，记为$b'=SE(b,a,o)$，称为状态估计函数\n对$b'(s')$的分母进行推导：\n$$\n\\begin{align}\nP_r(o|a,b)\u0026amp;=\\sum_{s'}\\mathcal Z_{s\u0026rsquo;o}^aP_r(s'|a,b)\\\\\n\u0026amp;=\\sum_{s'}\\mathcal Z_{s\u0026rsquo;o}^a\\sum_s\\mathcal P_{ss'}^ab(s)\n\\end{align}\n$$\n是给定$a$，$b$下出现$o$的平均概率\n  $b'(s')$的分子是$a$，$b$，$s'$下出现$o$的概率\n  $P_r(o|a,b)$是保证$\\sum_{s'}b'(s')=1$的正规化因子\n  $\\sum_s\\mathcal P_{ss'}^ab(s)=P_r(s'|a,b)$是不考虑观察而得到的下一状态为$s'$的概率，而$b'(s')$是考虑了观察$\\mathcal Z_{s\u0026rsquo;o}^a$所得出的下一个状态的概率，两者的关系：\n$$\nb'(s')=\\frac{\\mathcal Z_{s\u0026rsquo;o}^a}{P_r(o|a,b)}\\cdot P_r(s'|a,b)\n$$\n 若$\\mathcal Z_{s\u0026rsquo;o}^a\u0026gt;P_r(o|a,b)$，则$b'(s')\u0026gt;P_r(s'|a,b)$。在$s'$下出现$o$的概率，高于出现$o$的平均概率    $b'$包含了观察和模型的全部信息：\n 上一时刻的全部信息$b$ 模型信息$\\mathcal P$ 观察信息$\\mathcal Z_{s\u0026rsquo;o}^a$，$s'\\in \\mathcal S$    在POMDP问题中，$\\mathcal B$的作用相当于MDP中的$\\mathcal S$\n3.3. POMDPs的简化  历史$H_t$满足马尔可夫性质 信念状态$b(H_t)$满足马尔可夫性质   POMDP能够简化为一棵（无限）历史树 POMDP能够简化为一棵（无限）信念状态树  3.4. POMDP与MDP的比较与转化 3.4.1. MDP vs. POMDP 3.4.2. POMDP to MDP POMDPs中$\\mathcal B$的作用相当于MDP中的$\\mathcal S$，设法将一个POMDP模型问题转化为一个变形的MDP问题，使得相应的MDP模型为$\u0026lt;\\mathcal B,\\mathcal A,\\tau,\\rho,\\gamma\u0026gt;$，其中\n  $\\tau$为信念状态$b\\in\\mathcal B$的转移概率：\n$$\n\\begin{align}\n\\tau_{bb'}^a\u0026amp;=P_r(b'|b,a)\\\\\n\u0026amp;=\\sum_oP_r(b'|a,b,o)P_r(o|a,b)\n\\end{align}\n$$\n其中，\n$$\nP_r(b'|a,b,o)=\\begin{cases}\n1,\u0026amp;\\mathrm{if}\\ SE(b,a,o)=b'\\\\\n0,\u0026amp;\\mathrm{otherwise}\n\\end{cases}\n$$\n  $\\rho$为信念状态相应的奖励：\n$$\n\\rho_b^a=\\sum_sb_sR_s^a\n$$\n  由于$\\mathcal B$是无穷的，因此很难直接用值迭代法进行求解\n  3.5. POMDPs的策略表示  单步策略：$\\mathcal B\\rightarrow\\mathcal A$，多步策略：$\\pi=(\\pi_t,\\cdots,\\pi_1)$，但$\\mathcal B$是无穷的 策略树：一个$t$层策略树共有$t$层节点，根节点上标记代表第一个行动，它的分支代表执行该行动后得到的观察，是一种有穷表示  3.6. 价值函数 采用策略树表示，令$p$是一个$t$步策略树，$v_p(s)$是在$s$上执行$p$的预期效用：\n$$\n\\begin{align}\nv_p(s)\u0026amp;=R_s^{a(p)}+\\gamma v_{p'}(s')\\\\\n\u0026amp;=R_s^{a(p)}+\\gamma\\sum_{s'}P_r(s'|s,a(p))\\sum_{o_i}P_r(o_i|s',a(p))v_{o_i(p)}(s')\\\\\n\u0026amp;=R_s^{a(p)}+\\gamma\\sum_{s'}\\mathcal P_{ss'}^{a(p)}\\sum_{o_i}\\mathcal Z_{s\u0026rsquo;o_i}^{a(p)} v_{o_i(p)}(s')\n\\end{align}\n$$\n其中，$v_{p'}(s')$为后$t-1$步的预期效用，$o_i(p)$是$p$的由分支$o_i$引出的$t-1$步子树\n  对任意$b\\in\\mathcal B$，定义$v_p(b)=\\sum_sb(s)v_p(s)$为在$b$上执行$p$的预期效用\n  令$P_t$为所有$t$步策略树的集合，$P_t$有穷，$b$上最优$t$阶段效用定义为\n$$\nv_t(b)=\\max_{p\\in P_t}v_p(b)\n$$\n使$v_p(b)=v_t(b)$的$p$是$b$上的最佳策略\n  考虑在整个$\\mathcal B$上的最佳策略，一般要用策略树集来表示（因为$\\mathcal B$无穷，连续分布）\n  $P\\subseteq P_t$，满足$\\forall b\\in\\mathcal B$，$\\exists p\\in P$，使得$v_p(b)\\geq v_{p'}(b)$，$\\forall p'\\in P_t$\n  $|P_t|$是有穷的，\n$$\n|P_t|=|A|^{\\frac{|\\Omega|^t-1}{|\\Omega|-1}}=|A|^{|\\Omega|^{t-1}}\n$$\n  $\\mathcal S$是固定的、有穷的，$\\mathcal B$是无穷的\n  设$\\mathcal S={s_1,\\cdots,s_n}$，$b={b(s_1),\\cdots,b(s_n)}$，$0\\leq b(s_i)\\leq 1$，$\\sum_ib(s_i)=1$，\n$$\nv_p(b)=\\sum_sb(s)v_p(s)=b(s_1)v_p(s_1)+\\cdots+b(s_n)v_p(s_n)\n$$\n$v_p(b)$是$b(s_1),\\cdots,b(s_n)$的一个线性函数，$v_p(s_i)$与$b$无关\n  3.7. 最大期望效用函数  由所有$p\\in P_t$产生的$v_p(b)$的“上表面”可以得到$v_t(b)$，整个$\\mathcal B$上最优策略集合，以及每个最优策略的“最优区域”可用线性规划进行确定 对任意$|\\mathcal S|$，情况类似，$v_t(b)$是一个分块线性的凸函数    由$v_p(b)$构成“上表面”的所有$p$组合的集合（代表$v_t(b)$），称为最大期望效用函数/最佳价值函数$v_t(b)$的“最简表示”，记为$Pv_t$，每个$p\\in pV_t$是$\\mathcal B$的某个区域上的最优策略树，$p$的”最优区域“是\n$$\n{b\\in\\mathcal B|\\forall p'\\in Pv_t\\setminus{p},\\sum_sb(s)v_p(s)\u0026gt;\\sum_sb(s)v_{p'}(s) }\n$$\n可以由线性规划求出\n  $Pv_t$的任何真子集都无法表达$v_t(b)$，称为不完备的，与”上表面“有共同点的所有$p\\in P_t$的集合记为$P^+v_t$，称为”次简表示“\n $Pv_t\\subseteq P^+v_t$ $\\forall p\\in P^+v_t,\\exists b\\in\\mathcal B,\\forall p'\\in P_t;v_p(b)\\geq v_{p'}(b)$ 使用$Pv_t/P^+v_t$的动机是，它们通常远远小于$P_t$    ","description":"马尔可夫决策过程基础，包括马尔可夫性质，马尔可夫链，马尔可夫奖励过程MRP，完全可观察马尔可夫决策过程MDP以及部分可观察马尔可夫决策过程POMDP","id":0,"section":"posts","tags":["Reinforcement Learning"],"title":"强化学习 | 马尔可夫决策过程","uri":"https://chaphlagical.github.io/zh/posts/note/reinforcement_learning/mdp/"},{"content":"1. 机器学习的分类 机器学习主要分为监督学习、无监督学习、强化学习\n 监督学习：对于有标签的数据进行学习，目的是能够正确判断无标签的数据。主要任务分类和回归 无监督学习：对于无标签的数据进行学习，目的是不仅能够解决有明确答案的问题，也可以对没有明确答案的问题进行预测。主要任务聚类和关联分析 强化学习：根据周围环境的情况，采取行动，根据采取行动的结果，学习行动方式  强化学习 vs. 其他机器学习：\n 没有教师信号，也没有数据标签，只有效用reward 反馈有延时，不是能立即返回 输入数据为时序序列，而不是独立同分布数据 Agent执行的动作会影响之后的数据  2. 强化学习的应用  游戏：电子游戏。棋牌游戏  DeepMind: Atari Games, AlphaGo, StarCraft II OpenAI: Dota 2   机器人  机器人抓取 机器人行走、控制 导航避障   无人机  无人机树林中导航   自动驾驶  端到端控制，车道保持 动态环境中决策   其它应用：库存管理、动态定价、广告投放  3. 强化学习问题   强化学习问题可以由一个四元组$\u0026lt;A,S,R,P\u0026gt;$来描述\n 行动空间Action Space: $A$ 状态空间State Space: $S$ 效用Reward: $R:S\\times A\\times S\\rightarrow R$ 转移函数Transition: $P:S\\times A\\rightarrow S$    Agent\u0026rsquo;s policy:\n$$\n\\begin{align}\n\\pi(a|s)=P[A_t=a|S_t=s]\\\\\n\\pi : S\\times A\\rightarrow R,\\ \\ \\sum_{a\\in A}\\pi(a|s)=1\n\\end{align}\n$$\n对于确定策略：$\\pi:S\\rightarrow A$\n  Agent\u0026rsquo;s view:\n$$\n\\begin{align}\ns_0,a_0, r_1,s_1,a_1,r_2,s_2,a_2,r_3,s_3,\\cdots\\\\\n\\pi^\\ast(s_i)\\rightarrow a_i,\\ \\ i\\geq 0\n\\end{align}\n$$\n  Agent\u0026rsquo;s goal:\n学习最大化长期总效用的策略\n$$\n\\begin{align}\n\\mathrm{T-step}:\u0026amp;\\sum_{t=1}^T r_t\\\\\n\\mathrm{discounted}:\u0026amp;\\sum_{t=1}^\\infty \\gamma^tr_t\n\\end{align}\n$$\n  4. 强化学习Agent 强化学习Agent包含以下模块：\n  策略Policy: Agent的行为，状态到行动的映射\n 确定策略Deterministic policy: $a=\\pi(s)$ 随机策略Stochastic policy: $\\pi(a|s)=P[A_t=a|S_t=s]$    值函数Value function: 状态（和行动）的评价\n 值函数是对当前状态（和行动）下未来效用的预测\n$$\nv_\\pi(s)=E_\\pi[R_{t+1}+\\gamma R_{t+2}+\\gamma^2R_{t+3}+\\cdots|S_t=s]\n$$    模型Model: Agent对环境的刻画\n 给定状态和行动预测环境下一步的反应（下一个状态和效用）\n$$\n\\begin{align}\n\\mathcal P_{ss'}^a\u0026amp;=P[S_{t+1}=s'|S_t=s,A_t=a]\\\\\n\\mathcal R_s^a\u0026amp;=E[R_{t+1}|S_t=s,A_t=a]\n\\end{align}\n$$    ","description":"强化学习绪论","id":1,"section":"posts","tags":["Reinforcement Learning"],"title":"强化学习 | 简介","uri":"https://chaphlagical.github.io/zh/posts/note/reinforcement_learning/intro/"},{"content":"翻译自：https://gpuopen.com/performance/\nCommand Buffers command buffers是现代底层图形API的核心。DX12/Vulkan的大部分CPU时间占用都会花在录制绘制命令到command buffers上。一个最大的优化方向是应用程序现在可以通过多线程进行command buffer的录制\n在此前的图形API（DX11、OpenGL）中，多线程的数量严重受限于驱动程序能够收集到的内容\n  底层的API允许多线程生成command buffer，能够获得比高层API更好的CPU利用率\n  驱动程序不会对底层API生成额外的线程，由应用程序负责多线程管理\n  避免使用过多的小command buffer\n 按经验应至少10个draws或dispatch    command buffer的分配器不是线程安全的\n 建议每个线程都有自己相应的command buffer分配器用于每帧的指令录制 command buffer分配器的数量应大于等于录制指令的线程数乘以飞行帧（frames in flight）的数量    command buffer分配器的增长与其分配的最大command buffer一致\n 尽量为相同的渲染工作负载重用相同的分配器，以帮助最小化内存使用    尽量减少向GPU提交的command buffer的数量\n 每一次提交都会带来CPU和GPU的开销 尽量将command buffer批处理到单次提交中以减少开销 理想情况是每次提交只发生在队列同步或帧结束时发生 避免使用捆绑（bundles）和辅助（secondary）command buffer  只对CPU性能有帮助但会造成GPU性能损失 只需每帧填充command buffer 若非要使用，则每个捆绑/辅助command buffer应至少10个draw      Vulkan\n 对在重置之前只提交一次的command buffer使用USAGE_ONE_TIME_SUBMIT，这将最大化可以应用的优化 避免对command buffer使用USAGE_SIMULTANEOUS_USE 避免在辅助command buffer中使用清除attachment的操作  ","description":"现代图形API (Vulkan/DX12)使用优化技巧","id":2,"section":"posts","tags":["Engine"],"title":"现代图形API优化技巧","uri":"https://chaphlagical.github.io/zh/posts/engine/line/"},{"content":"1. 参数曲线 $E^3$中的一条曲线$C$是从区间$[a,b]$到$E^3$中的一个连续映射，记为：\n$$\np:[a,b]\\rightarrow E^3\n$$\n称为参数曲线\n在$E^3$中选取一个正交标架${O;\\pmb i,\\pmb j,\\pmb k}$，则$\\pmb r(t)$可以用标架向量表示为：\n$$\n\\pmb r(t)=x(t)\\pmb i+y(t)\\pmb j+z(t)\\pmb k\n$$\n或记成：\n$$\n\\pmb r(t)=(x(t),y(t),z(t)),\\ \\ \\ \\ t\\in [a,b]\n$$\n称为曲线$C$的参数方程\n若$x(t)$，$y(t)$和$z(t)$均为可微函数，则称曲线$\\pmb r(t)$是连续可微的，可微的概念与正交标架取法无关\n导数\n$$\n\\pmb r'(t)=\\lim_{\\Delta t\\rightarrow 0}\\dfrac{\\pmb r(t+\\Delta t)-\\pmb r(t)}{\\Delta t}=(x'(t),y'(t),z'(t))\n$$\n当$\\pmb r'(t)\\neq \\pmb 0$时，称为参数曲线的切向量 ，此时曲线在点$\\pmb r(t)$的切线是完全确定的，这样的点称为正则点\n当参数曲线成为正则参数曲线应满足：\n $\\pmb r(t)$至少是自变量$t$的三次以上连续可微的向量函数 $\\pmb r(t)$处处是正则点，即对任意的$t$，有$\\pmb r'(t)\\neq \\pmb 0$  $\\pmb r'(t)$的方向指向参数$t$增大的方向，称为参数曲线的正向\n正则参数曲线在参数变换$t=t(u)$下仍为正则参数曲线的条件为：\n $t(u)$是$u$的三次以上连续可微函数 $t'(u)$处处不为零  根据链式求导法则：\n$$\n\\pmb r'(u)=\\dfrac{\\mathrm d}{\\mathrm du}\\pmb r(t(u))=\\pmb r'(t(u))\\cdot t'(u)\n$$\n在$\\pmb r'(t)\\neq \\pmb 0$的情况下，$\\pmb r'(u)\\neq \\pmb 0$的充要条件为$t'(u)\\neq0$。如此的参数变换在正则参数曲线之间建立起一种等价关系，全体等价的正则参数曲线构成的集合称为一条正则曲线。若参数变换满足$t'(u)\u0026gt;0$，则这种容许的参数变换保持曲线的定向不变\n正则参数曲线$\\pmb r(t)=(x(t),y(t),z(t))$在每一点附近都能表示成如下形式：\n$$\n\\pmb r(x)=(x,y(x),z(x))\n$$\n2. 曲线的弧长 ","description":"古典微分几何曲线论","id":3,"section":"posts","tags":["Differential Geometry"],"title":"曲线论","uri":"https://chaphlagical.github.io/zh/posts/note/differential_geometry/base/"},{"content":"上一次我们成功用三角形填充算法初步渲染出一个模型：\n但其渲染结果与我们用成熟的渲染器渲染出来的结果相比：\n可以看出结果并不正确，原因是我们虽然对背面片元进行剔除，但并未对被遮挡的正面片元进行剔除。当有一前一后两个正向片元时，结果是显示最后渲染的那个片元，这里我们需要借助Z-Buffer缓冲来实现遮挡片元的剔除\nZ-Buffer Z-Buffer顾名思义就是Z轴的Buffer，通常情况下我们把Viewport的横方向定为$x$，纵向为$y$，垂直于屏幕空间为$z$，Z-Buffer存储的就是像素的深度信息。通常Z-Buffer和Frame Buffer大小相同，但只需要单通道，存储浮点数信息，在进行三角形填充遍历时，先索引当前像素的$z$分量是否小于Z-Buffer中已存的$z$分量，若是，则说明新的像素在之前像素（或之前无像素）的前面，可以进行覆盖绘制，否则进行剔除。\nZ-Buffer的示例结果：\n使用Z-Buffer进行剔除后的渲染效果：\n","description":"软光栅渲染器之遮挡剔除","id":4,"section":"posts","tags":["Software Renderer"],"title":"Z-Buffer与遮挡剔除","uri":"https://chaphlagical.github.io/zh/posts/softwarerenderer/zbuffer/"},{"content":"三角形填充算法是光栅化流程中重要的一步，是我们片元着色的基础\n1. 行扫描算法 在进行三角形填充之前，先对三角形三个顶点的纵坐标进行-排序，由小到大依次排列为$t_0$，$t_1$和$t_2$，以$t_1$为分界分为上下两个三角形，从$t_0$开始扫描，行$y$的左右顶点$A$和$B$满足：\n$$\n\\dfrac{y_0-y}{x_0-A_x}=\\dfrac{y_0-y_2}{x_0-x_2}\n$$\n$$\n\\dfrac{y_0-y}{x_0-B_x}=\\dfrac{y_0-y_1}{x_0-x_1}\n$$\n每一行填充$[A_x,B_x]$之间的像素，上下同理，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  void DrawPrimitive::DrawTriangle(const CML::Point2i\u0026amp; p1, const CML::Point2i\u0026amp; p2, const CML::Point2i\u0026amp; p3, const CML::Rgbi\u0026amp; color, FrameBuffer\u0026amp; fbo) { CML::Point2i v1 = p1, v2 = p2, v3 = p3; if (v1[1] \u0026gt; v2[1])std::swap(v1, v2); if (v1[1] \u0026gt; v3[1])std::swap(v1, v3); if (v2[1] \u0026gt; v3[1])std::swap(v2, v3); float total_height = v3[1] - v1[1]; for (int y = v1[1]; y \u0026lt;= v2[1]; y++) { float segment_height = v2[1] - v1[1] + 1; float alpha = (y - v1[1]) / total_height; float beta = (y - v1[1]) / segment_height; CML::Point2i A = v1 + (v3 - v1) * alpha; CML::Point2i B = v1 + (v2 - v1) * beta; if (A[0] \u0026gt; B[0])std::swap(A, B); for (int j = A[0]; j \u0026lt;= B[0]; j++) fbo.SetPixel(j, y, color[0], color[1], color[2]); } for (int y = v2[1]; y \u0026lt;= v3[1]; y++) { float segment_height = v3[1] - v2[1] + 1; float alpha = (y - v1[1]) / total_height; float beta = (y - v2[1]) / segment_height; CML::Point2i A = v1 + (v3 - v1) * alpha; CML::Point2i B = v2 + (v3 - v2) * beta; if (A[0] \u0026gt; B[0])std::swap(A, B); for (int j = A[0]; j \u0026lt;= B[0]; j++) fbo.SetPixel(j, y, color[0], color[1], color[2]); } }   绘制结果示例：\n2. 三角形重心方法 扫描线算法虽然直观上容易理解，编码简单，但因为涉及较多浮点数计算，效率一般，下面介绍一种利用三角形重心的方法进行三角形的填充\n对一个$\\triangle ABC$，任一点$P$与三个顶点有关系：\n$$\n\\vec{AP}=u\\vec{AB}+v\\vec{AC}\n$$\n用顶点表示为：\n$$\nP-A=u(B-A)+v(C-A)\n$$\n整理得到：\n$$\nP=(1-u-v)A+uB+vC=A+u\\vec{AB}+v\\vec{AC}\n$$\n写成分量形式则有：\n$$\n\\begin{cases}\nu\\vec{AB}_x+v\\vec{AC}_x+\\vec{PA}_x=0\\\\\nu\\vec{AB}_y+v\\vec{AC}_y+\\vec{PA}_y=0\n\\end{cases}\n$$\n写成矩阵形式：\n$$\n\\begin{align}\n\\begin{pmatrix}u\u0026amp;v\u0026amp;1\\end{pmatrix}\n\\begin{pmatrix}\\vec{AB}_x\\\\\\vec{AC}_x\\\\\\vec{PA}_x\\end{pmatrix}=0\\\\\n\\begin{pmatrix}u\u0026amp;v\u0026amp;1\\end{pmatrix}\n\\begin{pmatrix}\\vec{AB}_y\\\\\\vec{AC}_y\\\\\\vec{PA}_y\\end{pmatrix}=0\n\\end{align}\n$$\n即向量$(u,v,1)$同时与向量$(\\vec{AB}_x,\\vec{AC}_x,\\vec{PA}_x)$和$(\\vec{AB}_y,\\vec{AC}_y,\\vec{PA}_y)$垂直，因此$(u,v,1)$的一组取值可以为两个分量向量的叉乘\n若点$P$位于$\\triangle ABC$，则有约束：\n$$\n\\begin{cases}\n0\\leq u\\leq 1\\\\\n0\\leq v\\leq 1\\\\\n0\\leq 1-u-v\\leq 1\n\\end{cases}\n$$\n此时我们只需要在待填充的三角形的Bounding Box中遍历所有在三角形内部的像素并进行填充即可，C++代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  void DrawPrimitive::DrawTriangle(const CML::Point2i\u0026amp; p1, const CML::Point2i\u0026amp; p2, const CML::Point2i\u0026amp; p3, const CML::Rgbi\u0026amp; color, FrameBuffer\u0026amp; fbo, PrimitiveType primitive) { if (primitive == PrimitiveType::LINE) { DrawLine(p1, p2, color, fbo); DrawLine(p1, p3, color, fbo); DrawLine(p2, p3, color, fbo); } else { CML::BBox2i bbox{ p1, p2, p3 }; auto Min = bbox.GetMin(); auto Max = bbox.GetMax(); for (int i = Min[0]; i \u0026lt;= Max[0]; i++) { for (int j = Min[1]; j \u0026lt;= Max[1]; j++) { CML::Vec3f u = Barycentric(p1, p2, p3, { i,j }); if(u[0]\u0026gt;=0\u0026amp;\u0026amp;u[1]\u0026gt;=0 \u0026amp;\u0026amp; u[0] \u0026lt;= 1 \u0026amp;\u0026amp; u[1] \u0026lt;= 1 \u0026amp;\u0026amp;u[2]\u0026gt;=0 \u0026amp;\u0026amp; u[2] \u0026lt;= 1) fbo.SetPixel(i, j, color[0], color[1], color[2]); } } } } CML::Vec3f DrawPrimitive::Barycentric(const CML::Point2i\u0026amp; p1, const CML::Point2i\u0026amp; p2, const CML::Point2i\u0026amp; p3, const CML::Point2i\u0026amp; p) { CML::Vec3f v1 = { static_cast\u0026lt;float\u0026gt;(p2[0] - p1[0]), static_cast\u0026lt;float\u0026gt;(p3[0] - p1[0]), static_cast\u0026lt;float\u0026gt;(p1[0] - p[0]) }; CML::Vec3f v2 = { static_cast\u0026lt;float\u0026gt;(p2[1] - p1[1]), static_cast\u0026lt;float\u0026gt;(p3[1] - p1[1]), static_cast\u0026lt;float\u0026gt;(p1[1] - p[1]) }; CML::Vec3f res = v1.Cross(v2); if (std::abs(res[2]) \u0026lt; 1)return { -1, 1, 1 }; return { 1.f - (res[0] + res[1]) / res[2], res[1] / res[2] ,res[0] / res[2] }; }   3. 背面剔除 渲染三角形的开销比渲染直线的开销大得多，为了在渲染模型时提高效率，我们不希望渲染视野中模型背面的三角形，这里涉及一个三角形法向的问题，一般情况下，逆时针顶点顺序的三角形会被处理成正向三角形\n因此，要知道从摄像机视角方向$\\pmb v$看到的三角形$\\pmb p=(\\pmb p_1,\\pmb p_2,\\pmb p_3)$是否在背面，只需判断是否满足：\n$$\n\\pmb v\\cdot[(\\pmb p_2-\\pmb p_1)\\times(\\pmb p_3-\\pmb p_1)]\u0026gt;0\n$$\n对小于0的面不予以绘制\n可以看到效果其实还不正确，但这是因为没有做遮挡面剔除的缘故，具体方法后面再谈\n","description":"软光栅渲染器之三角形填充算法","id":5,"section":"posts","tags":["Software Renderer"],"title":"三角形填充算法","uri":"https://chaphlagical.github.io/zh/posts/softwarerenderer/triangle/"},{"content":"本节主要介绍计算机图形学中常用的3D数学方法，主要内容包括：\n 向量与矩阵 仿射变换 投影变换 四元数与旋转  1. 向量与矩阵 图形学中大部分情况使用2-4维的向量与矩阵，相关内容在线性代数中已有详细介绍，这里不多阐述，可参照LearnOpenGL网站查看相关内容。\n2. 仿射变换 仿射变换包括刚体变换（平移、旋转）、缩放和错切，能够保持共线性。为解决仿射变换中出现的非线性变换问题，例如平移：$\\pmb v'=\\pmb v+\\Delta \\pmb v$，引入齐次坐标的概念，用$n+1$维的向量来表示投影系统空间中的$n$维坐标，用线性变换来表示各种仿射变换，基本格式为：$\\pmb v'=\\pmb {Mv}$，不同变换的合成通过矩阵乘法来实现：$\\pmb v'=\\pmb M_1\\pmb M_2\\cdots\\pmb M_n \\pmb v$\n2.1. 平移变换 $$\n\\pmb T(x,y,z)=\\begin{pmatrix}\n1\u0026amp;0\u0026amp;0\u0026amp;t_x\\\\\n0\u0026amp;1\u0026amp;0\u0026amp;t_y\\\\\n0\u0026amp;0\u0026amp;1\u0026amp;t_z\\\\\n0\u0026amp;0\u0026amp;0\u0026amp;1\\\\\n\\end{pmatrix}\n$$\n2.2. 缩放变换 $$\n\\pmb S(x,y,z)=\\begin{pmatrix}\ns_x\u0026amp;0\u0026amp;0\u0026amp;0\\\\\n0\u0026amp;s_y\u0026amp;0\u0026amp;0\\\\\n0\u0026amp;0\u0026amp;s_z\u0026amp;0\\\\\n0\u0026amp;0\u0026amp;0\u0026amp;1\n\\end{pmatrix}\n$$\n2.3. 绕坐标轴的旋转 $$\n\\pmb R_x(\\theta)=\\begin{pmatrix}\n1\u0026amp;0\u0026amp;0\u0026amp;0\\\\\n0\u0026amp;\\cos\\theta\u0026amp;-\\sin\\theta\u0026amp;0\\\\\n0\u0026amp;\\sin\\theta\u0026amp;\\cos\\theta\u0026amp;0\\\\\n0\u0026amp;0\u0026amp;0\u0026amp;1\n\\end{pmatrix}\n$$\n$$\n\\pmb R_y(\\theta)=\\begin{pmatrix}\n\\cos\\theta\u0026amp;0\u0026amp;\\sin\\theta\u0026amp;0\\\\\n0\u0026amp;1\u0026amp;0\u0026amp;0\\\\\n-\\sin\\theta\u0026amp;0\u0026amp;\\cos\\theta\u0026amp;0\\\\\n0\u0026amp;0\u0026amp;0\u0026amp;1\n\\end{pmatrix}\n$$\n$$\n\\pmb R_z(\\theta)=\\begin{pmatrix}\n\\cos\\theta\u0026amp;-\\sin\\theta\u0026amp;0\u0026amp;0\\\\\n\\sin\\theta\u0026amp;\\cos\\theta\u0026amp;0\u0026amp;0\\\\\n0\u0026amp;0\u0026amp;1\u0026amp;0\\\\\n0\u0026amp;0\u0026amp;0\u0026amp;1\n\\end{pmatrix}\n$$\n2.4. 绕任意轴的旋转 2.4.1. Euler旋转 绕原点任一轴旋转$\\theta$角可以分解为绕$x$，$y$和$z$轴旋转的合成：\n$$\n\\pmb R(\\theta)=\\pmb R_z(\\theta)\\pmb R_y(\\theta)\\pmb R_z(\\theta)\n$$\n注意旋转顺序不可交换\n2.4.2. 一般情况 对于绕任意轴$\\pmb n=(n_x, n_y,n_z)$（其中$\\pmb n$为单位向量）旋转$\\theta$角的旋转矩阵$\\pmb R(\\pmb n, \\theta)$，设有向量$\\pmb v$参与变换，有$\\pmb v'=\\pmb R(\\pmb n, \\theta)\\pmb v$，将$\\pmb v$进行分解为垂直和平行于$\\pmb n$的分量：$\\pmb v=\\pmb v_\\perp+\\pmb v_\\parallel$，又设向量$\\pmb w=\\pmb n\\times\\pmb v_\\perp$垂直于$\\pmb n$和$\\pmb v$构成的平面，则有：\n$$\n\\begin{align}\n\\pmb v_\\parallel\u0026amp;=(\\pmb v\\cdot\\pmb n)\\pmb n\\\\\n\\pmb v_\\perp\u0026amp;=\\pmb v-(\\pmb v\\cdot\\pmb n)\\pmb n\\\\\n\\pmb w\u0026amp;=\\pmb n\\times\\pmb v_\\perp=\\pmb n\\times(\\pmb v-(\\pmb v\\cdot\\pmb n)\\pmb n)=\\pmb n\\times\\pmb v\n\\end{align}\n$$\n参与旋转部分仅有$\\pmb v_\\perp$，有：\n$$\n\\begin{align}\n\\pmb v'_\\perp\u0026amp;=\\pmb v_\\perp\\cos\\theta+\\pmb w\\sin\\theta\\\\\n\u0026amp;=(\\pmb v-(\\pmb v\\cdot\\pmb n)\\pmb n)\\cos\\theta+\\pmb n\\times\\pmb v\\sin\\theta\n\\end{align}\n$$\n结合平行分量：\n$$\n\\begin{align}\n\\pmb v'\u0026amp;=\\pmb v_\\perp'+\\pmb v_\\parallel\\\\\n\u0026amp;=\\pmb v\\cos\\theta+(1-\\cos\\theta)(\\pmb v\\cdot\\pmb n)\\pmb n+\\pmb n\\times\\pmb v\\sin\\theta\n\\end{align}\n$$\n整理得到$\\pmb R(\\pmb n, \\theta)$：\n$$\n\\pmb R(\\pmb n,\\theta)=\\begin{pmatrix}\nn_x^2(1-\\cos\\theta)+\\cos\\theta\u0026amp;n_xn_y(1-\\cos\\theta)-n_z\\sin\\theta\u0026amp;n_xn_z(1-\\cos\\theta)+n_y\\sin\\theta\\\\\nn_xn_y(1-\\cos\\theta)+n_z\\sin\\theta\u0026amp;n_y^2(1-\\cos\\theta)+\\cos\\theta\u0026amp;n_yn_z(1-\\cos\\theta)-n_x\\sin\\theta\\\\\nn_xn_z(1-\\cos\\theta)-n_y\\sin\\theta\u0026amp;n_yn_z(1-\\cos\\theta)-n_y\\sin\\theta\u0026amp;n_z^2(1-\\cos\\theta)+\\cos\\theta\n\\end{pmatrix}\n$$\n3. 投影变换 软光栅渲染中很重要的一步便是将三维空间中的物体投影到二维屏幕上，这一步便是由投影变换完成，投影变换矩阵将视图空间中的顶点数据变换到裁剪空间中，裁剪空间中的顶点最后通过透视除法变换到标准化设备坐标。最常用的投影方式有：透视投影和正交投影\n3.1. 透视投影 经过透视投影，视锥体中的坐标点将被映射到NDC标准化设备坐标\n下面推导透视投影矩阵的计算，假设视锥体中坐标点$(x_e,y_e,z_e)$投影到近平面上的点$(x_p.y_p.z_p)$，设视点到近平面距离为$n$到远平面距离为$f$\n从两个角度观察各个量的关系，由三角形近似比例：\n$$\n\\begin{align}\n\\dfrac{x_p}{x_e}\u0026amp;=\\dfrac{-n}{z_e}\\Rightarrow x_p=\\dfrac{-n\\cdot x_e}{z_e}=\\dfrac{n\\cdot x_e}{-z_e}\\\\\n\\dfrac{y_p}{y_e}\u0026amp;=\\dfrac{-n}{z_e}\\Rightarrow y_p=\\dfrac{-n\\cdot y_e}{z_e}=\\dfrac{n\\cdot y_e}{-z_e}\n\\end{align}\n$$\n注意到$x_p$和$y_p$的计算均需要除以一个$-z_e$，这与裁剪空间到NDC正则化的透视除法相对应：\n$$\n\\begin{align}\n\\begin{pmatrix}\nx_{clip}\\\\y_{clip}\\\\z_{clip}\\\\w_{clip}\n\\end{pmatrix}\n\u0026amp;=\\pmb M_{projection}\\cdot\n\\begin{pmatrix}\nx_{eye}\\\\y_{eye}\\\\z_{eye}\\\\w_{eye}\n\\end{pmatrix}\\\\\n\\begin{pmatrix}\nx_{ndc}\\\\y_{ndc}\\\\z_{ndc}\n\\end{pmatrix}\n\u0026amp;=\n\\begin{pmatrix}\nx_{clip}/w_{clip}\\\\\ny_{clip}/w_{clip}\\\\\nz_{clip}/w_{clip}\n\\end{pmatrix}\n\\end{align}\n$$\n这里的$w_{clip}$便是$-z_e$了，因此透视投影矩阵有如下形式：\n$$\n\\begin{align}\n\\begin{pmatrix}\nx_c\\\\\ny_c\\\\\nz_c\\\\\nw_c\n\\end{pmatrix}=\n\\begin{pmatrix}\n\\cdot \u0026amp; \\cdot \u0026amp; \\cdot \u0026amp; \\cdot\\\\\n\\cdot \u0026amp; \\cdot \u0026amp; \\cdot \u0026amp; \\cdot\\\\\n\\cdot \u0026amp; \\cdot \u0026amp; \\cdot \u0026amp; \\cdot\\\\\n0\u0026amp;0\u0026amp;-1\u0026amp;0\n\\end{pmatrix}\n\\begin{pmatrix}\nx_e\\\\\ny_e\\\\\nz_e\\\\\nw_e\n\\end{pmatrix}\n\\end{align}\n$$\n下面我们需要把近平面坐标点$x_p$和$y_p$线性映射到NDC坐标$x_n$和$y_n$：$[l,r]\\Rightarrow [-1,1]$以及$[b,t]\\Rightarrow [-1,1]$\n$$\n\\begin{align}\n\\dfrac{x_n-(-1)}{1-(-1)}\u0026amp;=\\dfrac{x_p-l}{r-l}\\Rightarrow x_n=\\dfrac{2x_p}{r-l}-\\dfrac{r+l}{r-l}\\\\\n\\dfrac{y_n-(-1)}{1-(-1)}\u0026amp;=\\dfrac{y_p-b}{t-b}\\Rightarrow y_n=\\dfrac{2y_p}{t-b}-\\dfrac{t+b}{t-b}\n\\end{align}\n$$\n将$x_p$和$y_p$代入得\n$$\n\\begin{align}\nx_n=\\Big(\\dfrac{2n}{r-l}\\cdot x_e+\\dfrac{r+l}{r-l}\\cdot z_e \\Big)\\Big/-z_e\\\\\ny_n=\\Big(\\dfrac{2n}{t-b}\\cdot y_e+\\dfrac{t+b}{t-b}\\cdot z_e \\Big)\\Big/-z_e\n\\end{align}\n$$\n可填入透视投影矩阵：\n$$\n\\begin{align}\n\\begin{pmatrix}\nx_c\\\\\ny_c\\\\\nz_c\\\\\nw_c\n\\end{pmatrix}=\n\\begin{pmatrix}\n\\frac{2n}{r-l}\u0026amp;0\u0026amp;\\frac{r+l}{r-l}\u0026amp;0\\\\\n0\u0026amp;\\frac{2n}{t-b}\u0026amp;\\frac{t+b}{t-b}\u0026amp;0\\\\\n\\cdot \u0026amp; \\cdot \u0026amp; \\cdot \u0026amp; \\cdot\\\\\n0\u0026amp;0\u0026amp;-1\u0026amp;0\n\\end{pmatrix}\n\\begin{pmatrix}\nx_e\\\\\ny_e\\\\\nz_e\\\\\nw_e\n\\end{pmatrix}\n\\end{align}\n$$\n由于$z_c$不依赖于$x_e$与$y_e$且与$z_e$和$w_e$成线性关系，设\n$$\n\\begin{align}\n\\begin{pmatrix}\nx_c\\\\\ny_c\\\\\nz_c\\\\\nw_c\n\\end{pmatrix}=\n\\begin{pmatrix}\n\\frac{2n}{r-l}\u0026amp;0\u0026amp;\\frac{r+l}{r-l}\u0026amp;0\\\\\n0\u0026amp;\\frac{2n}{t-b}\u0026amp;\\frac{t+b}{t-b}\u0026amp;0\\\\\n0\u0026amp;0\u0026amp;A\u0026amp;B\\\\\n0\u0026amp;0\u0026amp;-1\u0026amp;0\n\\end{pmatrix}\n\\begin{pmatrix}\nx_e\\\\\ny_e\\\\\nz_e\\\\\nw_e\n\\end{pmatrix}\n\\end{align}\n$$\n即\n$$\nz_n=z_c/w_c=\\dfrac{Az_e+Bw_e}{-z_e}\n$$\n在视角空间中，$w_e=1$，因此$z_n=\\frac{Az_e+B}{-z_e}$，利用边界关系：\n$$\n\\begin{cases}\n\\dfrac{-An+B}{n}=-1\\\\\n\\dfrac{-Af+B}{f}=1\n\\end{cases}\n\\Rightarrow\n\\begin{cases}\nA=-\\dfrac{f+n}{f-n}\\\\\nB=-\\dfrac{2fn}{f-n}\n\\end{cases}\n$$\n因此完整的透视投影矩阵表示为：\n$$\n\\begin{pmatrix}\n\\frac{2n}{r-l}\u0026amp;0\u0026amp;\\frac{r+l}{r-l}\u0026amp;0\\\\\n0\u0026amp;\\frac{2n}{t-b}\u0026amp;\\frac{t+b}{t-b}\u0026amp;0\\\\\n0\u0026amp;0\u0026amp;\\frac{-(f+n)}{f-n}\u0026amp;\\frac{-2fn}{f-n}\\\\\n0\u0026amp;0\u0026amp;-1\u0026amp;0\n\\end{pmatrix}\n$$\n如果视锥体对称，即$t=-b$和$l=-r$，则可简化为：\n$$\n\\begin{pmatrix}\n\\frac{n}{r}\u0026amp;0\u0026amp;0\u0026amp;0\\\\\n0\u0026amp;\\frac{n}{t}\u0026amp;0\u0026amp;0\\\\\n0\u0026amp;0\u0026amp;\\frac{-(f+n)}{f-n}\u0026amp;\\frac{-2fn}{f-n}\\\\\n0\u0026amp;0\u0026amp;-1\u0026amp;0\n\\end{pmatrix}\n$$\n通常情况下我们会用参数$fovy$（$y$轴方向的视域角）、$aspect$（屏幕宽高比）、$near$（近平面）以及$far$（远平面）来构造透视投影矩阵，相关关系如下：\n$$\n\\begin{align}\nr-l\u0026amp;=width=2*near*aspect*tan(fovy/2)\\\\\nt-b\u0026amp;=height=2*near*tan(fovy/2)\n\\end{align}\n$$\n3.2. 正交投影 正交投影定义了一个立方体的裁剪空间，由宽、高、近平面和远平面所指定，平截头箱以外的坐标点将被裁剪掉，最后同样映射到NDC坐标空间中\n正交投影矩阵的推导较为简单，只需对各个方向作正则化即可：\n$$\n\\begin{cases}\n\\dfrac{x_n-(-1)}{1-(-1)}=\\dfrac{x_e-l}{r-l}\\\\\n\\dfrac{y_n-(-1)}{1-(-1)}=\\dfrac{y_e-b}{t-b}\\\\\n\\dfrac{z_n-(-1)}{1-(-1)}=\\dfrac{z_e-n}{f-n}\n\\end{cases}\n$$\n得到正交投影矩阵：\n$$\n\\begin{pmatrix}\n\\frac{2}{r-l}\u0026amp;0\u0026amp;0\u0026amp;-\\frac{r+l}{r-l}\\\\\n0\u0026amp;\\frac{2}{t-b}\u0026amp;0\u0026amp;-\\frac{t+b}{t-b}\\\\\n0\u0026amp;0\u0026amp;\\frac{-2}{f-n}\u0026amp;-\\frac{f+n}{f-n}\\\\\n0\u0026amp;0\u0026amp;0\u0026amp;1\n\\end{pmatrix}\n$$\n同样地，如果平截头箱对称，则可简化为\n$$\n\\begin{pmatrix}\n\\frac{1}{r}\u0026amp;0\u0026amp;0\u0026amp;0\\\\\n0\u0026amp;\\frac{1}{t}\u0026amp;0\u0026amp;0\\\\\n0\u0026amp;0\u0026amp;\\frac{-2}{f-n}\u0026amp;-\\frac{f+n}{f-n}\\\\\n0\u0026amp;0\u0026amp;0\u0026amp;1\n\\end{pmatrix}\n$$\n至此渲染出一幅软光栅画面所需的数学应该没有太大问题了\n4. 四元数与旋转 前面提到绕固定轴旋转的计算合成方法，但仅依靠欧拉角旋转容易导致万向节死锁的现象，万向节死锁的具体阐述见视频。我们需要一个更加强大的表述旋转的工具，四元数就是其中一种\n4.1. 四元数的定义 四元数是复数的推广，拥有三个虚部，表示为：\n$$\nq=a+bi+cj+dk=(a,\\pmb v),\\ \\ \\ \\ (a,b,c,d\\in\\mathbb R)\n$$\n其中，$i^2=j^2=k^2=ijk=-1$\n4.2. 四元数的性质   模长（范数）\n$$\n\\begin{align}\n\\Arrowvert q\\Arrowvert\u0026amp;=\\sqrt{a^2+b^2+c^2+d^2}\\\\\n\u0026amp;=\\sqrt{s^2+\\Arrowvert\\pmb v\\Arrowvert^2}\\\\\n\u0026amp;=\\sqrt{s^2+\\pmb v\\cdot \\pmb v}\n\\end{align}\n$$\n  加减法运算\n$$\n\\begin{align}\nq_1\\pm q_2\u0026amp;=a_1+b_1i+c_1j+d_1k\\pm(a_2+b_2i+c_2j+d_2k)\\\\\n\u0026amp;=(a_1\\pm a_2)+(b_1\\pm b_2)i+(c_1\\pm c_2)j+(d_1\\pm d_2)k\\\\\n\u0026amp;=(a_1\\pm a_2,\\pmb v_1\\pm \\pmb v_2)\n\\end{align}\n$$\n  标量乘法\n$$\n\\begin{align}\nsq\u0026amp;=s(a+bi+cj+dk)\\\\\n\u0026amp;=sa+sbi+scj+sdk\n\\end{align}\n$$\n  四元数乘法（ Graßmann积）\n$$\n\\begin{align}\nq_1q_2=\u0026amp;(a_1+b_1i+c_1j+d_1k)(a_2+b_2i+c_2j+d_2k)\\\\\n=\u0026amp;(a_1+\\pmb v_1)(a_2+\\pmb v_2)\\\\\n=\u0026amp;a_1a_2+a_1\\pmb v_2+a_2\\pmb v_1+\\pmb v_1\\pmb v_2\n\\end{align}\n$$\n这里$\\pmb v_1=b_1i+c_1j+d_1k$，$\\pmb v_2=b_2i+c_2j+d_2k$，有\n$$\n\\begin{align}\n\\pmb v_1\\pmb v_2=\u0026amp;-b_1b_2+b_1c_2ij+b_1d_2ik\\\\\n\u0026amp;+c_1b_2ji-c_1c_2+c_1d_2jk\\\\\n\u0026amp;+d_1b_2ki+d_1c_2kj-d_1d_2\n\\end{align}\n$$\n又$i^2=j^2=k^2=ijk=-1$，故有：\n$$\n\\begin{align}\nij\u0026amp;=k,ji=-k\\\nik\u0026amp;=j,ki=-j\\\njk\u0026amp;=i,kj=-i\n\\end{align}\n$$\n代入得\n$$\n\\pmb v_1\\pmb v_2=-(b_1b_2+c_1c_2+d_1d_2)+\\left|\\begin{matrix}i\u0026amp;j\u0026amp;k\\\\b_1\u0026amp;c_1\u0026amp;d_1\\\\b_2\u0026amp;c_2\u0026amp;d_2\\end{matrix}\\right|=\\pmb v_1\\times\\pmb v_2-\\pmb v_1\\cdot\\pmb v_2\n$$\n综上，\n$$\n\\begin{align}\nq_1q_2\u0026amp;=(a_1a_2-\\pmb v_1\\cdot\\pmb v_2, a_1\\pmb v_2+a_2\\pmb v_1+\\pmb v_1\\times\\pmb v_2)\\\\\n\u0026amp;=\\begin{pmatrix}\na_1\u0026amp;-b_1\u0026amp;-c_1\u0026amp;-d_1\\\\\nb_1\u0026amp;a_1\u0026amp;-d_1\u0026amp;c_1\\\\\nc_1\u0026amp;d_1\u0026amp;a_1\u0026amp;-b_1\\\\\nd_1\u0026amp;-c_1\u0026amp;b_1\u0026amp;a_1\n\\end{pmatrix}\n\\begin{pmatrix}\na_2\\\\b_2\\\\c_2\\\\d_2\n\\end{pmatrix}\n\\end{align}\n$$\n四元数乘积不符合交换律，这里给出右乘结果：\n$$\n\\begin{align}\nq_2q_1\u0026amp;=\\begin{pmatrix}\na_1\u0026amp;-b_1\u0026amp;-c_1\u0026amp;-d_1\\\\\nb_1\u0026amp;a_1\u0026amp;d_1\u0026amp;-c_1\\\\\nc_1\u0026amp;-d_1\u0026amp;a_1\u0026amp;b_1\\\\\nd_1\u0026amp;c_1\u0026amp;-b_1\u0026amp;a_1\n\\end{pmatrix}\n\\begin{pmatrix}\na_2\\\\b_2\\\\c_2\\\\d_2\n\\end{pmatrix}\n\\end{align}\n$$\n  纯四元数\n$$\nq=(0,\\pmb v)\n$$\n两个纯四元数的乘积：\n$$\n\\begin{align}\nq_1q_2\u0026amp;=(0-\\pmb v_1\\cdot \\pmb v_2,0+\\pmb v_1\\times\\pmb v_2)\\\\\n\u0026amp;=(-\\pmb v_1\\cdot\\pmb v_2, \\pmb v_2\\times\\pmb v_2)\n\\end{align}\n$$\n  四元数的逆\n$$\nqq^{-1}=q^{-1}q=1\n$$\n$q$与$q^{-1}$互逆\n  四元数的共轭\n$$\n\\begin{align}\nq\u0026amp;=a_1+b_1i+c_1j+d_1k\\\\\nq^*\u0026amp;=a_1-b_1i-c_1j-d_1k\n\\end{align}\n$$\n$$\nqq^*=(a^2+\\pmb v\\cdot\\pmb v)=\\Arrowvert q\\Arrowvert^2\n$$\n因此求逆四元数的方法：\n$$\nq^{-1}=\\dfrac{q^*}{\\Arrowvert q\\Arrowvert^2}\n$$\n单位四元数：$\\Arrowvert q\\Arrowvert^2=1$\n  4.3. 四元数与3D旋转 同样地讨论一个向量$\\pmb v$绕旋转轴$\\pmb u$旋转$\\theta$个角度，同样考虑$\\pmb v_\\perp$和$\\pmb v_\\parallel$，定义为纯四元数：\n$$\n\\begin{matrix}\nv=(0,\\pmb v)\u0026amp;v'=(0,\\pmb v')\\\\\nv_\\perp=(0,\\pmb v_\\perp)\u0026amp;v'_\\perp=(0,\\pmb v'_\\perp)\\\\\nv_\\parallel=(0,\\pmb v_\\parallel)\u0026amp;v'_\\parallel=(0,\\pmb v'_\\parallel)\\\\\nu=(0,\\pmb u)\n\\end{matrix}\n$$\n$$\n\\begin{matrix}\nv=v_\\parallel+v_\\perp\u0026amp;\nv'=v'_\\parallel+v'_\\perp\n\\end{matrix}\n$$\n此前已推导过：\n$$\n\\pmb v_\\perp'=\\cos\\theta \\pmb v_\\perp+\\sin\\theta(\\pmb u\\times\\pmb v_\\perp)\n$$\n令四元数$v_\\perp=(0,\\pmb v_\\perp)$，$q=(\\cos\\theta,\\sin\\theta \\pmb u)$，可将上式用四元数表示：\n$$\nv'_\\perp=qv_\\perp\n$$\n同时平行分量不变：$v_\\parallel=v_\\parallel'$\n因此\n$$\nv'=v_\\parallel+qv_\\perp\n$$\n注意到，当$\\pmb u$为单位向量时，\n$$\n\\begin{align}\nq^2\u0026amp;=(\\cos\\theta,\\sin\\theta\\pmb u)\\cdot(\\cos\\theta,\\sin\\theta\\pmb u)\\\\\n\u0026amp;=(\\cos^2\\theta-\\sin^2\\theta, 2\\sin\\theta\\cos\\theta\\pmb u)\\\\\n\u0026amp;=(\\cos2\\theta,\\sin2\\theta\\pmb u)\n\\end{align}\n$$\n因此，旋转后的四元数可表示为：\n$$\n\\begin{align}\nv'\u0026amp;=v_\\parallel+qv_\\perp\\\\\n\u0026amp;=1\\cdot v_\\parallel+qv_\\perp\\\\\n\u0026amp;=pp^{-1}v_\\parallel+ppv_\\perp\n\\end{align}\n$$\n令$q=p^2$，则$p=(\\cos\\frac{\\theta}{2},\\sin\\frac{\\theta}{2}\\pmb u)$，注意到$\\Arrowvert p\\Arrowvert =1$，因此\n$$\np^{-1}=p^*\n$$\n因此，$v'=pp^*v_\\parallel+ppv_\\perp$\n为进一步简化，我们有结论$p^*v_\\parallel=v_\\parallel p^*$和$pv_\\perp=v_\\perp p^*$，证明从略，得到：\n$$\n\\begin{align}\nv'\u0026amp;=pp^*v_\\parallel+ppv_\\perp\\\\\n\u0026amp;=pv_{\\parallel}p^*+pv_{\\perp}p^*\\\\\n\u0026amp;=p(v_\\parallel+v_{\\perp})p^*\\\\\n\u0026amp;=pvp^*\n\\end{align}\n$$\n综上所述，任意向量$\\pmb v$绕以单位向量定义的旋转轴$\\pmb u$旋转$\\theta$角度之后的$\\pmb v'$用四元数表示为：\n$$\nv'=qvq^*=qvq^{-1}\n$$\n其中，$v=(0,\\pmb v)$，$q=(\\cos\\frac{\\theta}{2},\\sin\\frac{\\theta}{2}\\pmb u)$\n对于一个单位四元数$q=(a,\\pmb b)$，其旋转角度与旋转轴可通过如下方式计算：\n$$\n\\theta=2\\cos^{-1}a\n$$\n$$\n\\pmb u=\\dfrac{\\pmb b}{\\sin(\\cos^{-1}a)}\n$$\n4.4. 3D旋转的矩阵形式 前述提到左乘矩阵和右乘矩阵如下：\n$$\nL(q)=\\begin{pmatrix}\na\u0026amp;-b\u0026amp;-c\u0026amp;-d\\\\\nb\u0026amp;a\u0026amp;-d\u0026amp;c\\\\\nc\u0026amp;d\u0026amp;a\u0026amp;-b\\\\\nd\u0026amp;-c\u0026amp;b\u0026amp;a\n\\end{pmatrix}\n$$\n$$\nR(q)=\\begin{pmatrix}\na\u0026amp;-b\u0026amp;-c\u0026amp;-d\\\\\nb\u0026amp;a\u0026amp;d\u0026amp;-c\\\\\nc\u0026amp;-d\u0026amp;a\u0026amp;b\\\\\nd\u0026amp;c\u0026amp;-b\u0026amp;a\n\\end{pmatrix}\n$$\n令$a=\\cos\\frac{\\theta}{2}$，$b=\\sin\\frac{\\theta}{2}u_x$，$c=\\sin\\frac{\\theta}{2}u_y$，$d=\\sin\\frac{\\theta}{2}u_z$，$q=a+bi+cj+dk$，可得\n$$\n\\begin{align}\nqvq^\\ast\u0026amp;=L(q)R(q^\\ast)v\\\\\n\u0026amp;=\\begin{pmatrix}\na\u0026amp;-b\u0026amp;-c\u0026amp;-d\\\\\nb\u0026amp;a\u0026amp;-d\u0026amp;c\\\\\nc\u0026amp;d\u0026amp;a\u0026amp;-b\\\\\nd\u0026amp;-c\u0026amp;b\u0026amp;a\n\\end{pmatrix}\n\\begin{pmatrix}\na\u0026amp;-b\u0026amp;-c\u0026amp;-d\\\\\nb\u0026amp;a\u0026amp;d\u0026amp;-c\\\\\nc\u0026amp;-d\u0026amp;a\u0026amp;b\\\\\nd\u0026amp;c\u0026amp;-b\u0026amp;a\n\\end{pmatrix}v\n\\end{align}\n$$\n又$a^2+b^2+c^2+d^2=1$，有\n$$\nqvq^*=\\begin{pmatrix}\n1\u0026amp;0\u0026amp;0\u0026amp;0\\\\\n0\u0026amp;1-2c^2-2d^2\u0026amp;2bc-2ad\u0026amp;2ac+2bd\\\\\n0\u0026amp;2bc+2ad\u0026amp;1-2b^2-2d^2\u0026amp;2cd-2ab\\\\\n0\u0026amp;2bd-2ac\u0026amp;2ab+2cd\u0026amp;1-2b^2-2c^2\n\\end{pmatrix}v\n$$\n仅考虑虚部可简化为三阶矩阵：\n$$\n\\pmb v'=\\begin{pmatrix}\n1-2c^2-2d^2\u0026amp;2bc-2ad\u0026amp;2ac+2bd\\\\\n2bc+2ad\u0026amp;1-2b^2-2d^2\u0026amp;2cd-2ab\\\\\n2bd-2ac\u0026amp;2ab+2cd\u0026amp;1-2b^2-2c^2\n\\end{pmatrix}\\pmb v\n$$\n同时，四元数旋转也是可以合成的，需要用到引理：$\\prod_{i=1}^nq_i^\\ast=(\\prod_{i=n}^1q_i)^\\ast$\n复合结果：\n$$\n\\begin{align}\nv'\u0026amp;=(q_nq_{n-1}\\cdots q_2q_1)v(q_1^\\ast q_2^\\ast\\cdots q_{n-1}^\\ast q_n^\\ast)\\\\\n\u0026amp;=(q_nq_{n-1}\\cdots q_2q_1)v(q_nq_{n-1}\\cdots q_2q_1)^\\ast\n\\end{align}\n$$\n4.5. 四元数插值 4.5.1. 线性插值Lerp $$\nq_t=Lerp(q_0,q_1,t)=(1-t)q_0+tq_1\n$$\n4.5.2. 正规化线性插值Nlerp $$\nq_t=Nlerp(q_0,q_1,t)=\\dfrac{(1-t)q_0+tq_1}{\\Arrowvert(1-t)q_0+tq_1\\Arrowvert}\n$$\n4.5.3. 球面线性插值Slerp $$\nq_t=Slerp(q_0,q_1,t)=\\dfrac{\\sin((1-t)\\theta)}{\\sin\\theta}q_0+\\dfrac{\\sin(t\\theta)}{\\sin\\theta}q_1\n$$\n参考资料\n[1] https://krasjet.github.io/quaternion/\n[2] http://www.songho.ca/opengl/gl_projectionmatrix.html\n[3] https://learnopengl-cn.github.io/01%20Getting%20started/08%20Coordinate%20Systems/\n","description":"软光栅渲染器之数学库","id":6,"section":"posts","tags":["Software Renderer"],"title":"3D数学基础","uri":"https://chaphlagical.github.io/zh/posts/softwarerenderer/mathematics/"},{"content":"本节介绍光栅化中的画线算法，画线算法是光栅化中最简单的算法，如何充分发挥画线的效率是本节的重点\n1. 增量画线算法 想要在$(x_0,y_0)$到$(x_1,y_1)$之间画一条线，一个朴素的想法是根据某个给定的小步长行进，再对坐标进行取整：\n1 2 3 4 5 6 7 8 9  void line(int x0, int y0, int x1, int y1, Image \u0026amp;image, Color color) { for(float t=0;t\u0026lt;1;t+=0.01) { int x=x0+(x1-x0)*t; int y=y0+(y1-y0)*t; image.set(x, y, color); } }   2. DDA算法（数字微分分析法） 直线$y=mx$满足微分方程：$\\mathcal dy/\\mathcal dx=(y1-y0)/(x1-x0)$，沿着横坐标扫描填充像素：\n1 2 3 4 5 6 7 8 9 10  void line(int x0, int y0, int x1, int y1, Image \u0026amp;image, Color color) { float m = (y1-y0)/(x1-x0); float y=y0; for(int x = x0; x \u0026lt;= x1;x++) { float y += m; image.set(x, round(y), color); } }   DDA算法中每一步均需要进行浮点运算，为了尽可能提高运算效率，我们更希望进行纯整型计算\n3. Bresenham算法 Bresenham算法中可以不出现任何浮点运算，是现在硬件光栅化常用的一种算法。\nBresenham算法只需考虑$0\\leq m\\leq 1$的情况，其他情况利用对称性处理，并假设像素中心在半整数处。\n从一个已被确定激活的像素出发，那么下一个像素的可能位置只有两种可能情况：\n此时我们选取策略如图所示：\nC++程序如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  void line(int x0, int y0, int x1, int y1, Image \u0026amp;image, Color color) { bool steep = false; if (std::abs(x0 - x1) \u0026lt; std::abs(y0 - y1)) { std::swap(x0, y0); std::swap(x1, y1); steep = true; } if (x0 \u0026gt; x1) { std::swap(x0, x1); std::swap(y0, y1); } int dx = x1 - x0; int dy = y1 -y0; int derror2 = std::abs(dy) * 2; int error2 = 0; int y = y0; for (int x = x0; x \u0026lt;= x1; x++) { if (steep) image.set(y, x, color); else image.set(x, y, color); error2 += derror2; if (error2 \u0026gt; dx) { y += (y1 \u0026gt; y0 ? 1 : -1); error2 -= dx * 2; } } }   首先，将直线的形式统一为$x_0\u0026lt;x_1$且$|\\mathrm dy/\\mathrm dx|\u0026lt;1$的形式，设$\\Delta x=x_1-x_0$和$\\Delta y=y_1-y_0$，对每次迭代，有\n$$\nx_{i+1}=x_i+1\n$$\n$$\n\\overline y_{i+1}=mx_{i+1}+B=m(x_i+1)+B\n$$\n两个差值：\n$$\na=y_i+1-\\overline y_{i+1}=y_i+1-mx_{i+1}-B\n$$\n$$\nb=\\overline y_{i+1}-y_i=mx_{i+1}+B-y_i\n$$\n$$\nb-a=2mx_{i+1}+2B-2y_i-1\n$$\n注意到$m=\\Delta y/\\Delta x$，我们希望不使用任何浮点数，方程两边同乘$\\Delta x$有\n$$\np_i=\\Delta x(b-a)=2\\Delta yx_{i+1}-2\\Delta x y_i+c\n$$\n其中$c=(2B-1)\\Delta x+2\\Delta y$为常量，且$p_i$符号与$b-a$相同，用迭代的方式表示：\n$$\np_{i+1}-p_i=2\\Delta y-2\\Delta x(\\overline{y}_{i+1}-y_i)\n$$\n若$p_i\\leq 0$，则选择下像素，此时$\\overline y_{i+1}=y_i$，有\n$$\np_{i+1}=p_i+2\\Delta y\n$$\n若$p_i\u0026gt;0$，则选择上像素，此时$\\overline y_{i+1}=y_i+1$，有\n$$\np_{i+1}=p_i+2\\Delta y-2\\Delta x\n$$\n此即策略变量的迭代方程\n测试结果示例：\n参考资料\nhttps://github.com/ssloy/tinyrenderer/wiki/Lesson-1-Bresenham%E2%80%99s-Line-Drawing-Algorithm\nhttp://staff.ustc.edu.cn/~lgliu/Courses/ComputerGraphics_2020_spring-summer/default.htm\n","description":"软光栅渲染器之画线算法","id":7,"section":"posts","tags":["Software Renderer"],"title":"光栅画线算法","uri":"https://chaphlagical.github.io/zh/posts/softwarerenderer/line/"},{"content":"我将在这里分享有趣的知识与技术\n","description":"My Blog","id":9,"section":"","tags":null,"title":"关于","uri":"https://chaphlagical.github.io/zh/about/"}]