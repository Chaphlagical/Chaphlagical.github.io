<!DOCTYPE html><html lang="[&quot;en&quot;,&quot;zh-CN&quot;,&quot;default&quot;]" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>Vectorization for Fast, Analytic, and Differentiable Visibility | Chaf's Blog</title><meta name="author" content="Chaf Chen"><meta name="copyright" content="Chaf Chen"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="ACM Transactions on Graphics 2021 paper reading">
<meta property="og:type" content="article">
<meta property="og:title" content="Vectorization for Fast, Analytic, and Differentiable Visibility">
<meta property="og:url" content="https://chaphlagical.github.io/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/index.html">
<meta property="og:site_name" content="Chaf&#39;s Blog">
<meta property="og:description" content="ACM Transactions on Graphics 2021 paper reading">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://chaphlagical.github.io/img/logo.jpg">
<meta property="article:published_time" content="2022-12-17T21:13:11.000Z">
<meta property="article:modified_time" content="2023-03-03T07:54:56.940Z">
<meta property="article:author" content="Chaf Chen">
<meta property="article:tag" content="Differentiable Rendering">
<meta property="article:tag" content="Rendering">
<meta property="article:tag" content="TOG 2021">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://chaphlagical.github.io/img/logo.jpg"><link rel="shortcut icon" href="/img/logo.jpg"><link rel="canonical" href="https://chaphlagical.github.io/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Vectorization for Fast, Analytic, and Differentiable Visibility',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-03 07:54:56'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (false) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/logo.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">33</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Chaf's Blog"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/logo.jpg"/><span class="site-name">Chaf's Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">Vectorization for Fast, Analytic, and Differentiable Visibility</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-12-17T21:13:11.000Z" title="Created 2022-12-17 21:13:11">2022-12-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-03-03T07:54:56.940Z" title="Updated 2023-03-03 07:54:56">2023-03-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper-Reading/">Paper Reading</a></span></div><div class="meta-secondline"></div></div></div><article class="post-content" id="article-container"><p><strong>Author</strong>: <a target="_blank" rel="noopener" href="https://www.mangosister.me/">Yang Zhou</a>,¬†<a target="_blank" rel="noopener" href="https://winmad.github.io/">Lifan Wu</a>,¬†<a target="_blank" rel="noopener" href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>, <a target="_blank" rel="noopener" href="https://sites.cs.ucsb.edu/~lingqi/">Ling-Qi Yan</a></p>
<p><strong>Paper</strong>: <a target="_blank" rel="noopener" href="https://sites.cs.ucsb.edu/~lingqi/publications/paper_vectorization.pdf">Link</a>  </p>
<p><strong>Video</strong>:</p>
<p><video src="https://sites.cs.ucsb.edu/~lingqi/publications/video_vectorization.mp4" controls = true width = 400></video></p>
<p><strong>Presentation:</strong></p>
<p><video src="https://sites.cs.ucsb.edu/~lingqi/publications/presentation_vectorization.mp4" controls = true width = 400></video></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>There are generally two approaches to render images:</p>
<ul>
<li>Rasterization: Project scene geometry onto the screen and breaks the geometry into pixels<ul>
<li>Fast but prone to aliasing</li>
</ul>
</li>
<li>Ray Tracing: Cast rays into the scene and bounces them stochastically to find paths connecting the light and the camera<ul>
<li>High-quality but is slow and noisy</li>
</ul>
</li>
</ul>
<h3 id="Main-Problem"><a href="#Main-Problem" class="headerlink" title="Main Problem"></a>Main Problem</h3><p>Main problem for both approaches: point sampling</p>
<ul>
<li>The central point of each pixel is typically used to detect the coverage of geometry in rasterization, producing aliasing.</li>
<li>The sampled paths in ray tracing are essentially points in the high dimensional pathspace, and such random point sampling of the path space introduces variance.</li>
<li>Since the point samples are discrete, it is difficult to calculate the gradients of the rendering process with respect to scene parameters in order to enable differentiable rendering, especially with discontinuities that are commonly seen, such asboundaries of geometry and shadows.</li>
</ul>
<h3 id="Main-Contribution"><a href="#Main-Contribution" class="headerlink" title="Main Contribution"></a>Main Contribution</h3><ul>
<li>A novel vectorization pipeline different from both ray tracing and rasterization, eliminating point sampling in the 2D integrationdomain, producing fully analytic, accurate and anti-aliased point-to-region shading results.</li>
<li>A hierarchical data structure for efficient, robust, depth-aware andorder-independent insertion and maintenance of polygons, and most important.</li>
<li>A differentiable rendering framework for visibility using only automatic differentiation or finite differences without special treat-ments to the rendering pipeline, resulting in noise-free gradients, which enables second-order optimization methods in inverse rendering for the first time, and orders of magnitude faster performance than existing approaches.</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p><strong>Beam Tracing</strong></p>
<p><strong>Visibility</strong></p>
<p><strong>Hidden Surface Removal</strong></p>
<p><strong>Differentiable Light Transport</strong></p>
<p><strong>Differentiable Rasterization</strong></p>
<p><strong>Automatic Differentiation</strong></p>
<p><strong>Vector Representation in Images</strong></p>
<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><h3 id="The-Point-to-Region-Light-Transport-Problem"><a href="#The-Point-to-Region-Light-Transport-Problem" class="headerlink" title="The Point-to-Region Light Transport Problem"></a>The Point-to-Region Light Transport Problem</h3><p>Many problems in light transport involve solving high dimensional integrals. For the direct illumination from area light sources, which can be formulated as a 4D region-to-region light transport integral:</p>
<p>$$<br>    I&#x3D;\int_{\mathcal P}W(x)\underbrace{\int_AL_e(\pmb y\rightarrow x)f_r(\pmb y\leftrightarrow x\leftrightarrow x_c)G(x\leftrightarrow \pmb y)V(x,\pmb y)\mathrm d\pmb y\mathrm dx}_{&#x3D;:L(\pmb x)}<br>$$</p>
<ul>
<li>$\mathcal P$ : Pixel coverage (pixel footprint)</li>
<li>$A$: the set of area lights</li>
<li>$W(\cdot)$: The pixel reconstruction filter</li>
<li>$L(x)$: The radiance received at a primary shading point $x$<ul>
<li>Integrate over contributions from area light sources</li>
<li>$\pmb y$: A point on the area lights</li>
<li>$L_e$: The emitted radiance</li>
<li>$f_r$: The BRDF</li>
<li>$x_c$: The camera position</li>
<li>$G$: The geometry term</li>
<li>$V$: The binary visibility function</li>
</ul>
</li>
</ul>
<p>Finding an analytic solution to the full 4D region-to-region integral is challenging. This paper presents a geometry vectorization method that can compute its 2D point-to-region sub-problem. The method is based on beam tracing, which traces beams from a shading point $x$ to area lights.</p>
<p>Reformulate the received radiance $L(x)$ as</p>
<p>$$<br>    \begin{aligned}<br>        L(x)&amp;&#x3D;\int_{\mathcal H^2}f_r(x,\omega_i,\omega_o)\left&lt;\pmb n(x),\omega_i\right&gt;V(x,\omega_i)\mathrm d\omega_i\\<br>        &amp;&#x3D;\int_{Q(x)}L_i(x,\omega_i)f_r(x,\omega_i,\omega_o)\left&lt;\pmb n(x),\omega_i\right&gt;\mathrm d\omega_i<br>    \end{aligned}<br>$$</p>
<ul>
<li>$\mathcal H^2$: The hemisphere domain</li>
<li>$\omega_i&#x3D;(y-x)&#x2F;\|y-x\|$: The incoming light direction</li>
<li>$L_i(x,\omega_i)&#x3D;L_e(y\rightarrow x)$: The incoming radiance</li>
<li>$\omega_o&#x3D;(x_c-x)&#x2F;\|x_c-x\|$: The view direction</li>
<li>$\left&lt;\cdot,\cdot\right&gt;$: The clamped dot product</li>
<li>$\pmb n(x)$: The shading normal</li>
<li>$V(x,\omega_i)$: Indicate whether a shadow ray that starts at $x$ towards $\omega_i$ is occluded or not</li>
</ul>
<p>Moving the visibility function from the integrand to the integration domain by defining $Q(x)&#x3D;\{\omega|V(x,\omega)&#x3D;1\}$ as a set of spherical polygons, which are formed by projecting all the visible regions of area lights onto the unit sphere centered at the shading point $x$</p>
<p>Key: computing all the visible regions of area lights $Q(x)$ within the beams using a binary Visibility Bounding Volume Hierarchy</p>
<h3 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h3><h4 id="Practicality"><a href="#Practicality" class="headerlink" title="Practicality"></a>Practicality</h4><p>In practice, most of the 4D region-to-region light transport problem can be factored out into several point-to-region subproblems.</p>
<p>Use a hybrid approach to estimate the 4D region-to-region integral:</p>
<ol>
<li>Sample primary rays within a 2D pixel footprint $\mathcal P$<ul>
<li>Use adaptive sampling similar to MSAA</li>
<li>Group similar regions inside each pixel into at most 4 groups, perform beam tracing once for each group</li>
</ul>
</li>
<li>Trace beams to compute the other 2D point-to-region integral</li>
</ol>
<h4 id="Difficulty"><a href="#Difficulty" class="headerlink" title="Difficulty"></a>Difficulty</h4><ul>
<li>Predicate: detect relationships between geometric primitives, including problems like detecting whether a point is on a line segment<ul>
<li>When implementing themwith floating-point numbers, the numerical inaccuracies are usually ignored or walk-arounded by ùúñ-tweaking in engineering</li>
</ul>
</li>
<li>Construction: such as the hidden surface removal problem, generate new geometric primitives based on predicates<ul>
<li>Require much stronger guarantee on numerical robustness because otherwise, errors will accumulate and will lead to invalid control flow</li>
</ul>
</li>
</ul>
<h2 id="Geometry-Vectorization"><a href="#Geometry-Vectorization" class="headerlink" title="Geometry Vectorization"></a>Geometry Vectorization</h2><p>This paper focus on evaluating 2D point-to-region integrals in the following form:</p>
<p>$$<br>    I&#x3D;L(x)&#x3D;\int_{Q(x)}h(\omega)\mathrm d\omega<br>$$</p>
<ul>
<li>The integration domain $Q(x)&#x3D;\{\omega|V(x,\omega)&#x3D;1\}$ is the visible polygons projected to the unit sphere centered at $x$</li>
<li>$h(\omega)$ represents a general spherical function whose explicit formulation depends on specific rendering application</li>
</ul>
<p>Many problems in rendering, e.g. shading with area lights, can be formulated in this form of integral</p>
<ul>
<li>Usual approach to solve this integral is Monte Carlo integration</li>
<li>For some specific spherical functions used inrendering such as Linearly Transformed Cosines(LTC), integrating them over spherical polygons yields analytic solutions, which is beneficial for noise-free anti-aliased rendering</li>
<li>Therefore, the integral evaluation boils down to computing the visible spherical polygons $Q(x)$</li>
</ul>
<h3 id="Computing-Visible-Polygons"><a href="#Computing-Visible-Polygons" class="headerlink" title="Computing Visible Polygons"></a>Computing Visible Polygons</h3><p>Input: a set of 3D triangles $\{\Delta_i^{3D}\}_{i&#x3D;1}^n$, a beam frustum</p>
<ul>
<li>Assume that every pair of triangles are either disjoint or sharing vertices and edges, i.e., there is no pentration</li>
<li>The beam frustum is defined by a 4x4 perspective projection matrix</li>
</ul>
<p>Therefore, we can transform all the 3D triangles according to the perspective projection matrix. After the projection, all the relevant triangles are in the normalized device coordinate (NDC) space, i.e., the $x$, $y$ and $z$ coordinates of triangle vertices are within $[-1,1]$. The occlusion between the original 3D triangles can be equivalently resolved using a set of 2D projected triangles $\{\Delta_i\}^n_{i&#x3D;1}$ and their depths $\{z_i\}_{i&#x3D;1}^n$</p>
<p>This paper use an interative approach to build a data structure $D&#x3D;\{p_k\}^m_{k&#x3D;1}$ recording all the visible polygons in 2D, as we add the triangles $\{\Delta_i\}_{i&#x3D;1}^n$ one by one.</p>
<ul>
<li>Require  all of the polygons $p_k$ to be convex</li>
<li>Denote $D_i$ as the intermediate result after adding $\Delta_1,\Delta_2,\cdots,\Delta_i$</li>
<li>Initially, $D_0$ only has the square $[-1,1]^2$, indicating the projection of the frustum viewport rectangle at the far plane</li>
<li>The output is $D_n$, indicating all the 2D polygons with the minimum depths.<ul>
<li>They can be mapped to 3D visible polygons within the beam frustum by the inverse perspective projection transformation, and further projected on the unit hemisphere to get the integration domain $Q(x)$</li>
</ul>
</li>
</ul>
<p>Algorithm:</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/image-20221217141040381.png"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/image-20221217141103812.png"></p>
<p>Details at the $i$-th iteration that updates $D_i$ by adding $\Delta_i$</p>
<p><strong>Intersecting</strong></p>
<ul>
<li>Given a new triangle $\Delta_i$, find the convex polygons $p_k\in D_{i-1}$ that overlap with $\Delta_i$, i.e., $\tilde p_k&#x3D;\Delta_i\cap p_k\neq\phi$ </li>
<li>Build a 2D Visibility Bounding Volume Hierarchy (VBVH) to speed up the intersection test and maintain this datastructure as we add new triangles.</li>
<li>Once find the convex polygons $p_k$ that overlap with $\Delta_i$, we can compute their overlapping regions $\tilde p_k$.</li>
<li>Calculate the residual region $r_k&#x3D;p_k\backslash \tilde p_k$ by 2D polygon differencing.</li>
<li>The running time is linear in the number of polygon vertices, indicating that it belongs to the triangle $\Delta_{c_k}$</li>
</ul>
<p><strong>Labeling</strong></p>
<ul>
<li>Each visible convex polygon $p_k$ in $D_{i-1}$ is associated with a label $c_k$</li>
<li>For every overlapping region $\tilde p_k$, we compare the depth values of $\Delta_i$ and $p_k$ (restricting on $\tilde p_k$)<ul>
<li>Given the no-penetrating assumption, the new triangle $\Delta_i$ is either behind or in front of $p_k$</li>
</ul>
</li>
<li>Sometimes it is unnecessary to use a different label for every individual triangle, e.g., shading from area lights, the polygons representing occluders can share the same label</li>
</ul>
<p><strong>Splitting</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/image-20221217150314944.png"></p>
<ul>
<li>For every convex polygon $p_k$ in $D_{i-1}$, it can be decomposed into two disjoint regions $\tilde p_k$ and $r_k&#x3D;p_k\backslash \tilde p_k$</li>
<li>If the two regions have the same label, no changes have to made. Otherwise, need to remove the original polygon $p_k$ and add these two new regions $\tilde p_k$ and $r_k$ to the data structure<ul>
<li>$\tilde p_k$ is a convex polygon since it is the intersection of a convex polygon and a triangle</li>
<li>$r_k$ may be non-convex, need to split it into multiple disjoint convex regions $r_k\bigcup_jr_{k,j}$</li>
</ul>
</li>
<li>The list of convex regions is updated as</li>
</ul>
<p>$$<br>    D_i&#x3D;D_{i-1}-\{p_k\}+\{\tilde p_k\}+\{r_{k,j}\}<br>$$<br><strong>Merging</strong></p>
<ul>
<li>If the new triangle $\Delta_i$ is completely visible, i.e., all the sub-regions $\tilde p_k$ (note that $\Delta_i&#x3D;\bigcup_k\tilde p_k$) are visible and share the same label, we can just add $\Delta_i$ to $D_i$ by merging all of $\tilde p_k$</li>
</ul>
<h3 id="Visibility-Bounding-Volume-Hierarchy"><a href="#Visibility-Bounding-Volume-Hierarchy" class="headerlink" title="Visibility Bounding Volume Hierarchy"></a>Visibility Bounding Volume Hierarchy</h3><ul>
<li>Leaf node: contain a visible convex polygon and its corresponding bounding box</li>
<li>Interior node: store the union of the bounding boxes of its children</li>
</ul>
<p>Support operations:</p>
<p><strong>Intersecting</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/image-20221217152205706.png"></p>
<p><strong>Splitting</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/image-20221217152720372.png"></p>
<p><strong>Merging</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/image-20221217152805995.png"></p>
<h2 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h2><h3 id="Anti-Aliased-Primary-Visibility"><a href="#Anti-Aliased-Primary-Visibility" class="headerlink" title="Anti-Aliased Primary Visibility"></a>Anti-Aliased Primary Visibility</h3><p>Primary visibility is used to determine the occupied area of visiblepolygons inside a pixel. For traditional rasterization or ray tracing methods, it is common to get aliased results due to the insufficient sampling rates, especially at the object‚Äôs boundary regions that have many sub-pixel geometric details.</p>
<p>For each pixel on the image plane, we create a beam that originates from the camera and goes exactly through the pixel. Assuming the pixel is a square of $[-1, 1]^2$, the pixel color is</p>
<p>$$<br>    I&#x3D;\int_{[-1,1]^2}\alpha(\pmb u)c(\pmb u)\mathrm d\pmb u<br>$$</p>
<ul>
<li>$\alpha(\pmb u)$: the binary function indicating whether a position $\pmb u$ inside the pixel is covered by the projected triangles</li>
<li>$c(\pmb u)$ is the color of the triangle</li>
</ul>
<p>Let $\{p_k\}^m_{i&#x3D;1}$ be the set of 2D regions generated by previous visible polygon computation, and $\{c_k\}_{i&#x3D;1}^m$ be the corresponding colors. The pixel color can be reformulated as a summation</p>
<p>$$<br>    I&#x3D;\sum_{k&#x3D;1}^mc_k\underbrace{\int_{p_k}\mathrm d\pmb u}_{&#x3D;:\mathrm{Area}(p_k)}<br>$$</p>
<ul>
<li>The region areas $\mathrm{Area}(p_k)$ can be evaluated analytically given the polygon vertices</li>
<li>Able to compute the exact pixel colors and produce anti-aliased images</li>
</ul>
<h3 id="Accurate-Shading-from-Area-Lights"><a href="#Accurate-Shading-from-Area-Lights" class="headerlink" title="Accurate Shading from Area Lights"></a>Accurate Shading from Area Lights</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/image-20221217155712883.png"></p>
<p>Assume that the area light emits constant radiance $L_e$. The received radiance at a shading point $\pmb x$ from area lights is</p>
<p>$$<br>    I&#x3D;L(\pmb x)&#x3D;L_e\int_{Q(\pmb x)}f_r(\pmb \omega_i,\pmb\omega_o)\left&lt;\pmb n,\pmb\omega_i\right&gt;\mathrm d\pmb\omega_i<br>$$</p>
<p>To compute $Q(\pmb x)$, we create a beam from the shading point $\pmb x$ to the area light sources.</p>
<p>Use previous visible polygon computation to find the visible regions representing the area lights. Then project them onto the unit sphere centered at $\pmb x$ by the inverse perspective projection, resulting in a set of spherical polygons $\{Q_k\}_{k&#x3D;1}^m$. Then we can rewrite the shading integral as</p>
<p>$$<br>    I&#x3D;\sum_{k&#x3D;1}^mL_e\underbrace{\int_{Q_k}f_r(\pmb\omega_i,\pmb\omega_o)\left&lt;\pmb n,\pmb\omega_i\right&gt;\mathrm d\pmb\omega_i}_{&#x3D;:I_k}<br>$$</p>
<p>The integrals over spherical polygons $I_k$ can be approximated analytically using Linearly Transformed Cosines (LTCs). Fitting the cosine-weighted BRDF (the integrand of $I_k$) by an LTC with the transformation matrix $M$. The integral $I_k$ has an analytic solution:</p>
<p>$$<br>    I_k&#x3D;E(\tilde Q_k)&#x3D;\frac{1}{2\pi}\sum_{j&#x3D;1}^N\arccos(\left&lt;\pmb q_j,\pmb q_{j+1}\right&gt;)\left&lt;\frac{\pmb q_j\times\pmb q_{j+1}}{\|\pmb q_j\times\pmb q_{j+1}\|},\hat{\pmb z}\right&gt;<br>$$</p>
<ul>
<li>$E$: the irradiance of the polygon $\tilde Q_k&#x3D;M^{-1}Q_k$</li>
<li>$\pmb q_j$: the $j$-th vertex of the polygon $\tilde Q_k$, define $\pmb q_{N+1}&#x3D;\pmb q_1$</li>
<li>$\hat{\pmb z}&#x3D;(0,0,1)$</li>
</ul>
<h3 id="Anti-Aliased-Shadows-from-Point-Lights"><a href="#Anti-Aliased-Shadows-from-Point-Lights" class="headerlink" title="Anti-Aliased Shadows from Point Lights"></a>Anti-Aliased Shadows from Point Lights</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/image-20221217162714272.png"></p>
<p>The shading of a polygonal surface patch that is seen through a pixel and is lit by a point light can be formulated as a 2D integral:</p>
<p>$$<br>    I&#x3D;\int_{\mathcal P}W(\pmb x)f_r(\pmb \omega_i,\pmb\omega_o)L_i(\pmb x,\pmb\omega_i)\left&lt;\pmb n(\pmb x),\pmb\omega_i\right&gt;V(\pmb x,\pmb\omega_i)\mathrm d\pmb x<br>$$</p>
<ul>
<li>$\pmb \omega_i&#x3D;(\pmb x_l-\pmb x)&#x2F;\|\pmb x_l-\pmb x\|$: light direction<ul>
<li>$\pmb x_l$: point light position</li>
<li>$\pmb x$: shading position</li>
</ul>
</li>
</ul>
<p>Assuming the footprint is small enough compared to the size of the scene, we can approximate by splitting the integral into two parts:</p>
<p>$$<br>I\approx\int_{\mathcal P}W(\pmb x)f_r(\pmb \omega_i,\pmb\omega_o)L_i(\pmb x,\pmb\omega_i)\left&lt;\pmb n(\pmb x),\pmb\omega_i\right&gt;\mathrm d\pmb x \cdot\int_{\mathcal P}V(\pmb x,\pmb \omega_i)\mathrm d\pmb x<br>$$</p>
<ul>
<li>The first integral $I_{\mathrm{unshadow}}$ represents the unshadowed contribution, where the integrand terms vary smoothly<ul>
<li>It usually can be evaluated easily by taking one or a few samples on the pixel footprint</li>
</ul>
</li>
<li>To compute the visibility integral in the second part $I_{\mathrm{vis}}$, we trace a narrow beam from the light that encloses the patch, and compute the regions that are visible to the point light $Q(\mathcal P)&#x3D;\{\pmb x|V(\pmb x,\pmb \omega_i)&#x3D;1\}$ by the paper‚Äôs vectorization method.</li>
</ul>
<p>The second visibility integral becomes the area of the visible polygons:</p>
<p>$$<br>    I_{\mathrm{vis}}&#x3D;\int_{Q(\mathcal P)}\mathrm d\pmb x<br>$$</p>
<p>which has analytic solutions given polygon vertices</p>
<p>In practice, instead of computing the visible polygons $Q(\mathcal P)$ for each pixel footprint, usually precompute a vectorized shadow map that records all visible polygons from all directions as viewed from the light position.</p>
<h3 id="Pure-Specular-Reflection"><a href="#Pure-Specular-Reflection" class="headerlink" title="Pure Specular Reflection"></a>Pure Specular Reflection</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/image-20221217163024463.png"></p>
<h3 id="Differentiable-Rendering"><a href="#Differentiable-Rendering" class="headerlink" title="Differentiable Rendering"></a>Differentiable Rendering</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/image-20221217163249758.png"></p>
<p>Vectorization analytically finds all visibility discontinuties, therefore, automatic differentiation just works.</p>
<p>Example: Primary visibility</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/image-20221217163538470.png"></p>
<p>$$<br>    \begin{aligned}<br>        I&amp;&#x3D;\int_{[-1,1]^2}\alpha(\pmb u)c(\pmb u)\mathrm d\pmb u\\<br>        &amp;&#x3D;\sum_{k&#x3D;1}^mc_k\mathrm{Area}(p_k)<br>    \end{aligned}<br>$$</p>
<p>$$<br>    \frac{\partial I}{\partial\theta}&#x3D;\sum_{k&#x3D;1}^mc_k\frac{\partial}{\partial \theta}\mathrm{Area}(p_k)<br>$$</p>
<h2 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/image-20221217170127239.png"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/image-20221217170152863.png"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/image-20221217170207000.png"></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>Analytic 2D point-to-region visibility</li>
<li>Noise-free rendering</li>
<li>Noise-free differentiable rendering</li>
</ul>
<h3 id="Future-Work"><a href="#Future-Work" class="headerlink" title="Future Work"></a>Future Work</h3><ul>
<li>Extend to higher dimensions<ul>
<li>4D region-to-region visibility</li>
<li>Global illumination</li>
</ul>
</li>
<li>More optimization<ul>
<li>VBVH refitting</li>
<li>Exact vs. approximate</li>
</ul>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="https://chaphlagical.github.io">Chaf Chen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://chaphlagical.github.io/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/">https://chaphlagical.github.io/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Differentiable-Rendering/">Differentiable Rendering</a><a class="post-meta__tags" href="/tags/Rendering/">Rendering</a><a class="post-meta__tags" href="/tags/TOG-2021/">TOG 2021</a></div><div class="post_share"><div class="social-share" data-image="/img/logo.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/12/29/gaming/spiderman_miles/" title="Marvel's Spider-Man Miles Morales"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/29/gaming/spiderman_miles/image-20221229175057590.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Marvel's Spider-Man Miles Morales</div></div></a></div><div class="next-post pull-right"><a href="/2022/12/14/note/edge_sampling/" title="Physics Based Differentiable Rendering: Edge Sampling"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Physics Based Differentiable Rendering: Edge Sampling</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2022/12/13/note/differentiable_rendering_basic/" title="Physics Based Differentiable Rendering: Preliminaries"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-13</div><div class="title">Physics Based Differentiable Rendering: Preliminaries</div></div></a></div><div><a href="/2022/12/14/note/edge_sampling/" title="Physics Based Differentiable Rendering: Edge Sampling"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-14</div><div class="title">Physics Based Differentiable Rendering: Edge Sampling</div></div></a></div><div><a href="/2023/01/25/paper_reading/Adaptive_Incident_Radiance_Field_Sampling_and_Reconstruction_Using_Deep_Reinforcement_Learning/" title="Adaptive Incident Radiance Field Sampling and Reconstruction Using Deep Reinforcement Learning"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-25</div><div class="title">Adaptive Incident Radiance Field Sampling and Reconstruction Using Deep Reinforcement Learning</div></div></a></div><div><a href="/2021/08/29/paper_reading/Low_Cost_SPAD_Sensing_for_Non_Line_Of_Sight_Tracking_Material/" title="Low-Cost SPAD Sensing for Non-Line-Of-Sight Tracking, Material Classification and Depth Imaging"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-29</div><div class="title">Low-Cost SPAD Sensing for Non-Line-Of-Sight Tracking, Material Classification and Depth Imaging</div></div></a></div><div><a href="/2021/08/25/paper_reading/Neural_Light_Transport_for_Relighting_and_View_Synthesis/" title="Neural Light Transport for Relighting and View Synthesis"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-25</div><div class="title">Neural Light Transport for Relighting and View Synthesis</div></div></a></div><div><a href="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/" title="Temporal Coherence-based Distributed Ray Tracing of Massive Scenes"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-06</div><div class="title">Temporal Coherence-based Distributed Ray Tracing of Massive Scenes</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/logo.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Chaf Chen</div><div class="author-info__description">USTC CG Student</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">33</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Chaphlagical"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Chaphlagical" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:mail@ustc.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Looking for a Ph.D position!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Main-Problem"><span class="toc-number">1.1.</span> <span class="toc-text">Main Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Main-Contribution"><span class="toc-number">1.2.</span> <span class="toc-text">Main Contribution</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Related-Work"><span class="toc-number">2.</span> <span class="toc-text">Related Work</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Overview"><span class="toc-number">3.</span> <span class="toc-text">Overview</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Point-to-Region-Light-Transport-Problem"><span class="toc-number">3.1.</span> <span class="toc-text">The Point-to-Region Light Transport Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Analysis"><span class="toc-number">3.2.</span> <span class="toc-text">Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Practicality"><span class="toc-number">3.2.1.</span> <span class="toc-text">Practicality</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Difficulty"><span class="toc-number">3.2.2.</span> <span class="toc-text">Difficulty</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Geometry-Vectorization"><span class="toc-number">4.</span> <span class="toc-text">Geometry Vectorization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Computing-Visible-Polygons"><span class="toc-number">4.1.</span> <span class="toc-text">Computing Visible Polygons</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Visibility-Bounding-Volume-Hierarchy"><span class="toc-number">4.2.</span> <span class="toc-text">Visibility Bounding Volume Hierarchy</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Application"><span class="toc-number">5.</span> <span class="toc-text">Application</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Anti-Aliased-Primary-Visibility"><span class="toc-number">5.1.</span> <span class="toc-text">Anti-Aliased Primary Visibility</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Accurate-Shading-from-Area-Lights"><span class="toc-number">5.2.</span> <span class="toc-text">Accurate Shading from Area Lights</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Anti-Aliased-Shadows-from-Point-Lights"><span class="toc-number">5.3.</span> <span class="toc-text">Anti-Aliased Shadows from Point Lights</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Pure-Specular-Reflection"><span class="toc-number">5.4.</span> <span class="toc-text">Pure Specular Reflection</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Differentiable-Rendering"><span class="toc-number">5.5.</span> <span class="toc-text">Differentiable Rendering</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Result"><span class="toc-number">6.</span> <span class="toc-text">Result</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion"><span class="toc-number">7.</span> <span class="toc-text">Conclusion</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Summary"><span class="toc-number">7.1.</span> <span class="toc-text">Summary</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Future-Work"><span class="toc-number">7.2.</span> <span class="toc-text">Future Work</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/01/25/paper_reading/Adaptive_Incident_Radiance_Field_Sampling_and_Reconstruction_Using_Deep_Reinforcement_Learning/" title="Adaptive Incident Radiance Field Sampling and Reconstruction Using Deep Reinforcement Learning">Adaptive Incident Radiance Field Sampling and Reconstruction Using Deep Reinforcement Learning</a><time datetime="2023-01-25T00:04:00.000Z" title="Created 2023-01-25 00:04:00">2023-01-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/" title="Temporal Coherence-based Distributed Ray Tracing of Massive Scenes">Temporal Coherence-based Distributed Ray Tracing of Massive Scenes</a><time datetime="2023-01-06T22:13:11.000Z" title="Created 2023-01-06 22:13:11">2023-01-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/29/gaming/spiderman_miles/" title="Marvel's Spider-Man Miles Morales"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/29/gaming/spiderman_miles/image-20221229175057590.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Marvel's Spider-Man Miles Morales"/></a><div class="content"><a class="title" href="/2022/12/29/gaming/spiderman_miles/" title="Marvel's Spider-Man Miles Morales">Marvel's Spider-Man Miles Morales</a><time datetime="2022-12-29T21:13:11.000Z" title="Created 2022-12-29 21:13:11">2022-12-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/" title="Vectorization for Fast, Analytic, and Differentiable Visibility">Vectorization for Fast, Analytic, and Differentiable Visibility</a><time datetime="2022-12-17T21:13:11.000Z" title="Created 2022-12-17 21:13:11">2022-12-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/12/14/note/edge_sampling/" title="Physics Based Differentiable Rendering: Edge Sampling">Physics Based Differentiable Rendering: Edge Sampling</a><time datetime="2022-12-14T00:00:00.000Z" title="Created 2022-12-14 00:00:00">2022-12-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Chaf Chen</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'https://chaphlagical.github.io/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/'
    this.page.identifier = '/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/'
    this.page.title = 'Vectorization for Fast, Analytic, and Differentiable Visibility'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://chaphlagical-github-io.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }

  document.getElementById('darkmode').addEventListener('click', () => {
    setTimeout(() => window.disqusReset(), 200)
  })
}

if ('Disqus' === 'Disqus' || !false) {
  if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div></div></body></html>