---
bg: "2019-03-18.jpg"
layout: post
title:  "LeNet解读"
crawlertitle: "LeNet解读"
summary: "LeNet解读"
date:   2019-03-18 21:03:13 +0700
categories: posts
tags: ['计算机视觉']
author: Chaf
---

本文介绍LeNet神经网络结构

# 基本结构

![](/home/chaf/Chaphlagical.github.io/assets/images/CV/lenet.png)

LeNet神经网络由三层卷积层、两层池化层和两层全连接层构成。

# 结构详解

## 1、输入层（INPUT）

输入图像尺寸统一为$32\times32$

## 2、卷积层（C1）

1、 输入：$32\times32$ 

2、卷积核大小：$5\times5​$

3、滤波器数量：6

4、神经元数量：$28\times28\times6​$

5、输出的特征图大小：$28\times28​$

6、可训练的参数数：$(5\times5+1)\times6=156​$ 

7、连接数：$(5\times5+1)\times28\times28\times6=122,304$

**分析：**

对于卷积层C1，C1内的每个像素都与输入图像中的$5\times 5$个像素和1个bias有连接，所以总共有$156\times 28\times 28=122304$个连接，每一个滤波器共享参数，故只需要训练156个参数。

## 3、池化层/下采样层（S2）

1、 输入：$28\times28 ​$ 

2、采样区域：$2\times2​$

3、神经元数量：$14\times14\times6=1176​$ 

4、输出的特征图大小：$14\times14​$

5、采样方式：采样区域内四个值相加乘以一个权值后加上一个偏置，结果通过sigmoid函数

6、采样种类：6

7、可训练参数数：$2\times6=12​$（权值与偏置）

8、连接数：$(2\times2+1)\times14\times14\times6=5880$

**分析：**

使用$2\times 2$核进行池化运算，将池化区域内四个像素值相加乘以一个系数加上偏置并进行一次映射，每个池化需要权重和偏置两个参数，故一共有12个可训练参数，但每个

## 4、卷积层（C3）

1、 输入：S2中所有6个或者几个特征map组合

2、卷积核大小：$5\times5​$

3、滤波器数量：16

4、神经元数量：$28\times28\times6​$

5、输出的特征图大小：$10\times10$

6、可训练的参数数：$(5\times5+1)\times6=156​$ （一个滤波器共享一个权值）

7、连接数：$(5\times5+1)\times28\times28\times6=122,304​$

## 

4、神经元数量：$28\times28\times6$

5、输出的特征图大小：$28\times28$

6、可训练的参数数：$(5\times5+1)\times6=156$ （一个滤波器共享一个权值）

7、连接数：$(5\times5+1)\times28\times28\times6=122,304$

## 