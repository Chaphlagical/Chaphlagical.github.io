<!DOCTYPE html><html lang="[&quot;en&quot;,&quot;zh-CN&quot;,&quot;default&quot;]" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>GPU Accelerated Path Tracing of Massive Scenes | Chaf's Blog</title><meta name="author" content="Chaf Chen"><meta name="copyright" content="Chaf Chen"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="Siggraph 2021 paper reading">
<meta property="og:type" content="article">
<meta property="og:title" content="GPU Accelerated Path Tracing of Massive Scenes">
<meta property="og:url" content="https://chaphlagical.github.io/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/index.html">
<meta property="og:site_name" content="Chaf&#39;s Blog">
<meta property="og:description" content="Siggraph 2021 paper reading">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://chaphlagical.github.io/img/logo.jpg">
<meta property="article:published_time" content="2021-08-15T20:34:00.000Z">
<meta property="article:modified_time" content="2023-03-03T07:54:56.868Z">
<meta property="article:author" content="Chaf Chen">
<meta property="article:tag" content="Rendering">
<meta property="article:tag" content="Siggraph 2021">
<meta property="article:tag" content="Distributed Computing">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://chaphlagical.github.io/img/logo.jpg"><link rel="shortcut icon" href="/img/logo.jpg"><link rel="canonical" href="https://chaphlagical.github.io/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'GPU Accelerated Path Tracing of Massive Scenes',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-03 07:54:56'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (false) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/logo.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">33</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Chaf's Blog"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/logo.jpg"/><span class="site-name">Chaf's Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">GPU Accelerated Path Tracing of Massive Scenes</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-08-15T20:34:00.000Z" title="Created 2021-08-15 20:34:00">2021-08-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-03-03T07:54:56.868Z" title="Updated 2023-03-03 07:54:56">2023-03-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper-Reading/">Paper Reading</a></span></div><div class="meta-secondline"></div></div></div><article class="post-content" id="article-container"><p><strong>Author</strong>: <em>MILAN JAROŠ</em>, <em>LUBOMÍR ŘÍHA</em>, <em>PETR STRAKOŠ</em>, and <em>MATĚJ ŠPEŤKO</em>  </p>
<p><strong>Institution</strong>: IT4Innovations, VSB–Technical University of Ostrava, Czech Republic  </p>
<p><strong>Link</strong>: <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3447807">https://dl.acm.org/doi/10.1145/3447807</a></p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p><strong>GPUs Rendering vs CPUs Rendering</strong></p>
<ul>
<li>Limited memory size</li>
<li>Example: Pixar’s Coco movie were using up to 120GB, do not fit into the memory of a single GPU</li>
</ul>
<p><strong>Main contribution</strong></p>
<ul>
<li><p>A solution to GPUs rendering memory size limitation</p>
<ul>
<li>Based on replication of a small amount of scene data, between 1% ~ 5%, and well-chosen distribution of the rest of the data into the memory of several GPUs</li>
<li>Both replication and distribution of data is based on a memory access pattern analysis of a path tracer during a 1spp prepass  </li>
<li>The data with the highest number of memory accesses are replicated and the rest is stored only in the memory of the GPU that had the highest number of accesses to it  </li>
<li>Minimizes the penalty associated with reading data from the remote memory and is effective at providing near-linear scalability</li>
</ul>
</li>
<li><p>Demonstration that our proposed approach works on a memory management level  </p>
<ul>
<li>Any path tracing code that supports GPU acceleration using CUDA can adopt our approach without redesigning its internal data structures</li>
</ul>
</li>
</ul>
<p><strong>Two key technologies</strong></p>
<ul>
<li>NVLink GPU Interconnect<ul>
<li>Enables multiple GPUs to efficiently share the content of their memories due to its high bandwidth and low latency</li>
</ul>
</li>
<li>CUDA Unified Memory(UM)<ul>
<li>Provides programmers with control over data placement across the memories of interconnected GPUs</li>
</ul>
</li>
</ul>
<h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h2><h3 id="2-1-Out-of-core-Rendering"><a href="#2-1-Out-of-core-Rendering" class="headerlink" title="2.1. Out-of-core Rendering"></a>2.1. Out-of-core Rendering</h3><ul>
<li>Out of core rendering is the capability to render (with GPUs) scenes requiring more memory than the one directly connected to the device</li>
<li>It will use the system’s memory instead</li>
</ul>
<h3 id="2-2-Distributed-Rendering"><a href="#2-2-Distributed-Rendering" class="headerlink" title="2.2. Distributed Rendering"></a>2.2. Distributed Rendering</h3><ul>
<li>sort first: Image based partitioning</li>
<li>sort middle: Related to rasterization only</li>
<li>sort last: Use scene data distribution</li>
</ul>
<h4 id="2-2-1-Image-Parallel-Rendering"><a href="#2-2-1-Image-Parallel-Rendering" class="headerlink" title="2.2.1. Image-Parallel Rendering"></a>2.2.1. Image-Parallel Rendering</h4><ul>
<li>Distribute among processors or machines per blocks of pixels of a rendered image</li>
<li>Most common and efficient way the scene data is fully replicated in all local memories and ray tracing is embarrassingly parallel</li>
<li>In the case of ray tracing complex scenes that do not fit into local memory, this approach results in on-demand scene data movement while rays remains fixed (Moving scene data instead of ray data)</li>
<li>Our proposed solution is based on scene data communication while rays never leave the GPU they are created on</li>
</ul>
<h4 id="2-2-2-Data-Parallel-Rendering"><a href="#2-2-2-Data-Parallel-Rendering" class="headerlink" title="2.2.2. Data-Parallel Rendering"></a>2.2.2. Data-Parallel Rendering</h4><ul>
<li>Distribute the workload by subdividing the scene data</li>
<li>In the case of distributed ray tracing, these approaches transfer ray data among processors or machines, while scene data do not move after the initial distribution (Moving ray data instead of scene data)</li>
</ul>
<h3 id="2-3-Distributed-Shared-Memory-Systems"><a href="#2-3-Distributed-Shared-Memory-Systems" class="headerlink" title="2.3. Distributed Shared Memory Systems"></a>2.3. Distributed Shared Memory Systems</h3><ul>
<li>Shared Memory Processors (SMP) &amp; Distributed Shared Memory (DSM)<ul>
<li>Local memory with caches</li>
<li>Hardware or software layer transparently creates an illusion of global shared memory for applications</li>
</ul>
</li>
<li>The latency to access remote data is considerably larger than the latency to access local data  <ul>
<li>good data locality is therefore critical for high performance</li>
</ul>
</li>
</ul>
<h3 id="2-4-CUDA-Unified-Memory-For-Multi-GPU-Systems"><a href="#2-4-CUDA-Unified-Memory-For-Multi-GPU-Systems" class="headerlink" title="2.4. CUDA Unified Memory For Multi-GPU Systems"></a>2.4. CUDA Unified Memory For Multi-GPU Systems</h3><ul>
<li>UM Manages communication between multiple GPUs and CPUs transparently by adopting DSM techniques</li>
<li>UM simplifies both out-of-core processing between GPUs and CPUs as well as multi-GPU processing and combinations of both  </li>
<li>NVLink interconnect is the key enabler of DSM multi-GPU system</li>
</ul>
<h2 id="3-Blender-Cycles-Path-Tracer"><a href="#3-Blender-Cycles-Path-Tracer" class="headerlink" title="3. Blender Cycles Path Tracer"></a>3. Blender Cycles Path Tracer</h2><ul>
<li>An unbiased renderer based on unidirectional path tracing that supports CPU and GPU rendering  </li>
<li>For acceleration it uses a Bounding Volume Hierarchy (BVH)  </li>
<li>Supports CUDA, Optix, and OpenCL</li>
</ul>
<h3 id="3-1-Extensions-for-Multi-GPU-Support"><a href="#3-1-Extensions-for-Multi-GPU-Support" class="headerlink" title="3.1. Extensions for Multi-GPU Support"></a>3.1. Extensions for Multi-GPU Support</h3><p>Workflow:</p>
<ol>
<li>distribute the data structures evenly among all GPUs  </li>
<li>run the kernel with memory access counters and get the memory access statistics  </li>
<li>redistribute the data structures among GPUs based on memory access statistics  </li>
<li>run the original path-tracing kernel with redistributed data</li>
</ol>
<h3 id="3-2-Multi-GPU-Benchmark-Systems"><a href="#3-2-Multi-GPU-Benchmark-Systems" class="headerlink" title="3.2. Multi-GPU Benchmark Systems"></a>3.2. Multi-GPU Benchmark Systems</h3><ol>
<li><p>BullSequana X410-E5 NVLink-V blade server</p>
<ul>
<li>with 4 Tesla V100 GPUs, each with 16 GB of memory and direct NVLink interconnect</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815200655447.png" alt="image-20210815200655447.png"></p>
</li>
<li><p>NVidia DGX-2</p>
<ul>
<li>able to process massive scenes of sizes up to 512 GB in the shared memory of its 16 Tesla V100 GPUs, each with 32 GB of memory</li>
<li>The uniqueness of this platform is the enhancement of the NVLink interconnect by using NVSwitches, which enable the connection of all 16 GPUs and higher bandwidth</li>
</ul>
</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815200711051.png" alt="image-20210815200711051.png"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815094513710.png" alt="image-20210815094513710.png"></p>
<h3 id="3-3-Benchmark-Scenes"><a href="#3-3-Benchmark-Scenes" class="headerlink" title="3.3. Benchmark Scenes"></a>3.3. Benchmark Scenes</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815094628983.png" alt="image-20210815094628983"></p>
<h2 id="4-Data-Distributed-Multi-GPU-Path-Tracing"><a href="#4-Data-Distributed-Multi-GPU-Path-Tracing" class="headerlink" title="4. Data Distributed Multi-GPU Path Tracing"></a>4. Data Distributed Multi-GPU Path Tracing</h2><h3 id="4-1-Basic-Distribution-of-Entire-Data-Structures"><a href="#4-1-Basic-Distribution-of-Entire-Data-Structures" class="headerlink" title="4.1. Basic Distribution of Entire Data Structures"></a>4.1. Basic Distribution of Entire Data Structures</h3><h4 id="4-1-1-Memory-Access-Analysis"><a href="#4-1-1-Memory-Access-Analysis" class="headerlink" title="4.1.1. Memory Access Analysis"></a>4.1.1. Memory Access Analysis</h4><ul>
<li>Define the order in which data structures are replicated as a ratio of the total memory accesses to a particular data structure over its size</li>
<li>The analysis was done on the first sample when rendering the scenes with a resolution of 5,120x2,560 pixels</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815101537608.png" alt="image-20210815101537608.png"></p>
<ul>
<li><em>small_structures</em>: a set of data structures smaller than 16MB (the most important one is svm_nodes, which stores Shader Virtual Machine (SVM) data and codes)</li>
<li><em>bvh_node</em>: stores the BVH tree without its leaves (leaves are stored in a separate structure)</li>
<li><em>prim_tri_verts</em>: holds coordinates of all vertices in the scene</li>
<li><em>prim_tri_index</em>: a set of all triangles in the scene and it contains indices to the prim_tri_verts</li>
</ul>
<p>We can see that:</p>
<ul>
<li>The most important data structure is <em>bvh_nodes</em>, because it is responsible for 79.6% of all memory accesses  <ul>
<li>If it is replicated in the memory of all GPUs, the 79.6% of all memory accesses will be to the local memory</li>
<li>The size of this structure is 7.2 GB, which represents 26.5% of the entire scene size</li>
</ul>
</li>
<li>If in addition to <em>small_structures</em> and <em>bvh_nodes</em>, <em>prim_tri_index</em> and <em>prim_tri_verts</em> are also replicated, then the relative rendering time is only 109% while 40.7% of the scene is replicated and the rest is distributed</li>
</ul>
<h4 id="4-1-2-Performance-and-Scalability-Evaluation"><a href="#4-1-2-Performance-and-Scalability-Evaluation" class="headerlink" title="4.1.2. Performance and Scalability Evaluation"></a>4.1.2. Performance and Scalability Evaluation</h4><p>The scalability of the proposed approach is evaluated for four different cases:  </p>
<ol>
<li>all data structures are replicated—this case serves as a baseline as it achieves the best performance and scalability  </li>
<li>all data structures are evenly distributed  <ul>
<li>continuous distribution: the structures are divided into large chunks of a size equal to the structure size over a number of GPUs, and each GPU owns one chunk  </li>
<li>round robin distribution: the distributed structure is divided into chunks of 2 MB, which are distributed in a round robin fashion</li>
</ul>
</li>
<li><em>small structures</em> and <em>bvh_nodes</em> are replicated while all other data structures are distributed</li>
<li><em>small structures</em>, <em>bvh_nodes</em>, <em>prim_tri_index</em>, and <em>prim_tri_verts</em> are replicated while all other data structures are distributed</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815105113549.png" alt="image-20210815105113549.png"></p>
<p>Result:</p>
<ol>
<li>round robin distribution of small chunks performs better than continuous distribution of large chunks, therefore it is always used to distribute non-replicated data structures  </li>
<li>path tracing with fully distributed data structures does not scale on both platforms (there is reasonable scalability for two GPUs on DGX-2, but not beyond that)  </li>
<li>if <em>small structures</em> and <em>bvh_nodes</em> are replicated, the scalability is significantly improved</li>
<li>if <em>small structures</em>, <em>bvh_nodes</em>, <em>prim_tri_index</em>, and <em>prim_tri_verts</em> are replicated, the scalability is further improved</li>
</ol>
<h3 id="4-2-Advanced-Distribution-Based-on-Memory-Access-Pattern-and-Statistics"><a href="#4-2-Advanced-Distribution-Based-on-Memory-Access-Pattern-and-Statistics" class="headerlink" title="4.2. Advanced Distribution Based on Memory Access Pattern and Statistics"></a>4.2. Advanced Distribution Based on Memory Access Pattern and Statistics</h3><ul>
<li><p>The data placement is done with chunks, and hints are set for each chunk individually  </p>
</li>
<li><p>The optimal chunk size was identified experimentally by benchmarking the path tracer performance for chunks of sizes from 64 kB to 128 MB:</p>
<ul>
<li>for scenes smaller than 30 GB the optimal chunk size is 2 MB (smaller chunks are not recommended)  </li>
<li>for scenes of sizes around 40 GB the optimal chunk size is 16 MB  </li>
<li>for scenes of sizes above 120 GB the optimal chunk size is 64 MB</li>
</ul>
</li>
<li><p>The workflow of this data placement strategy:</p>
<ol>
<li>copy&#x2F;distribute every data structure across all GPUs in a round robin fashion using chunks of an optimal size</li>
<li>run the path tracing kernel with memory access counters for 1spp to measure the statistics</li>
<li>gather the statistics on the CPU and run the proposed algorithm to get the optimal data chunks distribution  </li>
<li>use <em>cudaMemAdvise</em> to migrate or replicate all chunks</li>
<li>run the original unmodified path tracing kernel</li>
</ol>
</li>
</ul>
<h4 id="4-2-1-Memory-Access-Pattern-Analysis"><a href="#4-2-1-Memory-Access-Pattern-Analysis" class="headerlink" title="4.2.1. Memory Access Pattern Analysis"></a>4.2.1. Memory Access Pattern Analysis</h4><ul>
<li><p>To identify the memory access pattern, per chunk access counters have been implemented in the GPU path tracing kernel of Cycles  </p>
<ul>
<li>Independent counters for all data structures and all their chunks</li>
<li>A total number of memory accesses per chunk can be recorded for each GPU</li>
</ul>
</li>
<li><p>The memory analysis starts with all data structures being evenly distributed using a round robin distribution</p>
<ul>
<li>The modified path tracing kernel with memory access counters is executed on all GPUs for one sample</li>
</ul>
</li>
<li><p>When the kernel finishes, then for every chunk of every structure, a number of accesses from all GPUs is recorded</p>
<ul>
<li>The workload is distributed among GPUs by horizontal stripes so that each GPU works on one stripe</li>
</ul>
</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815151251218.png" alt="image-20210815151251218.png"></p>
<ul>
<li>1% of scene data covers between 56.7% and 74.4% of memory accesses, depending on the scene size  </li>
<li>This analysis shows that there are clear candidates among the chunks that should be replicated on all GPUs, while a major portion of the data is accessed infrequently and can be distributed with an acceptable impact on performance.</li>
</ul>
<h4 id="4-2-2-Data-Placement-Algorithm-Based-on-Memory-Access-Pattern"><a href="#4-2-2-Data-Placement-Algorithm-Based-on-Memory-Access-Pattern" class="headerlink" title="4.2.2. Data Placement Algorithm Based on Memory Access Pattern"></a>4.2.2. Data Placement Algorithm Based on Memory Access Pattern</h4><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815200844083.png" alt="image-20210815200844083"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815151701943.png" alt="image-20210815151701943"></p>
<ol>
<li><p>The per GPU counters are summed to get the total number of accesses $a_{sum}$ for each chunk $c\in C$ of each data structure $s\in S$ and $a(a_{sum},s,c)$ tuple is created</p>
</li>
<li><p>All tuples are put into a single 1D array $H_{comb}$. The array is sorted by $a_{sum}$ from largest value to the smallest one and stored in $H_{&lt;}$ array</p>
</li>
<li><p>The last input of the algorithm is the number of chunks that can be replicated $N_{dup}$. This value can either be set manually or automatically using formula:<br>$$<br>N_{dup}&#x3D;\dfrac{1}{C_s}\Big(G_f-\frac{S_s}{N_g}\Big)<br>$$</p>
<ul>
<li>$G_f$: the amount of free memory per GPU in MB available to store scene data</li>
<li>$S_s$: scene size in MB</li>
<li>$N_g$: total number of GPUs</li>
<li>$C_s$: the chunk size in MB</li>
</ul>
</li>
<li><p>Define a threshold $t$ as the $N_{dup}$-th element in the sorted array $H_&lt;$ and evaluate all tuples in the array $H_&lt;$. If the counter value $a_{sum}$ is larger than $t$, then the corresponding chunk will be set as <em>SetReadMostly</em>, and therefore replicated</p>
<ul>
<li>In the opposite case, the chunk is set as <em>SetPreferredLocation</em> and is assigned to the GPU with the highest number of accesses to this chunk<ul>
<li>If the memory of this GPU is full, then the GPU with second, third, fourth, and so on, highest number of accesses is selected until a GPU with free memory is found.</li>
</ul>
</li>
<li>It the counter value is equal to zero (without any accesses), then the corresponding chunk will be distributed in a round robin fashion across GPUs with free memory</li>
</ul>
</li>
</ol>
<h4 id="4-2-3-Performance-Evaluation"><a href="#4-2-3-Performance-Evaluation" class="headerlink" title="4.2.3. Performance Evaluation"></a>4.2.3. Performance Evaluation</h4><ul>
<li>The performance of the proposed algorithm was evaluated for different ratios between replicated and distributed data at a 2 MB chunk level of granularity for the Moana 12 and 27 GB scenes</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815170302733.png" alt="image-20210815170302733.png"></p>
<ul>
<li>Figure shows the path tracing performance for one sample per pixel and 5,120x2,560 pixel resolution for both scenes and platforms, and for all available GPUs</li>
<li>Once at least 1% of chunks are replicated, the performance is almost identical</li>
</ul>
<h4 id="4-2-4-Maximum-Scene-Size-Analysis"><a href="#4-2-4-Maximum-Scene-Size-Analysis" class="headerlink" title="4.2.4. Maximum Scene Size Analysis"></a>4.2.4. Maximum Scene Size Analysis</h4><p>The following equation describes the maximum ratio of replicated data that fits into the memory of GPU memory for a scene of a given size:<br>$$<br>N_{max_dup}&#x3D;\frac{\Big(G_f-\frac{S_s}{N_g}\Big)}{\Big(S_s-\frac{S_s}{N_g}\Big)}<br>$$</p>
<ul>
<li>$G_f$: the amount of free memory per GPU in MB available to store the scene data</li>
<li>$S_s$: the scene size in MB</li>
<li>$N_g$: total number of GPUs</li>
</ul>
<h2 id="5-Performance-for-massive-scenes"><a href="#5-Performance-for-massive-scenes" class="headerlink" title="5. Performance for massive scenes"></a>5. Performance for massive scenes</h2><p><strong>Group 1</strong>: <em>Moana</em> 38 GB, <em>Museum</em> 41 GB, <em>Agent</em> 37 GB, and <em>Spring</em> 41 GB are designed to stress the <em>Barbora</em> GPU server with 64 GB of total GPU memory  </p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815171434217.png" alt="image-20210815171434217.png"></p>
<ul>
<li>the performance of the <em>Barbora</em> server is almost identical to the performance of DGX-2 for the same amount of scene replication (up to 10%)  </li>
<li>DGX-2 is able to further replicate scene data up to 60%, which improves performance by 2.8% only in the case of the Moana 38 GB scene (for the other scenes the performance is higher by only less than 1%)  </li>
<li>This means that for scenes of sizes approximately up to 45 GB distributed over 4 GPUs, the significantly less complex and cheaper GPU interconnect in the <em>Barbora</em> server is sufficient</li>
<li>For the Museum, Agent, and Spring scenes 2% of scene replication attains optimal performance. This holds for 4, 8, and 16 GPUs</li>
<li>Only the Moana scene needs higher amounts of replicated data, up to 25% for 16 GPUs</li>
<li>Scalability can be evaluated on DGX-2 for 4, 8, and 16 GPUs only. For the Moana, Museum, Agent, and Spring scenes, for 5% scene replication, the parallel efficiencies, going from 4 to 16 GPUs, are 82.7%, 97.1%, 97.9%, and 98.1%, respectively. In the case of the Moana scene, a higher replication ratio is needed to improve scalability, e.g., for 25% data replication ratio the parallel efficiency is 94.4%</li>
</ul>
<p><strong>Group 2</strong>: Moana 169 GB, Museum 124 GB, Agent 167 GB, and Spring 137 GB are designed to stress the DGX-2 server with 512 GB of total GPU memory  </p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815172628673.png" alt="image-20210815172628673.png"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815195203217.png" alt="image-20210815195203217.png"></p>
<ul>
<li>The performance is affected by selecting the right chunk size, particularly for the Moana scene</li>
<li>For 8 GPUs and the Moana, Agent, and Spring scenes, if the replication ratio is 10% the scene does not fit into GPU shared memory anymore and chunks are swapped between GPU and CPU memory (the default behavior of the CUDA Unified Memory), which makes the rendering several times slower depending on the number of chunks being moved back and forth. This is the point at which our approach stops working, and therefore it is crucial to correctly select the replication ratio to avoid this situation</li>
<li>For the Agent scene 1% of scene replication gives optimal performance for both 8 and 16 GPUs. The Spring scenes needs only 0.1% for 8 GPUs and 0.25% for 16 GPUs. The Museum scene needs 1% for 8 GPUs and 2% for 16 GPUs. Finally, the Moana scene requires 2% for 8 GPUs and 5% for 16 GPUs</li>
<li>Scalability between 8 and 16 GPUs is good for all scenes. The parallel efficiencies are 93.8%, 98.8%, 98.6%, and 99.0% for the Moana, Museum, Agent, and Spring scenes, respectively</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815194342922.png" alt="image-20210815194342922.png"></p>
<ul>
<li>Analyze memory access pattern only for one sample per pixel</li>
<li>Rendering times grows linearly with the number of samples</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815195412094.png" alt="image-20210815195412094.png"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/image-20210815195506893.png" alt="image-20210815195506893.png"></p>
<ul>
<li>Number of bounces influence</li>
</ul>
<h2 id="6-Conclusions"><a href="#6-Conclusions" class="headerlink" title="6. Conclusions"></a>6. Conclusions</h2><p><strong>Contribution</strong></p>
<ul>
<li>Presented a solution for path tracing of massive scenes on multiple GPUs</li>
<li>Analyzes the memory access pattern of a path tracer and defines how the scene data should be distributed across GPUs with a minimal loss of performance</li>
<li>Those parts of the scene data that have the highest memory access rate are replicated on all GPUs, because their distribution would have a major negative impact on performance</li>
</ul>
<p><strong>Methods</strong></p>
<ul>
<li>Uses the same memory management rules for the entire data structure</li>
<li>Splits the data structures into chunks and we control the placement and&#x2F;or replication of each chunk separately</li>
</ul>
<p><strong>Feature</strong></p>
<ul>
<li>Only control the memory allocations, the path tracer data structures do not have to be redesigned  </li>
<li>Take full advantage of NVLink 2.0 interconnect and its high bandwidth and low latency</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="https://chaphlagical.github.io">Chaf Chen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://chaphlagical.github.io/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/">https://chaphlagical.github.io/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Rendering/">Rendering</a><a class="post-meta__tags" href="/tags/Siggraph-2021/">Siggraph 2021</a><a class="post-meta__tags" href="/tags/Distributed-Computing/">Distributed Computing</a></div><div class="post_share"><div class="social-share" data-image="/img/logo.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/08/18/paper_reading/Temporally_Adaptive_Shading_Reuse_for_Real_time_Rendering_and_Virtual_Reality/" title="Temporally Adaptive Shading Reuse for Real-time Rendering and Virtual Reality"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/18/paper_reading/Temporally_Adaptive_Shading_Reuse_for_Real_time_Rendering_and_Virtual_Reality/image-20210817150114663.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Temporally Adaptive Shading Reuse for Real-time Rendering and Virtual Reality</div></div></a></div><div class="next-post pull-right"><a href="/2021/08/10/paper_reading/ExtraNet/" title="ExtraNet: Real-time Extrapolated Rendering for Low-latency Temporal Supersampling"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">ExtraNet: Real-time Extrapolated Rendering for Low-latency Temporal Supersampling</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2021/08/29/paper_reading/Low_Cost_SPAD_Sensing_for_Non_Line_Of_Sight_Tracking_Material/" title="Low-Cost SPAD Sensing for Non-Line-Of-Sight Tracking, Material Classification and Depth Imaging"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-29</div><div class="title">Low-Cost SPAD Sensing for Non-Line-Of-Sight Tracking, Material Classification and Depth Imaging</div></div></a></div><div><a href="/2021/08/25/paper_reading/Neural_Light_Transport_for_Relighting_and_View_Synthesis/" title="Neural Light Transport for Relighting and View Synthesis"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-25</div><div class="title">Neural Light Transport for Relighting and View Synthesis</div></div></a></div><div><a href="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/" title="Temporal Coherence-based Distributed Ray Tracing of Massive Scenes"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-06</div><div class="title">Temporal Coherence-based Distributed Ray Tracing of Massive Scenes</div></div></a></div><div><a href="/2021/08/18/paper_reading/Temporally_Adaptive_Shading_Reuse_for_Real_time_Rendering_and_Virtual_Reality/" title="Temporally Adaptive Shading Reuse for Real-time Rendering and Virtual Reality"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/08/18/paper_reading/Temporally_Adaptive_Shading_Reuse_for_Real_time_Rendering_and_Virtual_Reality/image-20210817150114663.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-18</div><div class="title">Temporally Adaptive Shading Reuse for Real-time Rendering and Virtual Reality</div></div></a></div><div><a href="/2023/01/25/paper_reading/Adaptive_Incident_Radiance_Field_Sampling_and_Reconstruction_Using_Deep_Reinforcement_Learning/" title="Adaptive Incident Radiance Field Sampling and Reconstruction Using Deep Reinforcement Learning"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-25</div><div class="title">Adaptive Incident Radiance Field Sampling and Reconstruction Using Deep Reinforcement Learning</div></div></a></div><div><a href="/2021/12/14/rendering/mouse_picking/" title="场景编辑器：鼠标拾取"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/12/14/rendering/mouse_picking/image-20211214200711937.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-14</div><div class="title">场景编辑器：鼠标拾取</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/logo.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Chaf Chen</div><div class="author-info__description">USTC CG Student</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">33</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Chaphlagical"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Chaphlagical" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:mail@ustc.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Looking for a Ph.D position!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Introduction"><span class="toc-number">1.</span> <span class="toc-text">1. Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Related-Work"><span class="toc-number">2.</span> <span class="toc-text">2. Related Work</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-Out-of-core-Rendering"><span class="toc-number">2.1.</span> <span class="toc-text">2.1. Out-of-core Rendering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Distributed-Rendering"><span class="toc-number">2.2.</span> <span class="toc-text">2.2. Distributed Rendering</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-Image-Parallel-Rendering"><span class="toc-number">2.2.1.</span> <span class="toc-text">2.2.1. Image-Parallel Rendering</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-Data-Parallel-Rendering"><span class="toc-number">2.2.2.</span> <span class="toc-text">2.2.2. Data-Parallel Rendering</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-Distributed-Shared-Memory-Systems"><span class="toc-number">2.3.</span> <span class="toc-text">2.3. Distributed Shared Memory Systems</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-CUDA-Unified-Memory-For-Multi-GPU-Systems"><span class="toc-number">2.4.</span> <span class="toc-text">2.4. CUDA Unified Memory For Multi-GPU Systems</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Blender-Cycles-Path-Tracer"><span class="toc-number">3.</span> <span class="toc-text">3. Blender Cycles Path Tracer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Extensions-for-Multi-GPU-Support"><span class="toc-number">3.1.</span> <span class="toc-text">3.1. Extensions for Multi-GPU Support</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-Multi-GPU-Benchmark-Systems"><span class="toc-number">3.2.</span> <span class="toc-text">3.2. Multi-GPU Benchmark Systems</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-Benchmark-Scenes"><span class="toc-number">3.3.</span> <span class="toc-text">3.3. Benchmark Scenes</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Data-Distributed-Multi-GPU-Path-Tracing"><span class="toc-number">4.</span> <span class="toc-text">4. Data Distributed Multi-GPU Path Tracing</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Basic-Distribution-of-Entire-Data-Structures"><span class="toc-number">4.1.</span> <span class="toc-text">4.1. Basic Distribution of Entire Data Structures</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-1-Memory-Access-Analysis"><span class="toc-number">4.1.1.</span> <span class="toc-text">4.1.1. Memory Access Analysis</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-2-Performance-and-Scalability-Evaluation"><span class="toc-number">4.1.2.</span> <span class="toc-text">4.1.2. Performance and Scalability Evaluation</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Advanced-Distribution-Based-on-Memory-Access-Pattern-and-Statistics"><span class="toc-number">4.2.</span> <span class="toc-text">4.2. Advanced Distribution Based on Memory Access Pattern and Statistics</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-1-Memory-Access-Pattern-Analysis"><span class="toc-number">4.2.1.</span> <span class="toc-text">4.2.1. Memory Access Pattern Analysis</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-2-Data-Placement-Algorithm-Based-on-Memory-Access-Pattern"><span class="toc-number">4.2.2.</span> <span class="toc-text">4.2.2. Data Placement Algorithm Based on Memory Access Pattern</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-3-Performance-Evaluation"><span class="toc-number">4.2.3.</span> <span class="toc-text">4.2.3. Performance Evaluation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-4-Maximum-Scene-Size-Analysis"><span class="toc-number">4.2.4.</span> <span class="toc-text">4.2.4. Maximum Scene Size Analysis</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Performance-for-massive-scenes"><span class="toc-number">5.</span> <span class="toc-text">5. Performance for massive scenes</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Conclusions"><span class="toc-number">6.</span> <span class="toc-text">6. Conclusions</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/01/25/paper_reading/Adaptive_Incident_Radiance_Field_Sampling_and_Reconstruction_Using_Deep_Reinforcement_Learning/" title="Adaptive Incident Radiance Field Sampling and Reconstruction Using Deep Reinforcement Learning">Adaptive Incident Radiance Field Sampling and Reconstruction Using Deep Reinforcement Learning</a><time datetime="2023-01-25T00:04:00.000Z" title="Created 2023-01-25 00:04:00">2023-01-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/" title="Temporal Coherence-based Distributed Ray Tracing of Massive Scenes">Temporal Coherence-based Distributed Ray Tracing of Massive Scenes</a><time datetime="2023-01-06T22:13:11.000Z" title="Created 2023-01-06 22:13:11">2023-01-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/29/gaming/spiderman_miles/" title="Marvel's Spider-Man Miles Morales"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/29/gaming/spiderman_miles/image-20221229175057590.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Marvel's Spider-Man Miles Morales"/></a><div class="content"><a class="title" href="/2022/12/29/gaming/spiderman_miles/" title="Marvel's Spider-Man Miles Morales">Marvel's Spider-Man Miles Morales</a><time datetime="2022-12-29T21:13:11.000Z" title="Created 2022-12-29 21:13:11">2022-12-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/" title="Vectorization for Fast, Analytic, and Differentiable Visibility">Vectorization for Fast, Analytic, and Differentiable Visibility</a><time datetime="2022-12-17T21:13:11.000Z" title="Created 2022-12-17 21:13:11">2022-12-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/12/14/note/edge_sampling/" title="Physics Based Differentiable Rendering: Edge Sampling">Physics Based Differentiable Rendering: Edge Sampling</a><time datetime="2022-12-14T00:00:00.000Z" title="Created 2022-12-14 00:00:00">2022-12-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Chaf Chen</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'https://chaphlagical.github.io/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/'
    this.page.identifier = '/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/'
    this.page.title = 'GPU Accelerated Path Tracing of Massive Scenes'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://chaphlagical-github-io.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }

  document.getElementById('darkmode').addEventListener('click', () => {
    setTimeout(() => window.disqusReset(), 200)
  })
}

if ('Disqus' === 'Disqus' || !false) {
  if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div></div></body></html>