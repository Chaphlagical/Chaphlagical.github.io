<!DOCTYPE html><html lang="[&quot;en&quot;,&quot;zh-CN&quot;,&quot;default&quot;]" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>Temporal Coherence-based Distributed Ray Tracing of Massive Scenes | Chaf's Blog</title><meta name="author" content="Chaf Chen"><meta name="copyright" content="Chaf Chen"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="TVCG 2022 paper reading">
<meta property="og:type" content="article">
<meta property="og:title" content="Temporal Coherence-based Distributed Ray Tracing of Massive Scenes">
<meta property="og:url" content="https://chaphlagical.github.io/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/index.html">
<meta property="og:site_name" content="Chaf&#39;s Blog">
<meta property="og:description" content="TVCG 2022 paper reading">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://chaphlagical.github.io/img/logo.jpg">
<meta property="article:published_time" content="2023-01-06T22:13:11.000Z">
<meta property="article:modified_time" content="2023-03-02T13:45:39.627Z">
<meta property="article:author" content="Chaf Chen">
<meta property="article:tag" content="Rendering">
<meta property="article:tag" content="Distributed Computing">
<meta property="article:tag" content="TVCG 2022">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://chaphlagical.github.io/img/logo.jpg"><link rel="shortcut icon" href="/img/logo.jpg"><link rel="canonical" href="https://chaphlagical.github.io/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Temporal Coherence-based Distributed Ray Tracing of Massive Scenes',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-02 13:45:39'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (false) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/logo.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">33</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Chaf's Blog"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/logo.jpg"/><span class="site-name">Chaf's Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">Temporal Coherence-based Distributed Ray Tracing of Massive Scenes</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-01-06T22:13:11.000Z" title="Created 2023-01-06 22:13:11">2023-01-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-03-02T13:45:39.627Z" title="Updated 2023-03-02 13:45:39">2023-03-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper-Reading/">Paper Reading</a></span></div><div class="meta-secondline"></div></div></div><article class="post-content" id="article-container"><h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><ul>
<li>An efficient temporal coherence-based scheduling algorithm<ul>
<li>A domain assignment algorithm<ul>
<li>Assign domains to all nodes according to the ray transmission information among domains in the previous frame</li>
</ul>
</li>
<li>A runtime scheduling algorithm<ul>
<li>Estimate each domain’s pre-loading prior based on the node’s current situation and information of the previous frame</li>
</ul>
</li>
</ul>
</li>
<li>A new virtual portal structure to record the radiance of rays passing through domains in the previous frame<ul>
<li>In the current frame, predict the radiance of the ray intersects with the virtual portal and send the low radiance rays to a pre-loaded simplified model in the current node by the recorded radiance in the virtual portal.</li>
</ul>
</li>
<li>An asynchronous distributed path tracing framework<ul>
<li>Can process domain loading, rendering and communication asynchronously</li>
</ul>
</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><ul>
<li>Out-of-Core Ray Tracing</li>
<li>Distributed Ray Tracing<ul>
<li>Image-space decomposition</li>
<li>Domain-space decomposition</li>
<li>Dynamic scheduling method</li>
</ul>
</li>
<li>Spatial Directional Radiance Caching</li>
</ul>
<h2 id="Distributed-Ray-Tracing-Framework"><a href="#Distributed-Ray-Tracing-Framework" class="headerlink" title="Distributed Ray Tracing Framework"></a>Distributed Ray Tracing Framework</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/image-20230107003324301.png"></p>
<ul>
<li>Architecture<ul>
<li>Hybrid ray tracing framework<ul>
<li>Combining the domain-space decomposition and out-of-core rendering</li>
</ul>
</li>
<li>Before rendering, a group of domains is assigned to a node<ul>
<li>Each node uses a cost-benefit formula to choose a domain to load or a cached domain to render at runtime</li>
</ul>
</li>
</ul>
</li>
<li>Temporal coherence based distributed algorithm<ol>
<li>The ray transmission and radiance information is recorded when rendering the previous frame and further used as input data for the current frame</li>
<li>A temporal coherence-based domain assignment and a domain scheduling algorithm are proposed for the current frame by using the ray transmission data of the previous frame to improve the load balance and resource utilization</li>
<li>The cached radiance information on the virtual portal in the previous frame is used to predict the radiance of the ray intersected with the virtual portal in the current frame. A low memory-cost simplified model is used to render the predicted low radiance ray</li>
</ol>
</li>
<li>Asynchronous execution thread:<ul>
<li>Management thread: responsible for communicating with other distributed nodes and managing other threads</li>
<li>Domain preloading thread: used to preload the uncached domain</li>
<li>Rendering thread: process the exact rendering task</li>
</ul>
</li>
</ul>
<h2 id="Temporal-Information-Collection"><a href="#Temporal-Information-Collection" class="headerlink" title="Temporal Information Collection"></a>Temporal Information Collection</h2><ul>
<li>Temporal information<ul>
<li>Ray transmission information between domains<ul>
<li>Recorded in the form of statistics</li>
</ul>
</li>
<li>The radiance of the rays passing through the domain<ul>
<li>Propose a cache made of virtual portal structure</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Transmission-Information-Statistics-for-Domains"><a href="#Transmission-Information-Statistics-for-Domains" class="headerlink" title="Transmission Information Statistics for Domains"></a>Transmission Information Statistics for Domains</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/image-20230107005918205.png"></p>
<p>Take the domain $A$ in above figure as an example. The recorded information includes:</p>
<ul>
<li>For domain $A$’s neighbors, domain $B$ and domain $C$, record the numbers of rays sent from domain $A$ to each of them as $s(A, B)$ and $s(A, C)$, respectively</li>
<li>The total number of rays sent from domain $A$ to other domains, recorded as $s(A)$</li>
<li>The total number of rays received by domain $A$ from other domains, recorded as $r(A)$</li>
<li>The proportion of $s(A)$ to $r(A)$, recorded as $R(A)$</li>
<li>The proportion of $s(A, B)$ to $r(A)$, recorded as $R(A, B)$</li>
<li>The data loading times of domain $A$</li>
</ul>
<h3 id="Virtual-Portal-with-Radiance-Caching"><a href="#Virtual-Portal-with-Radiance-Caching" class="headerlink" title="Virtual Portal with Radiance Caching"></a>Virtual Portal with Radiance Caching</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/image-20230107105019966.png"></p>
<p><strong>Virtual Portal Structure</strong></p>
<ul>
<li>Place virtual portals on each of the six faces of a domain’s bounding box to determine whether rays need to be sent to other domains<ul>
<li>Record spatial and directional information (2D each, 4D total)</li>
</ul>
</li>
<li>Divide each virtual portal into uniform 2D grids (32×32) in spatial space to represent the position of the intersection between the ray and virtual portal at the virtual portal’s local coordinate system</li>
<li>In practice, for each spatial grid, separate it into eight angle areas, each representing a 2D direction</li>
</ul>
<p><strong>Radiance Recording on Virtual Portal</strong></p>
<ul>
<li>When a ray intersects a virtual portal for the first time, calculate its virtual portal coordinates and record it onto the ray’s structure, and keep tracing the ray until it intersects geometry in a domain</li>
<li>After finishing the light source visibility test (shadow ray intersection) and shading, record the radiance of this ray path to the proper coordinates on the virtual portal</li>
<li>Once the current frame has been finished, the recorded virtual portal is gathered and broadcast to each node and will be used to predict the radiance of rays in the next frame</li>
<li>Only keep the maximum radiance on the coordinate if there is already a radiance value when recording radiance in the virtual portal to resolve potential conflicts</li>
</ul>
<p><strong>Node Information</strong></p>
<ul>
<li>As the distances between each node and the respective network storage system have wide variations, the data loading speeds are different for each node</li>
<li>In the first frame, when a node is loading a domain, record:<ul>
<li>Storage size</li>
<li>Loading time of the domain</li>
<li>Calculate their ratio as the data loading speed $S_{PROC}$ of the node</li>
</ul>
</li>
<li>After one frame is completed, node 0 gathers all the recorded information from other nodes and broadcasts the results to all nodes</li>
</ul>
<h2 id="Temporal-Coherence-Based-Domain-Assignment-and-Scheduling"><a href="#Temporal-Coherence-Based-Domain-Assignment-and-Scheduling" class="headerlink" title="Temporal Coherence-Based Domain Assignment and Scheduling"></a>Temporal Coherence-Based Domain Assignment and Scheduling</h2><p>Domain assignment algorithm:</p>
<ul>
<li>Assign the domains to each node</li>
<li>Runtime domain scheduling algorithm<ul>
<li>Select the next domain to pre-load during rendering<br>Improve data utilization and balance the workload between each node</li>
</ul>
</li>
</ul>
<h3 id="Domain-Assignment"><a href="#Domain-Assignment" class="headerlink" title="Domain Assignment"></a>Domain Assignment</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/image-20230107113109786.png"></p>
<ul>
<li>When rendering with $n$ nodes<ul>
<li>Divide the screen space evenly into $n$ tiles</li>
<li>Group the domains into an equal number of $n$ domain groups</li>
<li>Pack a screen tile and a domain group as an <em>AssignmentUnit</em> structure</li>
</ul>
</li>
<li>Each node<ul>
<li>Aassigned an AssignmentUnit<ul>
<li>The screen tile is the node’s ray generating task</li>
<li>The domain group is its processing data</li>
</ul>
</li>
<li>Can only load its local domains for ray tracing at runtime<ul>
<li>For a given node, domains inside its domain group are called its local domains</li>
</ul>
</li>
</ul>
</li>
<li>For massive scene ray tracing<ul>
<li>Transmitting rays between nodes is faster than out-of-core domain loading</li>
<li>Hope to minimize the ray transmission between domains inside an AssignmentUnit, to reduce the domain loading times of each node</li>
</ul>
</li>
<li>Assignment algorithm:<ol>
<li>Select initial domains for each AssignmentUnit<ul>
<li>Assign the $n$ screen tiles to the $n$ AssignmentUnits in turn</li>
<li>Project the bounding box of each domain to screen space</li>
<li>For each tile, select the domain with the largest projection area with it, and set the domain as the initial domain for this tile’s AssignmentUnit</li>
</ul>
</li>
<li>Group remaining domains<ul>
<li>Add a remaining domain to the AssignmentUnit with the fewest domain numbers in a loop until all domains have been assigned</li>
<li>Each time<ul>
<li>Choose an AssignmentUnit $U$ with the fewest domains</li>
<li>Find a remaining domain with lowest ray transmission number with all existing domains in $U$ according to the information recorded in previous frame</li>
<li>Add the domain to the domain group for $U$</li>
</ul>
</li>
</ul>
</li>
<li>Assign AssignmentUnits to nodes<ul>
<li>Sort all AssignmentUnits by the data size of domains in each AssignmentUnit</li>
<li>Sort all nodes by the data loading speed</li>
<li>Assign the AssignmentUnit with a larger data volume to the node with the faster loading speed</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="Domain-Scheduling"><a href="#Domain-Scheduling" class="headerlink" title="Domain Scheduling"></a>Domain Scheduling</h3><ul>
<li>For each node<ul>
<li>Use a temporal coherent-based domain scheduling algorithm to choose a candidate domain as the next active domain for further rendering</li>
<li>When a node is rendering an active domain, its management thread will calculate the priority of other local domains according to a cost-benefit function and select the domain with the highest priority as the next active domain<ul>
<li>If the next active domain is not cached, the domain pre-loading thread will load this domain when the active domain is being rendered</li>
<li>If the domain cache is full, the domain with the lowest priority will be selected to unload</li>
</ul>
</li>
</ul>
</li>
<li>Cost-benefit function calculates the domain’s priority by predicting its computation time and domain loading time<ul>
<li>For a node $n$ and a candidate local domain $d$<ul>
<li>$Q_{PRED}(d)$: denote the predicted quantity of rays that may be processed when domain $d$ is loaded</li>
<li>$S_{PROC}(d)$: denote the ray processing speed of the domain $d$ in the previous frame</li>
<li>$T_{LOAD}(n,d)$: denote the time of node $n$ to load domain $d$</li>
<li>$Dep’(d)$: denote the normalized distance between the viewpoint and domain $d$</li>
</ul>
</li>
<li>The priority of domain $d$, $P(n,d)$ is calculated as follows<br>  $$<br>  P(n,d)&#x3D;(1-Dep’(d))\cdot\left(\frac{Q_{PRED}(d)}{S_{PROC}(d)}-T_{LOAD}(n,d)\right)<br>  $$<ul>
<li>The larger the difference of $Q_{PRED}(d)&#x2F;S_{PROC}(d)$ and $T_{LOAD}(n,d)$, means that domain $d$ is more computationally intensive, while its loading overhead is relatively small<ul>
<li>This domain has a higher priority to be loaded</li>
</ul>
</li>
<li>When rays are transmitted in a scene, domains that are closer to the viewpoint tend to be requested earlier<ul>
<li>Use $1 − Dep’(d)$ as a term to schedule the closer domain to viewpoint</li>
</ul>
</li>
</ul>
</li>
<li>The parameter $T_{LOAD}(n,d)$ is calculated as follows:<br>  $$<br>  T_{LOAD}(n,d)&#x3D;\begin{cases}<br>  0&amp;\mathrm{if\ domain\ loaded}\\<br>  \frac{V(d)}{S_{LOAD}(n)}&amp;\mathrm{otherwise}<br>  \end{cases}<br>  $$<ul>
<li>$V(d)$: denote the data size of domain $d$</li>
<li>$S_{LOAD}(n)$: denote the loading speed of node $n$</li>
</ul>
</li>
<li>The parameter $Q_{PRED}(d)$ is calculated as follows:<br>  $$<br>  \begin{aligned}<br>      Q_{PRED}(d)&amp;&#x3D;Q_{CUR}(d)\\<br>      &amp;+Q_{CUR}(act)R(act)R(act,d)\\<br>      &amp;+Q_{POT}(d)<br>  \end{aligned}<br>  $$<ul>
<li>Predict this quantity as $Q_{PRED}(d)$ based on the current ray transmission status and the ray transmission information in the previous frame<ul>
<li>$act$: currently active domain</li>
<li>$d$: candidate domain</li>
<li>$Q_{CUR}(d)$: represents the current ray quantity of domain $d$</li>
<li>$Q_{CUR}(act)R(act)R(act,d)$: approximate the ray quantity generated from the active domain act for domain $d$ after domain act finishes rendering the current ray $Q_{CUR}(act)$<ul>
<li>$R(act)$ and $R(act, d)$ are recorded at the previous frame</li>
</ul>
</li>
<li>$Q_{POT}(d)$: represents the received ray quantity from other nodes’ (non-local) domain when domain $d$ is selected as the active domain and being rendered<br>  $$<br>  Q_{POT}(d)&#x3D;\frac{Q_{PRE}(d)-Q_{CUR_RECV}(d)}{N_{PRE}(d)-N_{CUR}(d)}<br>  $$<ul>
<li>$Q_{PRE}(d)$: represent the rays sent to domain $d$ from the non-local domains in the previous frame</li>
<li>$Q_{CUR_RECV}(d)$: represent the number of rays that the domain $d$ has received from them in the current frame</li>
<li>$Q_{PRE}(d)-Q_{CUR_RECV}(d)$: approximate the remaining rays that may be received from other nodes</li>
<li>$N_{PRE}(d)$: the total loading times of domain $d$ in the previous frame</li>
<li>$N_{CUR}(d)$: counts the number of times the domain $d$ has been loaded in the current frame</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Temporal-Coherence-Based-Simplified-Model-Tracing-Algorithm"><a href="#Temporal-Coherence-Based-Simplified-Model-Tracing-Algorithm" class="headerlink" title="Temporal Coherence-Based Simplified Model Tracing Algorithm"></a>Temporal Coherence-Based Simplified Model Tracing Algorithm</h2><ul>
<li>Optimized ray tracing algorithm by using a simplified model<ul>
<li>Reduce the overhead of ray computation and transmission</li>
<li>Store precomputed simplified models of the whole scene in each node<ul>
<li>For those unimportant rays (with low radiance) passing through its neighboring domains, prefer to trace them with simplified models in the current node to reduce the data transfer overhead</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Tracing-with-Simplified-Models"><a href="#Tracing-with-Simplified-Models" class="headerlink" title="Tracing with Simplified Models"></a>Tracing with Simplified Models</h3><ul>
<li>Based on the rays’ depths<ul>
<li>The camera rays (depth of 0)<ul>
<li>Contribute the most to the radiance</li>
<li>Use the original fine model to trace</li>
</ul>
</li>
<li>For rays with depths ≥ 2<ul>
<li>Provide almost exclusively low frequency radiance contributions</li>
<li>Trace them all using the simplified model</li>
</ul>
</li>
<li>For rays at a depth of 1<ul>
<li>Use virtual portal data structure to predict ray radiance and trace those rays with low radiance with the simplified model</li>
</ul>
</li>
</ul>
</li>
<li>Simplified models are resident in memory for all nodes<ul>
<li>No need to transfer data for further tracing</li>
</ul>
</li>
<li>For perfect reflection and refraction rays<ul>
<li>Use original fine model</li>
</ul>
</li>
</ul>
<h3 id="Radiance-Prediction"><a href="#Radiance-Prediction" class="headerlink" title="Radiance Prediction"></a>Radiance Prediction</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/image-20230107152316293.png"></p>
<ul>
<li>When a ray intersects the virtual portal<ul>
<li>Get its coordinates in our 4D virtual portal grid according to the intersection position and the ray’s direction</li>
<li>Get the recorded radiance at this coordinate in the previous frame and using it as the predicted radiance of the current ray</li>
<li>If the predicted radiance of the ray is greater than a threshold, trace it with the original fine model; otherwise, render it with the simplified model</li>
</ul>
</li>
</ul>
<h2 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h2><h3 id="Experiment-Setting"><a href="#Experiment-Setting" class="headerlink" title="Experiment Setting"></a>Experiment Setting</h3><ul>
<li>Sugon advanced computing cluster<ul>
<li>Each computing node has a 32-core 2.0 GHz x86 Hygon Dhyana processor with 128 GB main memory, each distributed node and storage system is connected by 200 GB&#x2F;s HDR InfiniBand network</li>
<li>Path tracing implementation is based on the Rodent path tracer with a BVH with branching factors eight as the accelerated structure and supports multiple importance sampling, area lights, next event estimation (NEE) , and physically-based materials</li>
<li>Use MPI for message passing between nodes</li>
</ul>
</li>
</ul>
<h3 id="Rendering-Time-amp-Scalability"><a href="#Rendering-Time-amp-Scalability" class="headerlink" title="Rendering Time &amp; Scalability"></a>Rendering Time &amp; Scalability</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/image-20230107155648470.png"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/image-20230107155925042.png"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/image-20230107155948308.png"></p>
<h3 id="Dynamic-Scene"><a href="#Dynamic-Scene" class="headerlink" title="Dynamic Scene"></a>Dynamic Scene</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/image-20230107160026174.png"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/image-20230107160035577.png"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/image-20230107160048650.png"></p>
<h2 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h2><ul>
<li>Inefficient for scenes with many perfectly reflected and refracted rays</li>
<li>Use a uniform grid to divide the scene into domains and assign domains for each node according to the number of domains regardless of the different memory footprints of each domain, resulting in an unbalanced data distribution among nodes</li>
<li>In domain scheduling, considering only the number of domains also leads to low memory usage</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="https://chaphlagical.github.io">Chaf Chen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://chaphlagical.github.io/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/">https://chaphlagical.github.io/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Rendering/">Rendering</a><a class="post-meta__tags" href="/tags/Distributed-Computing/">Distributed Computing</a><a class="post-meta__tags" href="/tags/TVCG-2022/">TVCG 2022</a></div><div class="post_share"><div class="social-share" data-image="/img/logo.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/01/25/paper_reading/Adaptive_Incident_Radiance_Field_Sampling_and_Reconstruction_Using_Deep_Reinforcement_Learning/" title="Adaptive Incident Radiance Field Sampling and Reconstruction Using Deep Reinforcement Learning"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Adaptive Incident Radiance Field Sampling and Reconstruction Using Deep Reinforcement Learning</div></div></a></div><div class="next-post pull-right"><a href="/2022/12/29/gaming/spiderman_miles/" title="Marvel's Spider-Man Miles Morales"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/29/gaming/spiderman_miles/image-20221229175057590.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Marvel's Spider-Man Miles Morales</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2021/08/15/paper_reading/GPU_Accelerated_Path_Tracing_of_Massive_Scenes/" title="GPU Accelerated Path Tracing of Massive Scenes"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-15</div><div class="title">GPU Accelerated Path Tracing of Massive Scenes</div></div></a></div><div><a href="/2023/01/25/paper_reading/Adaptive_Incident_Radiance_Field_Sampling_and_Reconstruction_Using_Deep_Reinforcement_Learning/" title="Adaptive Incident Radiance Field Sampling and Reconstruction Using Deep Reinforcement Learning"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-25</div><div class="title">Adaptive Incident Radiance Field Sampling and Reconstruction Using Deep Reinforcement Learning</div></div></a></div><div><a href="/2021/08/29/paper_reading/Low_Cost_SPAD_Sensing_for_Non_Line_Of_Sight_Tracking_Material/" title="Low-Cost SPAD Sensing for Non-Line-Of-Sight Tracking, Material Classification and Depth Imaging"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-29</div><div class="title">Low-Cost SPAD Sensing for Non-Line-Of-Sight Tracking, Material Classification and Depth Imaging</div></div></a></div><div><a href="/2021/08/25/paper_reading/Neural_Light_Transport_for_Relighting_and_View_Synthesis/" title="Neural Light Transport for Relighting and View Synthesis"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-25</div><div class="title">Neural Light Transport for Relighting and View Synthesis</div></div></a></div><div><a href="/2021/12/14/rendering/mouse_picking/" title="场景编辑器：鼠标拾取"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2021/12/14/rendering/mouse_picking/image-20211214200711937.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-14</div><div class="title">场景编辑器：鼠标拾取</div></div></a></div><div><a href="/2021/08/10/paper_reading/ExtraNet/" title="ExtraNet: Real-time Extrapolated Rendering for Low-latency Temporal Supersampling"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-10</div><div class="title">ExtraNet: Real-time Extrapolated Rendering for Low-latency Temporal Supersampling</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/logo.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Chaf Chen</div><div class="author-info__description">USTC CG Student</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">33</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Chaphlagical"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Chaphlagical" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:mail@ustc.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Looking for a Ph.D position!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Contribution"><span class="toc-number">1.</span> <span class="toc-text">Contribution</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Related-Work"><span class="toc-number">2.</span> <span class="toc-text">Related Work</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Distributed-Ray-Tracing-Framework"><span class="toc-number">3.</span> <span class="toc-text">Distributed Ray Tracing Framework</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Temporal-Information-Collection"><span class="toc-number">4.</span> <span class="toc-text">Temporal Information Collection</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Transmission-Information-Statistics-for-Domains"><span class="toc-number">4.1.</span> <span class="toc-text">Transmission Information Statistics for Domains</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Virtual-Portal-with-Radiance-Caching"><span class="toc-number">4.2.</span> <span class="toc-text">Virtual Portal with Radiance Caching</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Temporal-Coherence-Based-Domain-Assignment-and-Scheduling"><span class="toc-number">5.</span> <span class="toc-text">Temporal Coherence-Based Domain Assignment and Scheduling</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Domain-Assignment"><span class="toc-number">5.1.</span> <span class="toc-text">Domain Assignment</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Domain-Scheduling"><span class="toc-number">5.2.</span> <span class="toc-text">Domain Scheduling</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Temporal-Coherence-Based-Simplified-Model-Tracing-Algorithm"><span class="toc-number">6.</span> <span class="toc-text">Temporal Coherence-Based Simplified Model Tracing Algorithm</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Tracing-with-Simplified-Models"><span class="toc-number">6.1.</span> <span class="toc-text">Tracing with Simplified Models</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Radiance-Prediction"><span class="toc-number">6.2.</span> <span class="toc-text">Radiance Prediction</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Result"><span class="toc-number">7.</span> <span class="toc-text">Result</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Experiment-Setting"><span class="toc-number">7.1.</span> <span class="toc-text">Experiment Setting</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Rendering-Time-amp-Scalability"><span class="toc-number">7.2.</span> <span class="toc-text">Rendering Time &amp; Scalability</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dynamic-Scene"><span class="toc-number">7.3.</span> <span class="toc-text">Dynamic Scene</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Limitations"><span class="toc-number">8.</span> <span class="toc-text">Limitations</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/01/25/paper_reading/Adaptive_Incident_Radiance_Field_Sampling_and_Reconstruction_Using_Deep_Reinforcement_Learning/" title="Adaptive Incident Radiance Field Sampling and Reconstruction Using Deep Reinforcement Learning">Adaptive Incident Radiance Field Sampling and Reconstruction Using Deep Reinforcement Learning</a><time datetime="2023-01-25T00:04:00.000Z" title="Created 2023-01-25 00:04:00">2023-01-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/" title="Temporal Coherence-based Distributed Ray Tracing of Massive Scenes">Temporal Coherence-based Distributed Ray Tracing of Massive Scenes</a><time datetime="2023-01-06T22:13:11.000Z" title="Created 2023-01-06 22:13:11">2023-01-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/29/gaming/spiderman_miles/" title="Marvel's Spider-Man Miles Morales"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/2022/12/29/gaming/spiderman_miles/image-20221229175057590.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Marvel's Spider-Man Miles Morales"/></a><div class="content"><a class="title" href="/2022/12/29/gaming/spiderman_miles/" title="Marvel's Spider-Man Miles Morales">Marvel's Spider-Man Miles Morales</a><time datetime="2022-12-29T21:13:11.000Z" title="Created 2022-12-29 21:13:11">2022-12-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/12/17/paper_reading/Vectorization_for_Fast_Analytic_and_Differentiable_Visibility/" title="Vectorization for Fast, Analytic, and Differentiable Visibility">Vectorization for Fast, Analytic, and Differentiable Visibility</a><time datetime="2022-12-17T21:13:11.000Z" title="Created 2022-12-17 21:13:11">2022-12-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/12/14/note/edge_sampling/" title="Physics Based Differentiable Rendering: Edge Sampling">Physics Based Differentiable Rendering: Edge Sampling</a><time datetime="2022-12-14T00:00:00.000Z" title="Created 2022-12-14 00:00:00">2022-12-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Chaf Chen</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'https://chaphlagical.github.io/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/'
    this.page.identifier = '/2023/01/06/paper_reading/Temporal_Coherence-Based_Distributed_Ray_Tracing_of_Massive_Scenes/'
    this.page.title = 'Temporal Coherence-based Distributed Ray Tracing of Massive Scenes'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://chaphlagical-github-io.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }

  document.getElementById('darkmode').addEventListener('click', () => {
    setTimeout(() => window.disqusReset(), 200)
  })
}

if ('Disqus' === 'Disqus' || !false) {
  if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div></div></body></html>